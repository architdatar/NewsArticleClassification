---
title: "EDA Report"
author: "Bobby Lumpkin"
date: 
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Text Preprocessing

```{r preprocessing}
####################
#text preprocessing#
####################
#instal packages if you did not use them before. Ignore this step if you have these packages installed. 
#install.packages("quanteda")
#install.packages("readtext")
#install.packages("stringr")

#load the library
library(quanteda)
library(readtext)
library(stringr)

#read in the file using the readtext package
data <- readtext("data_to_group.csv", text_field = "title")

#clean text
data[["text"]] <-  stringr::str_replace_all(data[["text"]],"[^a-zA-Z\\s]", " ")
data[["text"]] <- stringr::str_replace_all(data[["text"]],"[\\s]+", " ")

#build a corpus, that is a bag of words
titles_corpus <- corpus(data)
summary(titles_corpus)

#explore the corpus texts a little bit. You can skip this step.
kwic(titles_corpus, "trump")

#create tokens (https://www.mzes.uni-mannheim.de/socialsciencedatalab/article/advancing-text-mining/#supervised)
titles_tokens <- tokens(titles_corpus, remove_numbers = TRUE, remove_symbols = TRUE, remove_punct = TRUE, remove_separators = TRUE, include_docvars = TRUE)

#lower case the tokens
titles_tokens <- tokens_tolower(titles_tokens)

#remove stopwords, such as "a" "an" "the" "and" etc
titles_tokens <- tokens_remove(titles_tokens, stopwords("english"))

#stem the tokens (e.g., learning -> learn, learned -> learn)
titles_tokens <- tokens_wordstem(titles_tokens)

#create document-feature matrix
titles_dfm <- dfm(titles_tokens)

#trim the text with dfm_trim. filter out words that appear less than 2.5% and more than 97.5% because these words may be less useful for prediction.
titles_dfm_trim <- dfm_trim(titles_dfm, min_docfreq = 0.025, max_docfreq = 0.975, docfreq_type = "prop")

#take a look at the dfm.
head(dfm_sort(titles_dfm_trim, decreasing =TRUE, margin = "both"), n = 10, nf = 10)

#create tf-idf (term-frequency-inverse-ducument-frequency), which is often used as a weighting factor in search for important words to a document in a collection or corpus. (https://en.wikipedia.org/wiki/Tf%E2%80%93idf)
#you can skip this step for now.
titles_tfidf <- dfm_tfidf(titles_dfm_trim)

#convert the dfm to a data frame. We can convert the trimmed dfm or the raw dfm.
titles_dataframe <- convert(titles_dfm, to = "data.frame", docid_field = "doc_id")

#add the document-level variables to the data frame
ready_to_use <- merge(x = titles_dataframe, y = data, by = "doc_id", all = TRUE)
```

## Exploring the Data

```{r initial look}
# remove the non-binary data from original data set (what existed before pre-processing)
original_cols <- colnames(data)
drop_cols <- original_cols[!(original_cols %in% c('doc_id', 'related'))]
ready_to_use_NoOriginalData <- ready_to_use[ , !(names(ready_to_use) %in% drop_cols)]

# Check the data dimension
dim(ready_to_use_NoOriginalData)

# See some of the variable names
names(ready_to_use_NoOriginalData)[0:50]

# Distribution of the response
table(ready_to_use_NoOriginalData$related)

# Sample proportion
table(ready_to_use_NoOriginalData$related) / nrow(ready_to_use)
```
Below, we look to see what proportion of "related" articles have a given word in their title, what proportion of "non-related" articles have a word in their title, and the words with largest absolute difference between those two groups. These words might be most useful as features.
```{r examining predictors}
## proportion of related articles that include words in title
related_cases <- ready_to_use_NoOriginalData[ready_to_use_NoOriginalData$related == 1, ][,-1]
related_cases <- related_cases[ , which(colnames(related_cases) != 'related')]

related_cases_means <- colMeans(related_cases)
related_cases_means[1:10]

## proportion of non-related articles that include words in title
non_related_cases <- ready_to_use_NoOriginalData[ready_to_use_NoOriginalData$related == 0, ][,-1]
non_related_cases <- non_related_cases[ , which(colnames(non_related_cases) != 'related')]

non_related_cases_means <- colMeans(non_related_cases)
non_related_cases_means[1:10]

## Absolute difference between them
abs_diff_means <- abs(related_cases_means - non_related_cases_means)

## Round and sort the differences
sorted_diffs <- round(sort(abs_diff_means, decreasing = TRUE), digits = 4)
sorted_diffs[1:10]
```