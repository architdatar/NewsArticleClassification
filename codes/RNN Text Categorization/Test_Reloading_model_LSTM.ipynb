{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from bpmll import bp_mll_loss\n",
    "import sklearn_json as skljson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the \n",
    "from threshold_learning import predict_labels_binary         ## threshold_learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Cross Entropy LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LSTM RNN architecture\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_LSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.LSTM(16, return_sequences = False, return_state = False),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "#optim_func_LSTM = tf.keras.optimizers.Adagrad(\n",
    "#    learning_rate = 0.001, initial_accumulator_value = 0.1, epsilon = 1e-07,\n",
    "#    name = 'Adagrad')\n",
    "\n",
    "#metrics = tfa.metrics.hamming_loss_fn(mode = 'multi-label')\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy', optimizer = optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c7220a4bb0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the weights\n",
    "model_LSTM.load_weights('Models/Cross_Entropy/LSTM_weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object = open('RNN_data_dict.json',)\n",
    "RNN_data_dict = json.load(file_object)\n",
    "RNN_data_dict = ast.literal_eval(RNN_data_dict)\n",
    "train_padded = np.array(RNN_data_dict['train_padded'])\n",
    "test_padded = np.array(RNN_data_dict['test_padded'])\n",
    "Y_train = np.array(RNN_data_dict['Y_train'])\n",
    "Y_test = np.array(RNN_data_dict['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5024038461538461"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using a constant 0.5 threshold function, get the hamming loss for the trained network on the test set\n",
    "predictions = model_LSTM.predict(test_padded)\n",
    "predictions_binary = model_LSTM.predict(test_padded)\n",
    "for i in range(Y_test.shape[0]):\n",
    "    for j in range(Y_test.shape[1]):\n",
    "        if predictions_binary[i, j] > 0.5:\n",
    "            predictions_binary[i, j] = 1\n",
    "        else:\n",
    "            predictions_binary[i, j] = 0\n",
    "\n",
    "# Get the hamming loss\n",
    "metrics.hamming_loss(Y_test, predictions_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass fit_intercept={'copy_X': True, 'fit_intercept': True, 'n_jobs': None, 'normalize': False} as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17548076923076922"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load the learned threshold function and get test-set hamming loss\n",
    "Y_test_pred = model_LSTM.predict(test_padded)\n",
    "threshold_filepath = 'Models/Cross_Entropy/threshold_LSTM.json'\n",
    "threshold_function = skljson.from_json(threshold_filepath)\n",
    "test_labels_binary = predict_labels_binary(Y_test_pred, threshold_function)\n",
    "\n",
    "metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the BP-MLL Bidirectional LSTM (trained on many epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bidirectional LSTM RNN architecture\n",
    "model_biLSTM_bpmll = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences = False, return_state = False)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_bpmll = tf.keras.optimizers.Adam(lr=0.001)\n",
    "#optim_bpmll = tf.keras.optimizers.Adagrad(\n",
    "#    learning_rate = 0.1, initial_accumulator_value = 0.1, epsilon = 1e-07,\n",
    "#    name = 'Adagrad')\n",
    "\n",
    "#optim = tf.keras.optimizers.RMSprop(learning_rate=0.001, rho=0.9, momentum = 0.8, epsilon=1e-07,)\n",
    "\n",
    "metric = tfa.metrics.HammingLoss(mode = 'multilabel', threshold = 0.5)\n",
    "model_biLSTM_bpmll.compile(loss = bp_mll_loss, optimizer = optim_bpmll, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2c722365fa0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_biLSTM_bpmll.load_weights('Models/BPMLL/biLSTM_bpmll_weights_manyEpochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object_reduced = open('RNN_data_dict_reduced.json',)\n",
    "RNN_data_dict_reduced = json.load(file_object_reduced)\n",
    "RNN_data_dict_reduced = ast.literal_eval(RNN_data_dict_reduced)\n",
    "train_padded_hasLabel = np.array(RNN_data_dict_reduced['train_padded_hasLabel'])\n",
    "test_padded_hasLabel = np.array(RNN_data_dict_reduced['test_padded_hasLabel'])\n",
    "Y_train_hasLabel = np.array(RNN_data_dict_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(RNN_data_dict_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15034965034965034"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using a constant 0.5 threshold function, get the hamming loss for the trained network on the test set\n",
    "predictions = model_biLSTM_bpmll.predict(test_padded_hasLabel)\n",
    "predictions_binary = model_biLSTM_bpmll.predict(test_padded_hasLabel)\n",
    "for i in range(Y_test_hasLabel.shape[0]):\n",
    "    for j in range(Y_test_hasLabel.shape[1]):\n",
    "        if predictions_binary[i, j] > 0.5:\n",
    "            predictions_binary[i, j] = 1\n",
    "        else:\n",
    "            predictions_binary[i, j] = 0\n",
    "\n",
    "# Get the hamming loss\n",
    "metrics.hamming_loss(Y_test_hasLabel, predictions_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
