{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from bpmll import bp_mll_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the \n",
    "                                                             ## threshold_learning library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LSTM RNN architecture\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_LSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.LSTM(16, return_sequences = False, return_state = False),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "#optim_func_LSTM = tf.keras.optimizers.Adagrad(\n",
    "#    learning_rate = 0.001, initial_accumulator_value = 0.1, epsilon = 1e-07,\n",
    "#    name = 'Adagrad')\n",
    "\n",
    "#metrics = tfa.metrics.hamming_loss_fn(mode = 'multi-label')\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy', optimizer = optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x254939949d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Restore the weights\n",
    "model_LSTM.load_weights('./Models/Models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>threats/impacts</th>\n",
       "      <th>responses/actions</th>\n",
       "      <th>severity</th>\n",
       "      <th>susceptibility</th>\n",
       "      <th>self-efficacy</th>\n",
       "      <th>external-efficacy</th>\n",
       "      <th>response efficacy</th>\n",
       "      <th>public health</th>\n",
       "      <th>...</th>\n",
       "      <th>prosper</th>\n",
       "      <th>preview</th>\n",
       "      <th>moor</th>\n",
       "      <th>coverag</th>\n",
       "      <th>glow</th>\n",
       "      <th>profil</th>\n",
       "      <th>clash</th>\n",
       "      <th>incumb</th>\n",
       "      <th>frequent</th>\n",
       "      <th>unfound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214236</td>\n",
       "      <td>MURPHY: Again Martha we are defacto staying at...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214232</td>\n",
       "      <td>GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214266</td>\n",
       "      <td>BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214246</td>\n",
       "      <td>But in the meantime, my message to Louisiana i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214238</td>\n",
       "      <td>MURPHY: Yeah listen, we had gotten another shi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   para_id                                          full_text  \\\n",
       "0   214236  MURPHY: Again Martha we are defacto staying at...   \n",
       "1   214232  GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...   \n",
       "2   214266  BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...   \n",
       "3   214246  But in the meantime, my message to Louisiana i...   \n",
       "4   214238  MURPHY: Yeah listen, we had gotten another shi...   \n",
       "\n",
       "   threats/impacts  responses/actions  severity  susceptibility  \\\n",
       "0                1                  1         0               1   \n",
       "1                1                  1         1               1   \n",
       "2                0                  1         0               0   \n",
       "3                1                  1         1               0   \n",
       "4                0                  1         0               0   \n",
       "\n",
       "   self-efficacy  external-efficacy  response efficacy  public health  ...  \\\n",
       "0              1                  0                  1              1  ...   \n",
       "1              1                  0                  1              1  ...   \n",
       "2              0                  1                  0              1  ...   \n",
       "3              1                  0                  1              1  ...   \n",
       "4              0                  1                  0              1  ...   \n",
       "\n",
       "   prosper  preview  moor  coverag  glow  profil  clash  incumb  frequent  \\\n",
       "0      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "1      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "2      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "3      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "4      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "\n",
       "  unfound  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 2119 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load 'content_paragraphs_ready.csv' into a pandas dataframe\n",
    "data_filepath = \"..\\..\\dataset\\content_paragraphs_ready.csv\"\n",
    "paragraph_data = pd.read_csv(data_filepath)\n",
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>threats/impacts</th>\n",
       "      <th>responses/actions</th>\n",
       "      <th>severity</th>\n",
       "      <th>susceptibility</th>\n",
       "      <th>self-efficacy</th>\n",
       "      <th>external-efficacy</th>\n",
       "      <th>response efficacy</th>\n",
       "      <th>public health</th>\n",
       "      <th>economy</th>\n",
       "      <th>education</th>\n",
       "      <th>political evaluation</th>\n",
       "      <th>racial conflict</th>\n",
       "      <th>international ralations/foreign policies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214236</td>\n",
       "      <td>MURPHY: Again Martha we are defacto staying at...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214232</td>\n",
       "      <td>GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214266</td>\n",
       "      <td>BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214246</td>\n",
       "      <td>But in the meantime, my message to Louisiana i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214238</td>\n",
       "      <td>MURPHY: Yeah listen, we had gotten another shi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   para_id                                          full_text  \\\n",
       "0   214236  MURPHY: Again Martha we are defacto staying at...   \n",
       "1   214232  GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...   \n",
       "2   214266  BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...   \n",
       "3   214246  But in the meantime, my message to Louisiana i...   \n",
       "4   214238  MURPHY: Yeah listen, we had gotten another shi...   \n",
       "\n",
       "   threats/impacts  responses/actions  severity  susceptibility  \\\n",
       "0                1                  1         0               1   \n",
       "1                1                  1         1               1   \n",
       "2                0                  1         0               0   \n",
       "3                1                  1         1               0   \n",
       "4                0                  1         0               0   \n",
       "\n",
       "   self-efficacy  external-efficacy  response efficacy  public health  \\\n",
       "0              1                  0                  1              1   \n",
       "1              1                  0                  1              1   \n",
       "2              0                  1                  0              1   \n",
       "3              1                  0                  1              1   \n",
       "4              0                  1                  0              1   \n",
       "\n",
       "   economy  education  political evaluation  racial conflict  \\\n",
       "0        0          0                     0                0   \n",
       "1        0          0                     0                0   \n",
       "2        0          0                     0                0   \n",
       "3        0          0                     0                0   \n",
       "4        0          0                     0                0   \n",
       "\n",
       "   international ralations/foreign policies  \n",
       "0                                         0  \n",
       "1                                         0  \n",
       "2                                         0  \n",
       "3                                         0  \n",
       "4                                         0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Keep only the paragraph id, paragraph text, and labels\n",
    "to_keep = paragraph_data.columns[0:15]\n",
    "#to_keep\n",
    "paragraph_data = paragraph_data[to_keep]\n",
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocessing\n",
    "import re\n",
    "import string\n",
    "\n",
    "def remove_URL(text):\n",
    "    url = re.compile(r\"https?://\\S+|www\\.\\S+\")\n",
    "    return url.sub(r\"\", text)\n",
    "\n",
    "# https://stackoverflow.com/questions/34293875/how-to-remove-punctuation-marks-from-a-string-in-python-3-x-using-translate/34294022\n",
    "def remove_punct(text):\n",
    "    translator = str.maketrans(\"\", \"\", string.punctuation)\n",
    "    return text.translate(translator)\n",
    "\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r\"https?://(\\S+|www)\\.\\S+\")\n",
    "for t in paragraph_data.full_text:\n",
    "    matches = pattern.findall(t)\n",
    "    for match in matches:\n",
    "        print(t)\n",
    "        print(match)\n",
    "        print(pattern.sub(r\"\", t))\n",
    "    if len(matches) > 0:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_data[\"full_text\"] = paragraph_data.full_text.map(remove_URL) # map(lambda x: remove_URL(x))\n",
    "paragraph_data[\"full_text\"] = paragraph_data.full_text.map(remove_punct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\rober\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Stop Words: A stop word is a commonly used word (such as “the”, “a”, “an”, “in”) that a search engine\n",
    "# has been programmed to ignore, both when indexing entries for searching and when retrieving them \n",
    "# as the result of a search query.\n",
    "stop = set(stopwords.words(\"english\"))\n",
    "\n",
    "# https://stackoverflow.com/questions/5486337/how-to-remove-stop-words-using-nltk-or-python\n",
    "def remove_stopwords(text):\n",
    "    filtered_words = [word.lower() for word in text.split() if word.lower() not in stop]\n",
    "    return \" \".join(filtered_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph_data[\"full_text\"] = paragraph_data.full_text.map(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count unique words\n",
    "def counter_word(text_col):\n",
    "    count = Counter()\n",
    "    for text in text_col.values:\n",
    "        for word in text.split():\n",
    "            count[word] += 1\n",
    "    return count\n",
    "\n",
    "counter = counter_word(paragraph_data.full_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('said', 69), ('people', 61), ('trump', 49), ('new', 48), ('tests', 47)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_unique_words = len(counter)\n",
    "counter.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the X and Y train and test matrices\n",
    "covariate_cols = ['full_text']\n",
    "label_cols = paragraph_data.columns.difference(['para_id'] + covariate_cols)\n",
    "\n",
    "X = paragraph_data.full_text.to_numpy()\n",
    "Y = paragraph_data[label_cols].to_numpy().astype(float)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "random.seed(123)\n",
    "\n",
    "# vectorize a text corpus by turning each text into a sequence of integers\n",
    "tokenizer = Tokenizer(num_words = num_unique_words)\n",
    "tokenizer.fit_on_texts(X_train) # fit only to training\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequences = tokenizer.texts_to_sequences(X_train)\n",
    "test_sequences = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_par_length = 0\n",
    "for par in train_sequences:\n",
    "    if len(par) > max_par_length:\n",
    "        max_par_length = len(par)\n",
    "        \n",
    "max_par_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((194, 100), (96, 100))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pad the sequences to have the same length\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Max number of words in a sequence\n",
    "max_length = 100\n",
    "\n",
    "train_padded = pad_sequences(train_sequences, maxlen = max_length, padding = \"post\", truncating = \"post\")\n",
    "test_padded = pad_sequences(test_sequences, maxlen = max_length, padding = \"post\", truncating = \"post\")\n",
    "train_padded.shape, test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check reversing the indices\n",
    "# flip (key, value)\n",
    "reverse_word_index = dict([(idx, word) for (word, idx) in word_index.items()])\n",
    "\n",
    "def decode(sequence):\n",
    "    return \" \".join([reverse_word_index.get(idx, \"?\") for idx in sequence])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5024038461538461"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Using a constant 0.5 threshold function, get the hamming loss for the trained network on the test set\n",
    "predictions = model_LSTM.predict(test_padded)\n",
    "predictions_binary = model_LSTM.predict(test_padded)\n",
    "for i in range(Y_test.shape[0]):\n",
    "    for j in range(Y_test.shape[1]):\n",
    "        if predictions_binary[i, j] > 0.5:\n",
    "            predictions_binary[i, j] = 1\n",
    "        else:\n",
    "            predictions_binary[i, j] = 0\n",
    "\n",
    "# Get the hamming loss\n",
    "metrics.hamming_loss(Y_test, predictions_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17708333333333334"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Learn a Threshold Function\n",
    "Y_train_pred = model_LSTM.predict(train_padded)\n",
    "Y_test_pred = model_LSTM.predict(test_padded)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
