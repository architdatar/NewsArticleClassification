{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Filename: Generate_ANN_Results.ipynb\n",
    "#\n",
    "# Purpose: Generate results from different ANN models trained on paragraph \n",
    "#          classification task\n",
    "#\n",
    "# Author(s): Bobby (Robert) Lumpkin\n",
    "#\n",
    "# Library Dependencies: numpy, pandas, tensorflow, bpmll\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Results from Different ANN Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from bpmll import bp_mll_loss\n",
    "import sklearn_json as skljson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "os.chdir('C:\\\\Users\\\\rober\\\\OneDrive\\\\Documents\\\\STAT 6500\\\\Project\\\\NewsArticleClassification\\\\codes\\\\ANN Results')  ## Set working directory\n",
    "                                                                                                                      ## to be 'ANN Results'\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the \n",
    "from threshold_learning import predict_labels_binary         ## threshold_learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Reduced Dataset (each instance has atleast one label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the reduced tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data_reduced.json',)\n",
    "tfidf_data_reduced = json.load(file_object)\n",
    "X_train_hasLabel = np.array(tfidf_data_reduced['X_train_hasLabel'])\n",
    "X_test_hasLabel = np.array(tfidf_data_reduced['X_test_hasLabel'])\n",
    "Y_train_hasLabel = np.array(tfidf_data_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(tfidf_data_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the cross-entropy loss network (bpmll used later)\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "metric = tfa.metrics.HammingLoss(mode = 'multilabel', threshold = 0.5)\n",
    "\n",
    "model_ce_FF.compile(optimizer = optim_func,\n",
    "              loss = 'categorical_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 3s - loss: 8.4710 - hamming_loss: 0.4803 - val_loss: 8.2122 - val_hamming_loss: 0.4685\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 8.1678 - hamming_loss: 0.4694 - val_loss: 8.0670 - val_hamming_loss: 0.4703\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 8.0293 - hamming_loss: 0.4672 - val_loss: 7.9268 - val_hamming_loss: 0.4747\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 7.9066 - hamming_loss: 0.4580 - val_loss: 7.7977 - val_hamming_loss: 0.4712\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 7.8850 - hamming_loss: 0.4624 - val_loss: 7.6922 - val_hamming_loss: 0.4773\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 7.7712 - hamming_loss: 0.4563 - val_loss: 7.6317 - val_hamming_loss: 0.4843\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 7.9109 - hamming_loss: 0.4650 - val_loss: 7.6316 - val_hamming_loss: 0.4948\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 8.1664 - hamming_loss: 0.4760 - val_loss: 7.7078 - val_hamming_loss: 0.5096\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 8.2705 - hamming_loss: 0.4821 - val_loss: 7.8541 - val_hamming_loss: 0.5157\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 8.6326 - hamming_loss: 0.4803 - val_loss: 8.0532 - val_hamming_loss: 0.5341\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 9.3283 - hamming_loss: 0.4934 - val_loss: 8.3252 - val_hamming_loss: 0.5612\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 9.4286 - hamming_loss: 0.5122 - val_loss: 8.6326 - val_hamming_loss: 0.5927\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 10.2863 - hamming_loss: 0.5297 - val_loss: 8.9910 - val_hamming_loss: 0.6101\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 10.4714 - hamming_loss: 0.5240 - val_loss: 9.3824 - val_hamming_loss: 0.6329\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 11.2945 - hamming_loss: 0.5398 - val_loss: 9.8061 - val_hamming_loss: 0.6521\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 11.6200 - hamming_loss: 0.5564 - val_loss: 10.2605 - val_hamming_loss: 0.6547\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 12.4932 - hamming_loss: 0.5726 - val_loss: 10.7258 - val_hamming_loss: 0.6608\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 12.7814 - hamming_loss: 0.5870 - val_loss: 11.1824 - val_hamming_loss: 0.6617\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 13.0035 - hamming_loss: 0.5752 - val_loss: 11.6530 - val_hamming_loss: 0.6635\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 14.4636 - hamming_loss: 0.6014 - val_loss: 12.1663 - val_hamming_loss: 0.6635\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 15.7123 - hamming_loss: 0.6071 - val_loss: 12.6506 - val_hamming_loss: 0.6643\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 16.3353 - hamming_loss: 0.6233 - val_loss: 13.1759 - val_hamming_loss: 0.6652\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 16.6213 - hamming_loss: 0.6246 - val_loss: 13.7727 - val_hamming_loss: 0.6652\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 18.0117 - hamming_loss: 0.6333 - val_loss: 14.4159 - val_hamming_loss: 0.6652\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 19.5418 - hamming_loss: 0.6298 - val_loss: 15.1043 - val_hamming_loss: 0.6652\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 20.3929 - hamming_loss: 0.6455 - val_loss: 15.8235 - val_hamming_loss: 0.6652\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 20.5191 - hamming_loss: 0.6394 - val_loss: 16.4705 - val_hamming_loss: 0.6661\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 22.2708 - hamming_loss: 0.6482 - val_loss: 17.1718 - val_hamming_loss: 0.6670\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 23.5800 - hamming_loss: 0.6508 - val_loss: 17.7160 - val_hamming_loss: 0.6670\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 25.2767 - hamming_loss: 0.6503 - val_loss: 18.2824 - val_hamming_loss: 0.6670\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 26.2792 - hamming_loss: 0.6517 - val_loss: 18.9878 - val_hamming_loss: 0.6670\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 26.7065 - hamming_loss: 0.6569 - val_loss: 19.8113 - val_hamming_loss: 0.6678\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 28.0540 - hamming_loss: 0.6608 - val_loss: 20.8366 - val_hamming_loss: 0.6678\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 29.2672 - hamming_loss: 0.6525 - val_loss: 21.7717 - val_hamming_loss: 0.6678\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 32.3945 - hamming_loss: 0.6573 - val_loss: 22.6849 - val_hamming_loss: 0.6678\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 32.3483 - hamming_loss: 0.6587 - val_loss: 23.5434 - val_hamming_loss: 0.6678\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 34.8478 - hamming_loss: 0.6604 - val_loss: 24.4484 - val_hamming_loss: 0.6678\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 35.9453 - hamming_loss: 0.6600 - val_loss: 25.3354 - val_hamming_loss: 0.6678\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 36.8652 - hamming_loss: 0.6656 - val_loss: 26.2129 - val_hamming_loss: 0.6678\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 39.7134 - hamming_loss: 0.6661 - val_loss: 26.7740 - val_hamming_loss: 0.6678\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 37.2432 - hamming_loss: 0.6661 - val_loss: 27.4753 - val_hamming_loss: 0.6678\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 38.9011 - hamming_loss: 0.6687 - val_loss: 28.3102 - val_hamming_loss: 0.6678\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 41.2975 - hamming_loss: 0.6643 - val_loss: 29.1223 - val_hamming_loss: 0.6678\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 44.3891 - hamming_loss: 0.6678 - val_loss: 29.6411 - val_hamming_loss: 0.6678\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 46.1487 - hamming_loss: 0.6665 - val_loss: 30.2919 - val_hamming_loss: 0.6678\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 47.5329 - hamming_loss: 0.6705 - val_loss: 30.7459 - val_hamming_loss: 0.6678\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 48.2684 - hamming_loss: 0.6683 - val_loss: 31.7511 - val_hamming_loss: 0.6678\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 50.1516 - hamming_loss: 0.6687 - val_loss: 32.9713 - val_hamming_loss: 0.6678\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 48.4011 - hamming_loss: 0.6678 - val_loss: 34.2191 - val_hamming_loss: 0.6678\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 54.6368 - hamming_loss: 0.6718 - val_loss: 35.6117 - val_hamming_loss: 0.6678\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 57.3756 - hamming_loss: 0.6665 - val_loss: 37.1238 - val_hamming_loss: 0.6678\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 58.8300 - hamming_loss: 0.6696 - val_loss: 38.0759 - val_hamming_loss: 0.6678\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 57.3341 - hamming_loss: 0.6691 - val_loss: 39.0924 - val_hamming_loss: 0.6678\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 59.7188 - hamming_loss: 0.6718 - val_loss: 39.7637 - val_hamming_loss: 0.6678\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 65.3551 - hamming_loss: 0.6696 - val_loss: 40.9063 - val_hamming_loss: 0.6678\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 65.2669 - hamming_loss: 0.6718 - val_loss: 42.1393 - val_hamming_loss: 0.6678\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 68.6910 - hamming_loss: 0.6696 - val_loss: 43.1587 - val_hamming_loss: 0.6678\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 69.1113 - hamming_loss: 0.6722 - val_loss: 44.3983 - val_hamming_loss: 0.6678\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 69.1146 - hamming_loss: 0.6718 - val_loss: 45.8058 - val_hamming_loss: 0.6678\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 71.0829 - hamming_loss: 0.6722 - val_loss: 47.0582 - val_hamming_loss: 0.6678\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 75.3890 - hamming_loss: 0.6687 - val_loss: 47.8989 - val_hamming_loss: 0.6678\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 72.8666 - hamming_loss: 0.6713 - val_loss: 47.9632 - val_hamming_loss: 0.6678\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 76.6102 - hamming_loss: 0.6731 - val_loss: 47.9931 - val_hamming_loss: 0.6678\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 76.1971 - hamming_loss: 0.6705 - val_loss: 49.0748 - val_hamming_loss: 0.6678\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 85.6006 - hamming_loss: 0.6726 - val_loss: 50.2712 - val_hamming_loss: 0.6678\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 79.8813 - hamming_loss: 0.6700 - val_loss: 51.4926 - val_hamming_loss: 0.6678\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 84.7942 - hamming_loss: 0.6713 - val_loss: 52.2983 - val_hamming_loss: 0.6678\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 85.8572 - hamming_loss: 0.6718 - val_loss: 53.0553 - val_hamming_loss: 0.6678\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 88.9381 - hamming_loss: 0.6718 - val_loss: 53.9332 - val_hamming_loss: 0.6678\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 90.7903 - hamming_loss: 0.6687 - val_loss: 55.2999 - val_hamming_loss: 0.6678\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 90.2574 - hamming_loss: 0.6713 - val_loss: 56.6254 - val_hamming_loss: 0.6678\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 91.2098 - hamming_loss: 0.6726 - val_loss: 58.4273 - val_hamming_loss: 0.6678\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 95.7419 - hamming_loss: 0.6705 - val_loss: 60.0694 - val_hamming_loss: 0.6678\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 94.9817 - hamming_loss: 0.6718 - val_loss: 61.3901 - val_hamming_loss: 0.6678\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 100.0732 - hamming_loss: 0.6731 - val_loss: 63.0352 - val_hamming_loss: 0.6678\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 105.5481 - hamming_loss: 0.6740 - val_loss: 64.2155 - val_hamming_loss: 0.6678\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 108.2275 - hamming_loss: 0.6691 - val_loss: 64.7046 - val_hamming_loss: 0.6678\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 108.2853 - hamming_loss: 0.6700 - val_loss: 65.4705 - val_hamming_loss: 0.6678\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 115.6899 - hamming_loss: 0.6722 - val_loss: 66.4434 - val_hamming_loss: 0.6678\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 111.3224 - hamming_loss: 0.6718 - val_loss: 66.9156 - val_hamming_loss: 0.6678\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 114.1459 - hamming_loss: 0.6700 - val_loss: 67.9034 - val_hamming_loss: 0.6678\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 115.1994 - hamming_loss: 0.6696 - val_loss: 68.8504 - val_hamming_loss: 0.6678\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 119.0428 - hamming_loss: 0.6705 - val_loss: 69.0581 - val_hamming_loss: 0.6678\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 124.6119 - hamming_loss: 0.6700 - val_loss: 69.2347 - val_hamming_loss: 0.6678\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 113.8358 - hamming_loss: 0.6700 - val_loss: 70.2090 - val_hamming_loss: 0.6678\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 120.9100 - hamming_loss: 0.6691 - val_loss: 71.9069 - val_hamming_loss: 0.6678\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 118.1001 - hamming_loss: 0.6705 - val_loss: 73.2444 - val_hamming_loss: 0.6678\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 128.7709 - hamming_loss: 0.6722 - val_loss: 74.3166 - val_hamming_loss: 0.6678\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 129.4456 - hamming_loss: 0.6705 - val_loss: 75.7743 - val_hamming_loss: 0.6678\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 127.9529 - hamming_loss: 0.6722 - val_loss: 77.3165 - val_hamming_loss: 0.6678\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 135.0566 - hamming_loss: 0.6696 - val_loss: 78.2351 - val_hamming_loss: 0.6678\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 134.8612 - hamming_loss: 0.6713 - val_loss: 78.9176 - val_hamming_loss: 0.6678\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 136.7973 - hamming_loss: 0.6700 - val_loss: 79.8110 - val_hamming_loss: 0.6678\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 142.8500 - hamming_loss: 0.6700 - val_loss: 81.8986 - val_hamming_loss: 0.6678\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 146.5423 - hamming_loss: 0.6713 - val_loss: 84.1625 - val_hamming_loss: 0.6678\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 144.1227 - hamming_loss: 0.6731 - val_loss: 85.3530 - val_hamming_loss: 0.6678\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 143.1309 - hamming_loss: 0.6709 - val_loss: 86.1339 - val_hamming_loss: 0.6678\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 143.5202 - hamming_loss: 0.6696 - val_loss: 87.8506 - val_hamming_loss: 0.6678\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 161.3534 - hamming_loss: 0.6709 - val_loss: 90.2468 - val_hamming_loss: 0.6678\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 156.1114 - hamming_loss: 0.6709 - val_loss: 92.4524 - val_hamming_loss: 0.6678\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001 = model_ce_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_ce_FF_lr001_df = pd.DataFrame(history_ce_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr001.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_ce_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "ce_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward BP-MLL Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the bp-mll loss network \n",
    "tf.random.set_seed(123)\n",
    "model_bpmll_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_bpmll_FF.compile(optimizer = optim_func,\n",
    "              loss = bp_mll_loss, metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 2s - loss: 0.9794 - hamming_loss: 0.5370 - val_loss: 0.9620 - val_hamming_loss: 0.4353\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9434 - hamming_loss: 0.4270 - val_loss: 0.9439 - val_hamming_loss: 0.4038\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9161 - hamming_loss: 0.3934 - val_loss: 0.9250 - val_hamming_loss: 0.3802\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.8863 - hamming_loss: 0.3571 - val_loss: 0.9059 - val_hamming_loss: 0.3531\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.8618 - hamming_loss: 0.3536 - val_loss: 0.8866 - val_hamming_loss: 0.3304\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.8277 - hamming_loss: 0.3252 - val_loss: 0.8678 - val_hamming_loss: 0.2990\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.8053 - hamming_loss: 0.3055 - val_loss: 0.8489 - val_hamming_loss: 0.2788\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.7880 - hamming_loss: 0.2898 - val_loss: 0.8311 - val_hamming_loss: 0.2570\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.7562 - hamming_loss: 0.2745 - val_loss: 0.8144 - val_hamming_loss: 0.2439\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.7367 - hamming_loss: 0.2461 - val_loss: 0.7990 - val_hamming_loss: 0.2343\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.7198 - hamming_loss: 0.2456 - val_loss: 0.7848 - val_hamming_loss: 0.2229\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.7032 - hamming_loss: 0.2242 - val_loss: 0.7720 - val_hamming_loss: 0.2177\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.6897 - hamming_loss: 0.2198 - val_loss: 0.7602 - val_hamming_loss: 0.2124\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.6717 - hamming_loss: 0.2041 - val_loss: 0.7493 - val_hamming_loss: 0.2089\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.6544 - hamming_loss: 0.1958 - val_loss: 0.7394 - val_hamming_loss: 0.2045\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.6414 - hamming_loss: 0.1923 - val_loss: 0.7305 - val_hamming_loss: 0.2010\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.6338 - hamming_loss: 0.1836 - val_loss: 0.7223 - val_hamming_loss: 0.1976\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.6170 - hamming_loss: 0.1792 - val_loss: 0.7148 - val_hamming_loss: 0.1949\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.6047 - hamming_loss: 0.1639 - val_loss: 0.7079 - val_hamming_loss: 0.1949\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.6008 - hamming_loss: 0.1726 - val_loss: 0.7017 - val_hamming_loss: 0.1932\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.5838 - hamming_loss: 0.1569 - val_loss: 0.6960 - val_hamming_loss: 0.1888\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.5825 - hamming_loss: 0.1469 - val_loss: 0.6906 - val_hamming_loss: 0.1871\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.5759 - hamming_loss: 0.1469 - val_loss: 0.6857 - val_hamming_loss: 0.1862\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.5687 - hamming_loss: 0.1464 - val_loss: 0.6813 - val_hamming_loss: 0.1844\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.5640 - hamming_loss: 0.1517 - val_loss: 0.6773 - val_hamming_loss: 0.1809\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.5607 - hamming_loss: 0.1394 - val_loss: 0.6735 - val_hamming_loss: 0.1774\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.5349 - hamming_loss: 0.1167 - val_loss: 0.6700 - val_hamming_loss: 0.1740\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.5414 - hamming_loss: 0.1267 - val_loss: 0.6668 - val_hamming_loss: 0.1705\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.5414 - hamming_loss: 0.1241 - val_loss: 0.6635 - val_hamming_loss: 0.1705\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.5340 - hamming_loss: 0.1241 - val_loss: 0.6607 - val_hamming_loss: 0.1652\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.5239 - hamming_loss: 0.1145 - val_loss: 0.6587 - val_hamming_loss: 0.1661\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.5190 - hamming_loss: 0.1036 - val_loss: 0.6569 - val_hamming_loss: 0.1635\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.5229 - hamming_loss: 0.1180 - val_loss: 0.6550 - val_hamming_loss: 0.1626\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.5117 - hamming_loss: 0.1014 - val_loss: 0.6531 - val_hamming_loss: 0.1626\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.5064 - hamming_loss: 0.1045 - val_loss: 0.6518 - val_hamming_loss: 0.1600\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.5144 - hamming_loss: 0.1115 - val_loss: 0.6503 - val_hamming_loss: 0.1591\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.5041 - hamming_loss: 0.0970 - val_loss: 0.6485 - val_hamming_loss: 0.1591\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.4913 - hamming_loss: 0.0935 - val_loss: 0.6466 - val_hamming_loss: 0.1582\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.4966 - hamming_loss: 0.0909 - val_loss: 0.6451 - val_hamming_loss: 0.1582\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.4917 - hamming_loss: 0.0957 - val_loss: 0.6435 - val_hamming_loss: 0.1582\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.4862 - hamming_loss: 0.0839 - val_loss: 0.6420 - val_hamming_loss: 0.1582\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.4896 - hamming_loss: 0.0918 - val_loss: 0.6404 - val_hamming_loss: 0.1582\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.4854 - hamming_loss: 0.0892 - val_loss: 0.6393 - val_hamming_loss: 0.1556\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.4742 - hamming_loss: 0.0817 - val_loss: 0.6388 - val_hamming_loss: 0.1556\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.4834 - hamming_loss: 0.0909 - val_loss: 0.6382 - val_hamming_loss: 0.1538\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.4903 - hamming_loss: 0.0909 - val_loss: 0.6377 - val_hamming_loss: 0.1521\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.4819 - hamming_loss: 0.0830 - val_loss: 0.6372 - val_hamming_loss: 0.1530\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.4780 - hamming_loss: 0.0857 - val_loss: 0.6363 - val_hamming_loss: 0.1530\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.4694 - hamming_loss: 0.0800 - val_loss: 0.6353 - val_hamming_loss: 0.1521\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.4758 - hamming_loss: 0.0870 - val_loss: 0.6342 - val_hamming_loss: 0.1486\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.4766 - hamming_loss: 0.0830 - val_loss: 0.6338 - val_hamming_loss: 0.1486\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.4698 - hamming_loss: 0.0795 - val_loss: 0.6337 - val_hamming_loss: 0.1495\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.4609 - hamming_loss: 0.0712 - val_loss: 0.6336 - val_hamming_loss: 0.1495\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.4731 - hamming_loss: 0.0870 - val_loss: 0.6333 - val_hamming_loss: 0.1512\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.4705 - hamming_loss: 0.0787 - val_loss: 0.6327 - val_hamming_loss: 0.1495\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.4615 - hamming_loss: 0.0717 - val_loss: 0.6323 - val_hamming_loss: 0.1486\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.4641 - hamming_loss: 0.0734 - val_loss: 0.6321 - val_hamming_loss: 0.1477\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.4619 - hamming_loss: 0.0760 - val_loss: 0.6320 - val_hamming_loss: 0.1477\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.4614 - hamming_loss: 0.0699 - val_loss: 0.6316 - val_hamming_loss: 0.1477\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.4562 - hamming_loss: 0.0717 - val_loss: 0.6317 - val_hamming_loss: 0.1477\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.4612 - hamming_loss: 0.0673 - val_loss: 0.6319 - val_hamming_loss: 0.1486\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.4564 - hamming_loss: 0.0739 - val_loss: 0.6318 - val_hamming_loss: 0.1495\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.4606 - hamming_loss: 0.0712 - val_loss: 0.6312 - val_hamming_loss: 0.1486\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.4539 - hamming_loss: 0.0699 - val_loss: 0.6309 - val_hamming_loss: 0.1477\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.4547 - hamming_loss: 0.0726 - val_loss: 0.6306 - val_hamming_loss: 0.1477\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.4539 - hamming_loss: 0.0695 - val_loss: 0.6308 - val_hamming_loss: 0.1469\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.4486 - hamming_loss: 0.0660 - val_loss: 0.6312 - val_hamming_loss: 0.1460\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.4569 - hamming_loss: 0.0721 - val_loss: 0.6315 - val_hamming_loss: 0.1460\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.4590 - hamming_loss: 0.0734 - val_loss: 0.6315 - val_hamming_loss: 0.1460\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.4536 - hamming_loss: 0.0634 - val_loss: 0.6312 - val_hamming_loss: 0.1451\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.4435 - hamming_loss: 0.0660 - val_loss: 0.6309 - val_hamming_loss: 0.1442\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.4471 - hamming_loss: 0.0642 - val_loss: 0.6308 - val_hamming_loss: 0.1442\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.4505 - hamming_loss: 0.0677 - val_loss: 0.6305 - val_hamming_loss: 0.1434\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.4561 - hamming_loss: 0.0699 - val_loss: 0.6301 - val_hamming_loss: 0.1442\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.4476 - hamming_loss: 0.0629 - val_loss: 0.6297 - val_hamming_loss: 0.1451\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.4526 - hamming_loss: 0.0699 - val_loss: 0.6295 - val_hamming_loss: 0.1442\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.4433 - hamming_loss: 0.0621 - val_loss: 0.6294 - val_hamming_loss: 0.1434\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.4488 - hamming_loss: 0.0647 - val_loss: 0.6290 - val_hamming_loss: 0.1434\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.4462 - hamming_loss: 0.0660 - val_loss: 0.6288 - val_hamming_loss: 0.1425\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.4451 - hamming_loss: 0.0669 - val_loss: 0.6288 - val_hamming_loss: 0.1425\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.4449 - hamming_loss: 0.0642 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.4394 - hamming_loss: 0.0559 - val_loss: 0.6287 - val_hamming_loss: 0.1425\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.4395 - hamming_loss: 0.0573 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.4448 - hamming_loss: 0.0651 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.4436 - hamming_loss: 0.0594 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.4466 - hamming_loss: 0.0664 - val_loss: 0.6287 - val_hamming_loss: 0.1425\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.4359 - hamming_loss: 0.0586 - val_loss: 0.6290 - val_hamming_loss: 0.1434\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.4428 - hamming_loss: 0.0625 - val_loss: 0.6288 - val_hamming_loss: 0.1451\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.4382 - hamming_loss: 0.0608 - val_loss: 0.6289 - val_hamming_loss: 0.1451\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.4415 - hamming_loss: 0.0673 - val_loss: 0.6286 - val_hamming_loss: 0.1451\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.4432 - hamming_loss: 0.0660 - val_loss: 0.6284 - val_hamming_loss: 0.1451\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.4380 - hamming_loss: 0.0612 - val_loss: 0.6284 - val_hamming_loss: 0.1451\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.4341 - hamming_loss: 0.0581 - val_loss: 0.6280 - val_hamming_loss: 0.1451\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.4358 - hamming_loss: 0.0612 - val_loss: 0.6282 - val_hamming_loss: 0.1434\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.4363 - hamming_loss: 0.0564 - val_loss: 0.6281 - val_hamming_loss: 0.1434\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.4431 - hamming_loss: 0.0647 - val_loss: 0.6284 - val_hamming_loss: 0.1442\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.4430 - hamming_loss: 0.0712 - val_loss: 0.6284 - val_hamming_loss: 0.1442\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.4377 - hamming_loss: 0.0621 - val_loss: 0.6279 - val_hamming_loss: 0.1434\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.4452 - hamming_loss: 0.0621 - val_loss: 0.6278 - val_hamming_loss: 0.1434\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.4429 - hamming_loss: 0.0664 - val_loss: 0.6280 - val_hamming_loss: 0.1434\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_FF_lr001 = model_bpmll_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_bpmll_FF_lr001_df = pd.DataFrame(history_bpmll_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL Feed Forward/history_bpmll_FF_lr001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_bpmll_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object_reduced = open('../RNN Text Categorization/RNN_data_dict_reduced.json',)\n",
    "RNN_data_dict_reduced = json.load(file_object_reduced)\n",
    "RNN_data_dict_reduced = ast.literal_eval(RNN_data_dict_reduced)\n",
    "train_padded_hasLabel = np.array(RNN_data_dict_reduced['train_padded_hasLabel'])\n",
    "test_padded_hasLabel = np.array(RNN_data_dict_reduced['test_padded_hasLabel'])\n",
    "Y_train_hasLabel = np.array(RNN_data_dict_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(RNN_data_dict_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bidirectional LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_bpmll_biLSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences = False, return_state = False)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_bpmll_biLSTM.compile(loss = bp_mll_loss, optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 9s - loss: 0.9963 - hamming_loss: 0.3636 - val_loss: 0.9916 - val_hamming_loss: 0.3759\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9869 - hamming_loss: 0.3431 - val_loss: 0.9820 - val_hamming_loss: 0.3549\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9746 - hamming_loss: 0.3475 - val_loss: 0.9679 - val_hamming_loss: 0.3584\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.9561 - hamming_loss: 0.3479 - val_loss: 0.9450 - val_hamming_loss: 0.3514\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.9259 - hamming_loss: 0.3230 - val_loss: 0.9044 - val_hamming_loss: 0.3042\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.8743 - hamming_loss: 0.3046 - val_loss: 0.8490 - val_hamming_loss: 0.3007\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.8240 - hamming_loss: 0.2985 - val_loss: 0.8097 - val_hamming_loss: 0.3007\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.7903 - hamming_loss: 0.2985 - val_loss: 0.7843 - val_hamming_loss: 0.3007\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.7678 - hamming_loss: 0.2985 - val_loss: 0.7658 - val_hamming_loss: 0.3007\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.7521 - hamming_loss: 0.2985 - val_loss: 0.7528 - val_hamming_loss: 0.3007\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.7408 - hamming_loss: 0.2985 - val_loss: 0.7438 - val_hamming_loss: 0.3007\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.7329 - hamming_loss: 0.2985 - val_loss: 0.7375 - val_hamming_loss: 0.3007\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.7267 - hamming_loss: 0.2985 - val_loss: 0.7325 - val_hamming_loss: 0.3007\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.7216 - hamming_loss: 0.2985 - val_loss: 0.7290 - val_hamming_loss: 0.3007\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.7173 - hamming_loss: 0.2985 - val_loss: 0.7253 - val_hamming_loss: 0.3007\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.7132 - hamming_loss: 0.2981 - val_loss: 0.7225 - val_hamming_loss: 0.3007\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.7090 - hamming_loss: 0.2946 - val_loss: 0.7198 - val_hamming_loss: 0.2998\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.7048 - hamming_loss: 0.2920 - val_loss: 0.7166 - val_hamming_loss: 0.2981\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.7004 - hamming_loss: 0.2902 - val_loss: 0.7141 - val_hamming_loss: 0.2981\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.6962 - hamming_loss: 0.2858 - val_loss: 0.7120 - val_hamming_loss: 0.2928\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.6916 - hamming_loss: 0.2592 - val_loss: 0.7090 - val_hamming_loss: 0.2771\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.6874 - hamming_loss: 0.2469 - val_loss: 0.7089 - val_hamming_loss: 0.2509\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.6834 - hamming_loss: 0.2356 - val_loss: 0.7086 - val_hamming_loss: 0.2465\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.6791 - hamming_loss: 0.2225 - val_loss: 0.7035 - val_hamming_loss: 0.2386\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.6738 - hamming_loss: 0.2128 - val_loss: 0.6994 - val_hamming_loss: 0.2360\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.6689 - hamming_loss: 0.2102 - val_loss: 0.7021 - val_hamming_loss: 0.2369\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.6644 - hamming_loss: 0.2067 - val_loss: 0.6952 - val_hamming_loss: 0.2351\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.6586 - hamming_loss: 0.1954 - val_loss: 0.6979 - val_hamming_loss: 0.2220\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.6533 - hamming_loss: 0.1731 - val_loss: 0.6938 - val_hamming_loss: 0.2142\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.6480 - hamming_loss: 0.1608 - val_loss: 0.6948 - val_hamming_loss: 0.2072\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.6428 - hamming_loss: 0.1565 - val_loss: 0.6915 - val_hamming_loss: 0.2150\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.6378 - hamming_loss: 0.1556 - val_loss: 0.6924 - val_hamming_loss: 0.2019\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.6332 - hamming_loss: 0.1534 - val_loss: 0.6900 - val_hamming_loss: 0.1993\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.6291 - hamming_loss: 0.1547 - val_loss: 0.6900 - val_hamming_loss: 0.2002\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.6248 - hamming_loss: 0.1582 - val_loss: 0.6929 - val_hamming_loss: 0.1949\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.6217 - hamming_loss: 0.1565 - val_loss: 0.6951 - val_hamming_loss: 0.1993\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.6182 - hamming_loss: 0.1543 - val_loss: 0.6962 - val_hamming_loss: 0.1976\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.6144 - hamming_loss: 0.1521 - val_loss: 0.6888 - val_hamming_loss: 0.2002\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.6106 - hamming_loss: 0.1521 - val_loss: 0.6866 - val_hamming_loss: 0.1984\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.6072 - hamming_loss: 0.1486 - val_loss: 0.6869 - val_hamming_loss: 0.2002\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.6041 - hamming_loss: 0.1486 - val_loss: 0.6909 - val_hamming_loss: 0.1932\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.6010 - hamming_loss: 0.1499 - val_loss: 0.6886 - val_hamming_loss: 0.1941\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.5980 - hamming_loss: 0.1486 - val_loss: 0.6884 - val_hamming_loss: 0.1976\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.5953 - hamming_loss: 0.1538 - val_loss: 0.6907 - val_hamming_loss: 0.1932\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.5933 - hamming_loss: 0.1565 - val_loss: 0.6943 - val_hamming_loss: 0.1949\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.5932 - hamming_loss: 0.1482 - val_loss: 0.6854 - val_hamming_loss: 0.1914\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.5898 - hamming_loss: 0.1521 - val_loss: 0.6937 - val_hamming_loss: 0.2133\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.5900 - hamming_loss: 0.1552 - val_loss: 0.6898 - val_hamming_loss: 0.1897\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.5859 - hamming_loss: 0.1490 - val_loss: 0.6921 - val_hamming_loss: 0.1879\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.5830 - hamming_loss: 0.1477 - val_loss: 0.6887 - val_hamming_loss: 0.1923\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.5805 - hamming_loss: 0.1508 - val_loss: 0.6881 - val_hamming_loss: 0.1906\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.5781 - hamming_loss: 0.1473 - val_loss: 0.6904 - val_hamming_loss: 0.1862\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.5760 - hamming_loss: 0.1451 - val_loss: 0.6875 - val_hamming_loss: 0.1906\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.5738 - hamming_loss: 0.1499 - val_loss: 0.6858 - val_hamming_loss: 0.1888\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.5716 - hamming_loss: 0.1464 - val_loss: 0.6877 - val_hamming_loss: 0.1871\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.5695 - hamming_loss: 0.1469 - val_loss: 0.6861 - val_hamming_loss: 0.1906\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.5674 - hamming_loss: 0.1442 - val_loss: 0.6876 - val_hamming_loss: 0.1897\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.5652 - hamming_loss: 0.1429 - val_loss: 0.6862 - val_hamming_loss: 0.1879\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.5631 - hamming_loss: 0.1416 - val_loss: 0.6857 - val_hamming_loss: 0.1888\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.5609 - hamming_loss: 0.1407 - val_loss: 0.6873 - val_hamming_loss: 0.1888\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.5587 - hamming_loss: 0.1381 - val_loss: 0.6854 - val_hamming_loss: 0.1879\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.5565 - hamming_loss: 0.1320 - val_loss: 0.6858 - val_hamming_loss: 0.1862\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.5544 - hamming_loss: 0.1307 - val_loss: 0.6832 - val_hamming_loss: 0.1853\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.5522 - hamming_loss: 0.1311 - val_loss: 0.6825 - val_hamming_loss: 0.1853\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.5502 - hamming_loss: 0.1307 - val_loss: 0.6848 - val_hamming_loss: 0.1836\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.5481 - hamming_loss: 0.1307 - val_loss: 0.6868 - val_hamming_loss: 0.1853\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.5460 - hamming_loss: 0.1281 - val_loss: 0.6838 - val_hamming_loss: 0.1836\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.5441 - hamming_loss: 0.1259 - val_loss: 0.6874 - val_hamming_loss: 0.1888\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.5421 - hamming_loss: 0.1237 - val_loss: 0.6880 - val_hamming_loss: 0.1844\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.5417 - hamming_loss: 0.1241 - val_loss: 0.6878 - val_hamming_loss: 0.1766\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.5396 - hamming_loss: 0.1206 - val_loss: 0.6957 - val_hamming_loss: 0.1888\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.5378 - hamming_loss: 0.1193 - val_loss: 0.6890 - val_hamming_loss: 0.1809\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.5361 - hamming_loss: 0.1136 - val_loss: 0.6818 - val_hamming_loss: 0.1897\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.5347 - hamming_loss: 0.1171 - val_loss: 0.6881 - val_hamming_loss: 0.1801\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.5317 - hamming_loss: 0.1084 - val_loss: 0.6916 - val_hamming_loss: 0.1801\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.5306 - hamming_loss: 0.1062 - val_loss: 0.6953 - val_hamming_loss: 0.1827\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.5288 - hamming_loss: 0.1036 - val_loss: 0.6929 - val_hamming_loss: 0.1836\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.5267 - hamming_loss: 0.1001 - val_loss: 0.6913 - val_hamming_loss: 0.1853\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.5247 - hamming_loss: 0.0948 - val_loss: 0.6890 - val_hamming_loss: 0.1783\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.5230 - hamming_loss: 0.0913 - val_loss: 0.6905 - val_hamming_loss: 0.1844\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.5212 - hamming_loss: 0.0896 - val_loss: 0.6870 - val_hamming_loss: 0.1792\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.5198 - hamming_loss: 0.0870 - val_loss: 0.6904 - val_hamming_loss: 0.1844\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.5180 - hamming_loss: 0.0865 - val_loss: 0.6857 - val_hamming_loss: 0.1774\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.5166 - hamming_loss: 0.0839 - val_loss: 0.6914 - val_hamming_loss: 0.1827\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.5151 - hamming_loss: 0.0848 - val_loss: 0.6873 - val_hamming_loss: 0.1748\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.5133 - hamming_loss: 0.0822 - val_loss: 0.6886 - val_hamming_loss: 0.1818\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.5118 - hamming_loss: 0.0809 - val_loss: 0.6867 - val_hamming_loss: 0.1748\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.5102 - hamming_loss: 0.0787 - val_loss: 0.6891 - val_hamming_loss: 0.1801\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.5088 - hamming_loss: 0.0787 - val_loss: 0.6851 - val_hamming_loss: 0.1705\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.5073 - hamming_loss: 0.0756 - val_loss: 0.6883 - val_hamming_loss: 0.1783\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.5060 - hamming_loss: 0.0774 - val_loss: 0.6857 - val_hamming_loss: 0.1713\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.5044 - hamming_loss: 0.0752 - val_loss: 0.6882 - val_hamming_loss: 0.1801\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.5029 - hamming_loss: 0.0752 - val_loss: 0.6835 - val_hamming_loss: 0.1696\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.5017 - hamming_loss: 0.0747 - val_loss: 0.6875 - val_hamming_loss: 0.1774\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.5001 - hamming_loss: 0.0721 - val_loss: 0.6853 - val_hamming_loss: 0.1705\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.4986 - hamming_loss: 0.0708 - val_loss: 0.6853 - val_hamming_loss: 0.1748\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.4969 - hamming_loss: 0.0712 - val_loss: 0.6884 - val_hamming_loss: 0.1731\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.4955 - hamming_loss: 0.0699 - val_loss: 0.6830 - val_hamming_loss: 0.1722\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.4942 - hamming_loss: 0.0677 - val_loss: 0.6890 - val_hamming_loss: 0.1722\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.4930 - hamming_loss: 0.0730 - val_loss: 0.6858 - val_hamming_loss: 0.1722\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_RNN_lr001 = model_bpmll_biLSTM.fit(train_padded_hasLabel, Y_train_hasLabel, epochs = 100, \n",
    "                       validation_data = (test_padded_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_bpmll_RNN_lr001_df = pd.DataFrame(history_bpmll_RNN_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL RNN/history_bpmll_RNN_lr001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_RNN_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_biLSTM.predict(train_padded_hasLabel)\n",
    "Y_test_pred = model_bpmll_biLSTM.predict(test_padded_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_RNN_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_lr001' : ce_FF_withThreshold,\n",
    "                                                        'bpmll_FF_lr001' : bpmll_FF_withThreshold,\n",
    "                                                        'bpmll_RNN_lr001' : bpmll_RNN_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "#with open(\"Reduced Data Eval Metrics/val_hamming_loss_withThreshold_lr001.json\", \"w\") as outfile: \n",
    "#    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_lr001</th>\n",
       "      <th>bpmll_FF_lr001</th>\n",
       "      <th>bpmll_RNN_lr001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.667832</td>\n",
       "      <td>0.257867</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_lr001  bpmll_FF_lr001  bpmll_RNN_lr001\n",
       "0     0.667832        0.257867         0.204545"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Full Dataset (some instances have no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the full tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data.json',)\n",
    "tfidf_data_full = json.load(file_object)\n",
    "X_train = np.array(tfidf_data_full['X_train'])\n",
    "X_test = np.array(tfidf_data_full['X_test'])\n",
    "Y_train = np.array(tfidf_data_full['Y_train'])\n",
    "Y_test = np.array(tfidf_data_full['Y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use same architecture as the previous cross-entropy feed-forward network and train on full dataset\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_ce_FF_full.compile(optimizer = optim_func,\n",
    "              loss = 'categorical_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 1s - loss: 7.5654 - hamming_loss: 0.3860 - val_loss: 7.6821 - val_hamming_loss: 0.4688\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 7.3172 - hamming_loss: 0.4687 - val_loss: 7.5401 - val_hamming_loss: 0.4704\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 7.1500 - hamming_loss: 0.4651 - val_loss: 7.4061 - val_hamming_loss: 0.4720\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 6.9570 - hamming_loss: 0.4580 - val_loss: 7.2831 - val_hamming_loss: 0.4720\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 7.0566 - hamming_loss: 0.4492 - val_loss: 7.1935 - val_hamming_loss: 0.4840\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 6.8512 - hamming_loss: 0.4675 - val_loss: 7.1488 - val_hamming_loss: 0.4848\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 6.7843 - hamming_loss: 0.4647 - val_loss: 7.1674 - val_hamming_loss: 0.4864\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 7.1565 - hamming_loss: 0.4496 - val_loss: 7.2623 - val_hamming_loss: 0.4952\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 7.3134 - hamming_loss: 0.4536 - val_loss: 7.4056 - val_hamming_loss: 0.5096\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 7.8009 - hamming_loss: 0.4695 - val_loss: 7.6080 - val_hamming_loss: 0.5353\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 8.0421 - hamming_loss: 0.4865 - val_loss: 7.8416 - val_hamming_loss: 0.5545\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 8.5979 - hamming_loss: 0.4933 - val_loss: 8.1062 - val_hamming_loss: 0.5857\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 9.1433 - hamming_loss: 0.5147 - val_loss: 8.4320 - val_hamming_loss: 0.6090\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 9.8529 - hamming_loss: 0.5361 - val_loss: 8.7806 - val_hamming_loss: 0.6330\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 9.2357 - hamming_loss: 0.5333 - val_loss: 9.0733 - val_hamming_loss: 0.6498\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 11.1736 - hamming_loss: 0.5484 - val_loss: 9.3325 - val_hamming_loss: 0.6667\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 10.3172 - hamming_loss: 0.5579 - val_loss: 9.6754 - val_hamming_loss: 0.6667\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 12.1385 - hamming_loss: 0.5777 - val_loss: 10.0285 - val_hamming_loss: 0.6707\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 12.3507 - hamming_loss: 0.5841 - val_loss: 10.4034 - val_hamming_loss: 0.6715\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 12.2390 - hamming_loss: 0.5924 - val_loss: 10.8095 - val_hamming_loss: 0.6715\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 13.4489 - hamming_loss: 0.6011 - val_loss: 11.2368 - val_hamming_loss: 0.6707\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 14.3731 - hamming_loss: 0.6086 - val_loss: 11.7476 - val_hamming_loss: 0.6707\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 14.0002 - hamming_loss: 0.6134 - val_loss: 12.2662 - val_hamming_loss: 0.6699\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 15.9412 - hamming_loss: 0.6162 - val_loss: 12.8550 - val_hamming_loss: 0.6731\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 17.0697 - hamming_loss: 0.6293 - val_loss: 13.4384 - val_hamming_loss: 0.6747\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 18.1300 - hamming_loss: 0.6261 - val_loss: 13.9589 - val_hamming_loss: 0.6747\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 17.4358 - hamming_loss: 0.6443 - val_loss: 14.5011 - val_hamming_loss: 0.6747\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 19.1775 - hamming_loss: 0.6376 - val_loss: 14.9891 - val_hamming_loss: 0.6755\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 21.6386 - hamming_loss: 0.6467 - val_loss: 15.5957 - val_hamming_loss: 0.6763\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 21.6577 - hamming_loss: 0.6416 - val_loss: 16.3615 - val_hamming_loss: 0.6771\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 22.3296 - hamming_loss: 0.6519 - val_loss: 16.9817 - val_hamming_loss: 0.6787\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 23.1938 - hamming_loss: 0.6562 - val_loss: 17.6736 - val_hamming_loss: 0.6819\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 24.4677 - hamming_loss: 0.6554 - val_loss: 18.3486 - val_hamming_loss: 0.6827\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 24.6226 - hamming_loss: 0.6554 - val_loss: 19.2268 - val_hamming_loss: 0.6827\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 27.5758 - hamming_loss: 0.6649 - val_loss: 20.2849 - val_hamming_loss: 0.6843\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 30.2529 - hamming_loss: 0.6649 - val_loss: 21.1376 - val_hamming_loss: 0.6843\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 28.9700 - hamming_loss: 0.6685 - val_loss: 22.0914 - val_hamming_loss: 0.6843\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 30.3138 - hamming_loss: 0.6657 - val_loss: 22.7216 - val_hamming_loss: 0.6843\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 32.6873 - hamming_loss: 0.6665 - val_loss: 23.3517 - val_hamming_loss: 0.6843\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 34.1562 - hamming_loss: 0.6681 - val_loss: 24.1963 - val_hamming_loss: 0.6851\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 34.8980 - hamming_loss: 0.6685 - val_loss: 24.7568 - val_hamming_loss: 0.6851\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 38.5688 - hamming_loss: 0.6701 - val_loss: 25.0877 - val_hamming_loss: 0.6851\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 37.8322 - hamming_loss: 0.6761 - val_loss: 25.6250 - val_hamming_loss: 0.6851\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 39.8058 - hamming_loss: 0.6741 - val_loss: 26.2200 - val_hamming_loss: 0.6851\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 39.8462 - hamming_loss: 0.6784 - val_loss: 27.0397 - val_hamming_loss: 0.6851\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 41.2372 - hamming_loss: 0.6737 - val_loss: 28.1409 - val_hamming_loss: 0.6851\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 42.5813 - hamming_loss: 0.6820 - val_loss: 29.3541 - val_hamming_loss: 0.6851\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 41.6405 - hamming_loss: 0.6780 - val_loss: 30.4890 - val_hamming_loss: 0.6851\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 45.3296 - hamming_loss: 0.6812 - val_loss: 31.7031 - val_hamming_loss: 0.6851\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 47.8563 - hamming_loss: 0.6804 - val_loss: 32.4795 - val_hamming_loss: 0.6851\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 48.6805 - hamming_loss: 0.6832 - val_loss: 33.2745 - val_hamming_loss: 0.6851\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 51.3652 - hamming_loss: 0.6852 - val_loss: 34.1098 - val_hamming_loss: 0.6851\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 53.8589 - hamming_loss: 0.6784 - val_loss: 34.8115 - val_hamming_loss: 0.6851\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 54.4712 - hamming_loss: 0.6883 - val_loss: 35.5149 - val_hamming_loss: 0.6851\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 57.3991 - hamming_loss: 0.6860 - val_loss: 36.3353 - val_hamming_loss: 0.6851\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 56.5742 - hamming_loss: 0.6891 - val_loss: 37.0564 - val_hamming_loss: 0.6851\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 57.5846 - hamming_loss: 0.6899 - val_loss: 38.1524 - val_hamming_loss: 0.6851\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 58.0918 - hamming_loss: 0.6899 - val_loss: 39.7227 - val_hamming_loss: 0.6851\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 59.1541 - hamming_loss: 0.6907 - val_loss: 41.6149 - val_hamming_loss: 0.6851\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 63.5539 - hamming_loss: 0.6915 - val_loss: 43.1342 - val_hamming_loss: 0.6851\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 63.1892 - hamming_loss: 0.6899 - val_loss: 44.2815 - val_hamming_loss: 0.6851\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 65.5867 - hamming_loss: 0.6915 - val_loss: 45.1793 - val_hamming_loss: 0.6851\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 66.8557 - hamming_loss: 0.6915 - val_loss: 45.4726 - val_hamming_loss: 0.6851\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 68.4876 - hamming_loss: 0.6899 - val_loss: 45.5977 - val_hamming_loss: 0.6859\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 68.7931 - hamming_loss: 0.6903 - val_loss: 45.3649 - val_hamming_loss: 0.6859\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 69.3431 - hamming_loss: 0.6911 - val_loss: 46.0655 - val_hamming_loss: 0.6859\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 70.1231 - hamming_loss: 0.6911 - val_loss: 46.8151 - val_hamming_loss: 0.6859\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 74.5338 - hamming_loss: 0.6911 - val_loss: 47.7584 - val_hamming_loss: 0.6859\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 76.0830 - hamming_loss: 0.6911 - val_loss: 49.0384 - val_hamming_loss: 0.6859\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 77.3926 - hamming_loss: 0.6931 - val_loss: 50.1841 - val_hamming_loss: 0.6859\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 87.3831 - hamming_loss: 0.6939 - val_loss: 52.4770 - val_hamming_loss: 0.6859\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 84.5637 - hamming_loss: 0.6899 - val_loss: 54.4090 - val_hamming_loss: 0.6859\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 82.5973 - hamming_loss: 0.6923 - val_loss: 56.2031 - val_hamming_loss: 0.6859\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 89.0014 - hamming_loss: 0.6923 - val_loss: 58.4089 - val_hamming_loss: 0.6859\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 90.5516 - hamming_loss: 0.6923 - val_loss: 59.7425 - val_hamming_loss: 0.6859\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 94.5299 - hamming_loss: 0.6923 - val_loss: 60.9781 - val_hamming_loss: 0.6859\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 95.3213 - hamming_loss: 0.6935 - val_loss: 61.6470 - val_hamming_loss: 0.6859\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 93.2411 - hamming_loss: 0.6955 - val_loss: 61.8630 - val_hamming_loss: 0.6859\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 88.6811 - hamming_loss: 0.6919 - val_loss: 61.6929 - val_hamming_loss: 0.6859\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 102.8422 - hamming_loss: 0.6939 - val_loss: 63.0030 - val_hamming_loss: 0.6851\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 100.1017 - hamming_loss: 0.6935 - val_loss: 64.7545 - val_hamming_loss: 0.6851\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 102.1717 - hamming_loss: 0.6939 - val_loss: 66.6338 - val_hamming_loss: 0.6851\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 101.9129 - hamming_loss: 0.6935 - val_loss: 67.6546 - val_hamming_loss: 0.6851\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 102.3964 - hamming_loss: 0.6931 - val_loss: 68.7386 - val_hamming_loss: 0.6851\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 108.3802 - hamming_loss: 0.6931 - val_loss: 69.7109 - val_hamming_loss: 0.6851\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 111.0580 - hamming_loss: 0.6939 - val_loss: 71.2492 - val_hamming_loss: 0.6851\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 113.2997 - hamming_loss: 0.6923 - val_loss: 72.5786 - val_hamming_loss: 0.6851\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 110.9177 - hamming_loss: 0.6943 - val_loss: 74.2724 - val_hamming_loss: 0.6851\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 108.4564 - hamming_loss: 0.6931 - val_loss: 74.9319 - val_hamming_loss: 0.6851\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 114.8433 - hamming_loss: 0.6935 - val_loss: 75.6565 - val_hamming_loss: 0.6851\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 119.8325 - hamming_loss: 0.6939 - val_loss: 76.2432 - val_hamming_loss: 0.6851\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 118.3012 - hamming_loss: 0.6943 - val_loss: 77.0995 - val_hamming_loss: 0.6851\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 124.8925 - hamming_loss: 0.6927 - val_loss: 78.3342 - val_hamming_loss: 0.6851\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 118.8325 - hamming_loss: 0.6919 - val_loss: 79.8700 - val_hamming_loss: 0.6851\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 123.9742 - hamming_loss: 0.6927 - val_loss: 81.8096 - val_hamming_loss: 0.6851\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 125.4325 - hamming_loss: 0.6935 - val_loss: 83.7716 - val_hamming_loss: 0.6851\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 127.0410 - hamming_loss: 0.6935 - val_loss: 85.3973 - val_hamming_loss: 0.6851\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 129.6431 - hamming_loss: 0.6935 - val_loss: 86.3015 - val_hamming_loss: 0.6851\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 127.0651 - hamming_loss: 0.6935 - val_loss: 87.8357 - val_hamming_loss: 0.6851\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 127.1041 - hamming_loss: 0.6951 - val_loss: 89.7325 - val_hamming_loss: 0.6851\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001_full = model_ce_FF_full.fit(X_train, Y_train, epochs = 100,\n",
    "                validation_data = (X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_FF_lr001_full_df = pd.DataFrame(history_ce_FF_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF_full.predict(X_train)\n",
    "Y_test_pred = model_ce_FF_full.predict(X_test)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_FF_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Reccurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object = open('../RNN Text Categorization/RNN_data_dict.json',)\n",
    "RNN_data_dict = json.load(file_object)\n",
    "RNN_data_dict = ast.literal_eval(RNN_data_dict)\n",
    "train_padded = np.array(RNN_data_dict['train_padded'])\n",
    "test_padded = np.array(RNN_data_dict['test_padded'])\n",
    "Y_train = np.array(RNN_data_dict['Y_train'])\n",
    "Y_test = np.array(RNN_data_dict['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_LSTM_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.LSTM(16, return_sequences = False, return_state = False),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_LSTM_full.compile(loss = 'categorical_crossentropy', optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 6s - loss: 7.6843 - hamming_loss: 0.5867 - val_loss: 7.9091 - val_hamming_loss: 0.4639\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 7.6235 - hamming_loss: 0.5052 - val_loss: 7.8395 - val_hamming_loss: 0.5393\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 7.5496 - hamming_loss: 0.5551 - val_loss: 7.7410 - val_hamming_loss: 0.5393\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 7.4440 - hamming_loss: 0.5551 - val_loss: 7.5849 - val_hamming_loss: 0.5393\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 7.2851 - hamming_loss: 0.5551 - val_loss: 7.3702 - val_hamming_loss: 0.5777\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 7.0946 - hamming_loss: 0.5440 - val_loss: 7.1429 - val_hamming_loss: 0.5024\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 6.9162 - hamming_loss: 0.5186 - val_loss: 6.9666 - val_hamming_loss: 0.5024\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 6.7968 - hamming_loss: 0.5186 - val_loss: 6.8954 - val_hamming_loss: 0.5024\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 6.7634 - hamming_loss: 0.5186 - val_loss: 6.8984 - val_hamming_loss: 0.5024\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 6.7741 - hamming_loss: 0.5186 - val_loss: 6.9197 - val_hamming_loss: 0.5024\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 6.7983 - hamming_loss: 0.5186 - val_loss: 6.9437 - val_hamming_loss: 0.5024\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 6.8210 - hamming_loss: 0.5385 - val_loss: 6.9651 - val_hamming_loss: 0.5473\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 6.8543 - hamming_loss: 0.5472 - val_loss: 6.9933 - val_hamming_loss: 0.5473\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 6.8938 - hamming_loss: 0.5472 - val_loss: 7.0285 - val_hamming_loss: 0.5473\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 6.9310 - hamming_loss: 0.5472 - val_loss: 7.0545 - val_hamming_loss: 0.5473\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 6.9593 - hamming_loss: 0.5472 - val_loss: 7.0882 - val_hamming_loss: 0.5473\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 7.0100 - hamming_loss: 0.5472 - val_loss: 7.1381 - val_hamming_loss: 0.5473\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 7.0590 - hamming_loss: 0.5472 - val_loss: 7.1815 - val_hamming_loss: 0.6098\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 7.0997 - hamming_loss: 0.6170 - val_loss: 7.2089 - val_hamming_loss: 0.6098\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 7.1256 - hamming_loss: 0.6170 - val_loss: 7.2256 - val_hamming_loss: 0.6098\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 7.1425 - hamming_loss: 0.6170 - val_loss: 7.2461 - val_hamming_loss: 0.6098\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 7.1635 - hamming_loss: 0.6170 - val_loss: 7.2692 - val_hamming_loss: 0.6098\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 7.1823 - hamming_loss: 0.6170 - val_loss: 7.2932 - val_hamming_loss: 0.6098\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 7.2033 - hamming_loss: 0.6170 - val_loss: 7.3229 - val_hamming_loss: 0.6098\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 7.2317 - hamming_loss: 0.6170 - val_loss: 7.3518 - val_hamming_loss: 0.6098\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 7.2490 - hamming_loss: 0.6170 - val_loss: 7.3610 - val_hamming_loss: 0.6098\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 7.2550 - hamming_loss: 0.6170 - val_loss: 7.3680 - val_hamming_loss: 0.6098\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 7.2537 - hamming_loss: 0.6170 - val_loss: 7.3690 - val_hamming_loss: 0.6098\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 7.2505 - hamming_loss: 0.6170 - val_loss: 7.3745 - val_hamming_loss: 0.6098\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 7.2510 - hamming_loss: 0.6170 - val_loss: 7.3871 - val_hamming_loss: 0.6098\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 7.2563 - hamming_loss: 0.6170 - val_loss: 7.4025 - val_hamming_loss: 0.6098\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 7.2697 - hamming_loss: 0.6170 - val_loss: 7.4241 - val_hamming_loss: 0.6098\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 7.2826 - hamming_loss: 0.6170 - val_loss: 7.4378 - val_hamming_loss: 0.6098\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 7.2896 - hamming_loss: 0.6170 - val_loss: 7.4480 - val_hamming_loss: 0.6098\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 7.3011 - hamming_loss: 0.6170 - val_loss: 7.4657 - val_hamming_loss: 0.6098\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 7.3188 - hamming_loss: 0.6170 - val_loss: 7.4835 - val_hamming_loss: 0.6098\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 7.3306 - hamming_loss: 0.6170 - val_loss: 7.4944 - val_hamming_loss: 0.6098\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 7.3442 - hamming_loss: 0.6170 - val_loss: 7.5126 - val_hamming_loss: 0.6098\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 7.3585 - hamming_loss: 0.6170 - val_loss: 7.5231 - val_hamming_loss: 0.6098\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 7.3684 - hamming_loss: 0.6178 - val_loss: 7.5278 - val_hamming_loss: 0.6851\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 7.3715 - hamming_loss: 0.6931 - val_loss: 7.5355 - val_hamming_loss: 0.6851\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 7.3801 - hamming_loss: 0.6931 - val_loss: 7.5495 - val_hamming_loss: 0.6851\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 7.3839 - hamming_loss: 0.6931 - val_loss: 7.5553 - val_hamming_loss: 0.6851\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 7.3863 - hamming_loss: 0.6931 - val_loss: 7.5633 - val_hamming_loss: 0.6851\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 7.3893 - hamming_loss: 0.6931 - val_loss: 7.5676 - val_hamming_loss: 0.6851\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 7.3850 - hamming_loss: 0.6931 - val_loss: 7.5598 - val_hamming_loss: 0.6851\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 7.3798 - hamming_loss: 0.6931 - val_loss: 7.5632 - val_hamming_loss: 0.6851\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 7.3809 - hamming_loss: 0.6931 - val_loss: 7.5732 - val_hamming_loss: 0.6851\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 7.3874 - hamming_loss: 0.6931 - val_loss: 7.5852 - val_hamming_loss: 0.6851\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 7.4017 - hamming_loss: 0.6931 - val_loss: 7.6056 - val_hamming_loss: 0.6851\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 7.4149 - hamming_loss: 0.6931 - val_loss: 7.6211 - val_hamming_loss: 0.6851\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 7.4262 - hamming_loss: 0.6931 - val_loss: 7.6356 - val_hamming_loss: 0.6851\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 7.4302 - hamming_loss: 0.6931 - val_loss: 7.6374 - val_hamming_loss: 0.6851\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 7.4322 - hamming_loss: 0.6931 - val_loss: 7.6457 - val_hamming_loss: 0.6851\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 7.4377 - hamming_loss: 0.6931 - val_loss: 7.6515 - val_hamming_loss: 0.6851\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 7.4384 - hamming_loss: 0.6931 - val_loss: 7.6531 - val_hamming_loss: 0.6851\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 7.4493 - hamming_loss: 0.6931 - val_loss: 7.6747 - val_hamming_loss: 0.6851\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 7.4684 - hamming_loss: 0.6931 - val_loss: 7.6977 - val_hamming_loss: 0.6851\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 7.4884 - hamming_loss: 0.6931 - val_loss: 7.7173 - val_hamming_loss: 0.6851\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 7.4979 - hamming_loss: 0.6931 - val_loss: 7.7261 - val_hamming_loss: 0.6851\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 7.5072 - hamming_loss: 0.6931 - val_loss: 7.7416 - val_hamming_loss: 0.6851\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 7.5155 - hamming_loss: 0.6931 - val_loss: 7.7490 - val_hamming_loss: 0.6851\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 7.5205 - hamming_loss: 0.6931 - val_loss: 7.7560 - val_hamming_loss: 0.6851\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 7.5253 - hamming_loss: 0.6931 - val_loss: 7.7651 - val_hamming_loss: 0.6851\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 7.5354 - hamming_loss: 0.6931 - val_loss: 7.7788 - val_hamming_loss: 0.6851\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 7.5513 - hamming_loss: 0.6931 - val_loss: 7.7946 - val_hamming_loss: 0.6851\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 7.5561 - hamming_loss: 0.6931 - val_loss: 7.7956 - val_hamming_loss: 0.6851\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 7.5572 - hamming_loss: 0.6931 - val_loss: 7.8036 - val_hamming_loss: 0.6851\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 7.5617 - hamming_loss: 0.6931 - val_loss: 7.8136 - val_hamming_loss: 0.6851\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 7.5720 - hamming_loss: 0.6931 - val_loss: 7.8310 - val_hamming_loss: 0.6851\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 7.5864 - hamming_loss: 0.6931 - val_loss: 7.8483 - val_hamming_loss: 0.6851\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 7.6026 - hamming_loss: 0.6931 - val_loss: 7.8722 - val_hamming_loss: 0.6851\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 7.6222 - hamming_loss: 0.6931 - val_loss: 7.8973 - val_hamming_loss: 0.6851\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 7.6438 - hamming_loss: 0.6931 - val_loss: 7.9232 - val_hamming_loss: 0.6851\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 7.6676 - hamming_loss: 0.6931 - val_loss: 7.9466 - val_hamming_loss: 0.6851\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 7.6914 - hamming_loss: 0.6931 - val_loss: 7.9701 - val_hamming_loss: 0.6851\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 7.7044 - hamming_loss: 0.6931 - val_loss: 7.9741 - val_hamming_loss: 0.6851\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 7.7050 - hamming_loss: 0.6931 - val_loss: 7.9720 - val_hamming_loss: 0.6851\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 7.7086 - hamming_loss: 0.6931 - val_loss: 7.9795 - val_hamming_loss: 0.6851\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 7.7094 - hamming_loss: 0.6931 - val_loss: 7.9834 - val_hamming_loss: 0.6851\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 7.7136 - hamming_loss: 0.6931 - val_loss: 7.9980 - val_hamming_loss: 0.6851\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 7.7243 - hamming_loss: 0.6931 - val_loss: 8.0070 - val_hamming_loss: 0.6851\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 7.7311 - hamming_loss: 0.6931 - val_loss: 8.0128 - val_hamming_loss: 0.6851\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 7.7310 - hamming_loss: 0.6931 - val_loss: 8.0115 - val_hamming_loss: 0.6851\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 7.7306 - hamming_loss: 0.6931 - val_loss: 8.0195 - val_hamming_loss: 0.6851\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 7.7404 - hamming_loss: 0.6931 - val_loss: 8.0365 - val_hamming_loss: 0.6851\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 7.7535 - hamming_loss: 0.6931 - val_loss: 8.0503 - val_hamming_loss: 0.6851\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 7.7629 - hamming_loss: 0.6931 - val_loss: 8.0649 - val_hamming_loss: 0.6851\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 7.7698 - hamming_loss: 0.6931 - val_loss: 8.0765 - val_hamming_loss: 0.6851\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 7.7785 - hamming_loss: 0.6931 - val_loss: 8.0876 - val_hamming_loss: 0.6851\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 7.7812 - hamming_loss: 0.6931 - val_loss: 8.0925 - val_hamming_loss: 0.6851\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 7.7829 - hamming_loss: 0.6931 - val_loss: 8.1008 - val_hamming_loss: 0.6851\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 7.7858 - hamming_loss: 0.6931 - val_loss: 8.1070 - val_hamming_loss: 0.6851\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 7.7883 - hamming_loss: 0.6931 - val_loss: 8.1104 - val_hamming_loss: 0.6851\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 7.7843 - hamming_loss: 0.6931 - val_loss: 8.1074 - val_hamming_loss: 0.6851\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 7.7860 - hamming_loss: 0.6931 - val_loss: 8.1149 - val_hamming_loss: 0.6851\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 7.7836 - hamming_loss: 0.6931 - val_loss: 8.1092 - val_hamming_loss: 0.6851\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 7.7790 - hamming_loss: 0.6931 - val_loss: 8.1169 - val_hamming_loss: 0.6851\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 7.7847 - hamming_loss: 0.6931 - val_loss: 8.1312 - val_hamming_loss: 0.6851\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 7.7938 - hamming_loss: 0.6931 - val_loss: 8.1453 - val_hamming_loss: 0.6851\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_RNN_lr001_full = model_LSTM_full.fit(train_padded, Y_train, epochs = 100, \n",
    "               validation_data = (test_padded, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_RNN_lr001_full_df = pd.DataFrame(history_ce_RNN_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy RNN/history_ce_RNN_lr001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_RNN_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_LSTM_full.predict(train_padded)\n",
    "Y_test_pred = model_LSTM_full.predict(test_padded)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_RNN_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23798076923076922"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_RNN_full_withThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_full_lr001' : ce_FF_full_withThreshold,\n",
    "                                                        'ce_RNN_full_lr001' : ce_RNN_full_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "with open(\"Full Data Eval Metrics/val_hamming_loss_withThreshold_lr001.json\", \"w\") as outfile: \n",
    "    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_full_lr001</th>\n",
       "      <th>ce_RNN_full_lr001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.678686</td>\n",
       "      <td>0.237981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_full_lr001  ce_RNN_full_lr001\n",
       "0          0.678686           0.237981"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
