{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Filename: Generate_ANN_Results.ipynb\n",
    "#\n",
    "# Purpose: Generate results from different ANN models trained on paragraph \n",
    "#          classification task\n",
    "#\n",
    "# Author(s): Bobby (Robert) Lumpkin\n",
    "#\n",
    "# Library Dependencies: numpy, pandas, tensorflow, bpmll, os, json, ast, random, \n",
    "#                       tensorflow_addons, skljson, sklearn, sys, threshold_learning\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Results from Different ANN Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from bpmll import bp_mll_loss\n",
    "import sklearn_json as skljson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "os.chdir('C:\\\\Users\\\\rober\\\\OneDrive\\\\Documents\\\\STAT 6500\\\\Project\\\\NewsArticleClassification\\\\codes\\\\ANN Results')  ## Set working directory\n",
    "                                                                                                                      ## to be 'ANN Results'\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the \n",
    "from threshold_learning import predict_labels_binary         ## threshold_learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Reduced Dataset (each instance has atleast one label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the reduced tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data_reduced.json',)\n",
    "tfidf_data_reduced = json.load(file_object)\n",
    "X_train_hasLabel = np.array(tfidf_data_reduced['X_train_hasLabel'])\n",
    "X_test_hasLabel = np.array(tfidf_data_reduced['X_test_hasLabel'])\n",
    "Y_train_hasLabel = np.array(tfidf_data_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(tfidf_data_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the cross-entropy loss network (bpmll used later)\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "metric = tfa.metrics.HammingLoss(mode = 'multilabel', threshold = 0.5)\n",
    "\n",
    "model_ce_FF.compile(optimizer = optim_func,\n",
    "              loss = 'binary_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 1s - loss: 0.7028 - hamming_loss: 0.4847 - val_loss: 0.6898 - val_hamming_loss: 0.4650\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.6970 - hamming_loss: 0.4742 - val_loss: 0.6878 - val_hamming_loss: 0.4572\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.6969 - hamming_loss: 0.4764 - val_loss: 0.6858 - val_hamming_loss: 0.4484\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.6936 - hamming_loss: 0.4642 - val_loss: 0.6838 - val_hamming_loss: 0.4414\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.6903 - hamming_loss: 0.4572 - val_loss: 0.6818 - val_hamming_loss: 0.4318\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.6836 - hamming_loss: 0.4489 - val_loss: 0.6799 - val_hamming_loss: 0.4274\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.6821 - hamming_loss: 0.4414 - val_loss: 0.6780 - val_hamming_loss: 0.4248\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.6825 - hamming_loss: 0.4427 - val_loss: 0.6761 - val_hamming_loss: 0.4205\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.6757 - hamming_loss: 0.4135 - val_loss: 0.6743 - val_hamming_loss: 0.4152\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.6670 - hamming_loss: 0.4091 - val_loss: 0.6724 - val_hamming_loss: 0.4082\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.6709 - hamming_loss: 0.4087 - val_loss: 0.6705 - val_hamming_loss: 0.4012\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.6657 - hamming_loss: 0.4126 - val_loss: 0.6686 - val_hamming_loss: 0.3942\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.6648 - hamming_loss: 0.3964 - val_loss: 0.6668 - val_hamming_loss: 0.3837\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.6559 - hamming_loss: 0.3776 - val_loss: 0.6649 - val_hamming_loss: 0.3794\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.6587 - hamming_loss: 0.3811 - val_loss: 0.6630 - val_hamming_loss: 0.3706\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.6551 - hamming_loss: 0.3767 - val_loss: 0.6611 - val_hamming_loss: 0.3654\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.6499 - hamming_loss: 0.3741 - val_loss: 0.6592 - val_hamming_loss: 0.3566\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.6474 - hamming_loss: 0.3580 - val_loss: 0.6573 - val_hamming_loss: 0.3523\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.6433 - hamming_loss: 0.3510 - val_loss: 0.6554 - val_hamming_loss: 0.3453\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.6441 - hamming_loss: 0.3501 - val_loss: 0.6535 - val_hamming_loss: 0.3392\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.6385 - hamming_loss: 0.3448 - val_loss: 0.6516 - val_hamming_loss: 0.3313\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.6348 - hamming_loss: 0.3326 - val_loss: 0.6497 - val_hamming_loss: 0.3260\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.6361 - hamming_loss: 0.3339 - val_loss: 0.6478 - val_hamming_loss: 0.3156\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.6341 - hamming_loss: 0.3352 - val_loss: 0.6459 - val_hamming_loss: 0.3138\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.6297 - hamming_loss: 0.3269 - val_loss: 0.6440 - val_hamming_loss: 0.3086\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.6267 - hamming_loss: 0.3147 - val_loss: 0.6420 - val_hamming_loss: 0.3033\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.6171 - hamming_loss: 0.3090 - val_loss: 0.6400 - val_hamming_loss: 0.2972\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.6220 - hamming_loss: 0.3204 - val_loss: 0.6380 - val_hamming_loss: 0.2955\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.6199 - hamming_loss: 0.3164 - val_loss: 0.6359 - val_hamming_loss: 0.2928\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.6075 - hamming_loss: 0.2858 - val_loss: 0.6339 - val_hamming_loss: 0.2885\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.6019 - hamming_loss: 0.2976 - val_loss: 0.6317 - val_hamming_loss: 0.2841\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.6088 - hamming_loss: 0.3073 - val_loss: 0.6295 - val_hamming_loss: 0.2815\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.6038 - hamming_loss: 0.2911 - val_loss: 0.6274 - val_hamming_loss: 0.2797\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.5995 - hamming_loss: 0.2832 - val_loss: 0.6252 - val_hamming_loss: 0.2788\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.5993 - hamming_loss: 0.2885 - val_loss: 0.6231 - val_hamming_loss: 0.2771\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.5996 - hamming_loss: 0.2972 - val_loss: 0.6209 - val_hamming_loss: 0.2762\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.5926 - hamming_loss: 0.2775 - val_loss: 0.6187 - val_hamming_loss: 0.2719\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.5895 - hamming_loss: 0.2810 - val_loss: 0.6165 - val_hamming_loss: 0.2692\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.5860 - hamming_loss: 0.2710 - val_loss: 0.6142 - val_hamming_loss: 0.2692\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.5845 - hamming_loss: 0.2666 - val_loss: 0.6119 - val_hamming_loss: 0.2666\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.5836 - hamming_loss: 0.2684 - val_loss: 0.6097 - val_hamming_loss: 0.2657\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.5820 - hamming_loss: 0.2688 - val_loss: 0.6074 - val_hamming_loss: 0.2640\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.5766 - hamming_loss: 0.2478 - val_loss: 0.6051 - val_hamming_loss: 0.2605\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.5689 - hamming_loss: 0.2526 - val_loss: 0.6027 - val_hamming_loss: 0.2552\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.5691 - hamming_loss: 0.2570 - val_loss: 0.6004 - val_hamming_loss: 0.2535\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.5695 - hamming_loss: 0.2653 - val_loss: 0.5981 - val_hamming_loss: 0.2535\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.5633 - hamming_loss: 0.2395 - val_loss: 0.5958 - val_hamming_loss: 0.2517\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.5536 - hamming_loss: 0.2343 - val_loss: 0.5934 - val_hamming_loss: 0.2465\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.5501 - hamming_loss: 0.2268 - val_loss: 0.5909 - val_hamming_loss: 0.2421\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.5601 - hamming_loss: 0.2461 - val_loss: 0.5886 - val_hamming_loss: 0.2395\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.5460 - hamming_loss: 0.2391 - val_loss: 0.5862 - val_hamming_loss: 0.2395\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.5441 - hamming_loss: 0.2334 - val_loss: 0.5839 - val_hamming_loss: 0.2386\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.5418 - hamming_loss: 0.2356 - val_loss: 0.5815 - val_hamming_loss: 0.2360\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.5415 - hamming_loss: 0.2351 - val_loss: 0.5792 - val_hamming_loss: 0.2325\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.5389 - hamming_loss: 0.2330 - val_loss: 0.5768 - val_hamming_loss: 0.2308\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.5391 - hamming_loss: 0.2299 - val_loss: 0.5745 - val_hamming_loss: 0.2308\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.5311 - hamming_loss: 0.2264 - val_loss: 0.5721 - val_hamming_loss: 0.2290\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.5304 - hamming_loss: 0.2247 - val_loss: 0.5697 - val_hamming_loss: 0.2290\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.5301 - hamming_loss: 0.2198 - val_loss: 0.5674 - val_hamming_loss: 0.2264\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.5215 - hamming_loss: 0.2124 - val_loss: 0.5651 - val_hamming_loss: 0.2255\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.5163 - hamming_loss: 0.2172 - val_loss: 0.5628 - val_hamming_loss: 0.2255\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.5165 - hamming_loss: 0.2159 - val_loss: 0.5605 - val_hamming_loss: 0.2247\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.5209 - hamming_loss: 0.2238 - val_loss: 0.5582 - val_hamming_loss: 0.2247\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.5172 - hamming_loss: 0.2163 - val_loss: 0.5559 - val_hamming_loss: 0.2255\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.5037 - hamming_loss: 0.2032 - val_loss: 0.5537 - val_hamming_loss: 0.2238\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.5044 - hamming_loss: 0.1989 - val_loss: 0.5514 - val_hamming_loss: 0.2212\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.5076 - hamming_loss: 0.2098 - val_loss: 0.5491 - val_hamming_loss: 0.2194\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.5066 - hamming_loss: 0.2032 - val_loss: 0.5470 - val_hamming_loss: 0.2203\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.5032 - hamming_loss: 0.1980 - val_loss: 0.5448 - val_hamming_loss: 0.2203\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.4897 - hamming_loss: 0.2032 - val_loss: 0.5426 - val_hamming_loss: 0.2185\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.4867 - hamming_loss: 0.2006 - val_loss: 0.5405 - val_hamming_loss: 0.2150\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.4865 - hamming_loss: 0.1980 - val_loss: 0.5383 - val_hamming_loss: 0.2142\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.4941 - hamming_loss: 0.2050 - val_loss: 0.5362 - val_hamming_loss: 0.2133\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.4873 - hamming_loss: 0.1901 - val_loss: 0.5341 - val_hamming_loss: 0.2124\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.4855 - hamming_loss: 0.2015 - val_loss: 0.5319 - val_hamming_loss: 0.2115\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.4857 - hamming_loss: 0.1993 - val_loss: 0.5298 - val_hamming_loss: 0.2115\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.4655 - hamming_loss: 0.1770 - val_loss: 0.5277 - val_hamming_loss: 0.2107\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.4769 - hamming_loss: 0.1906 - val_loss: 0.5256 - val_hamming_loss: 0.2089\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.4855 - hamming_loss: 0.2050 - val_loss: 0.5235 - val_hamming_loss: 0.2072\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.4750 - hamming_loss: 0.1971 - val_loss: 0.5215 - val_hamming_loss: 0.2045\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.4594 - hamming_loss: 0.1788 - val_loss: 0.5195 - val_hamming_loss: 0.2045\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.4640 - hamming_loss: 0.1823 - val_loss: 0.5175 - val_hamming_loss: 0.2002\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.4574 - hamming_loss: 0.1849 - val_loss: 0.5156 - val_hamming_loss: 0.1993\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.4538 - hamming_loss: 0.1696 - val_loss: 0.5136 - val_hamming_loss: 0.1967\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.4546 - hamming_loss: 0.1788 - val_loss: 0.5117 - val_hamming_loss: 0.1967\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.4556 - hamming_loss: 0.1805 - val_loss: 0.5098 - val_hamming_loss: 0.1941\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.4508 - hamming_loss: 0.1796 - val_loss: 0.5079 - val_hamming_loss: 0.1932\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.4524 - hamming_loss: 0.1753 - val_loss: 0.5060 - val_hamming_loss: 0.1923\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.4381 - hamming_loss: 0.1683 - val_loss: 0.5041 - val_hamming_loss: 0.1906\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.4421 - hamming_loss: 0.1753 - val_loss: 0.5023 - val_hamming_loss: 0.1906\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.4494 - hamming_loss: 0.1757 - val_loss: 0.5005 - val_hamming_loss: 0.1897\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.4400 - hamming_loss: 0.1674 - val_loss: 0.4987 - val_hamming_loss: 0.1888\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.4324 - hamming_loss: 0.1656 - val_loss: 0.4969 - val_hamming_loss: 0.1888\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.4400 - hamming_loss: 0.1753 - val_loss: 0.4951 - val_hamming_loss: 0.1862\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.4294 - hamming_loss: 0.1700 - val_loss: 0.4933 - val_hamming_loss: 0.1862\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.4338 - hamming_loss: 0.1696 - val_loss: 0.4916 - val_hamming_loss: 0.1827\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.4300 - hamming_loss: 0.1639 - val_loss: 0.4899 - val_hamming_loss: 0.1827\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.4241 - hamming_loss: 0.1569 - val_loss: 0.4882 - val_hamming_loss: 0.1783\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.4332 - hamming_loss: 0.1735 - val_loss: 0.4866 - val_hamming_loss: 0.1757\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.4285 - hamming_loss: 0.1696 - val_loss: 0.4850 - val_hamming_loss: 0.1757\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001 = model_ce_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_ce_FF_lr001_df = pd.DataFrame(history_ce_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr0001.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_ce_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "ce_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward BP-MLL Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the bp-mll loss network \n",
    "tf.random.set_seed(123)\n",
    "model_bpmll_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model_bpmll_FF.compile(optimizer = optim_func,\n",
    "              loss = bp_mll_loss, metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 1s - loss: 0.9846 - hamming_loss: 0.3820 - val_loss: 0.9769 - val_hamming_loss: 0.4685\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9782 - hamming_loss: 0.4808 - val_loss: 0.9751 - val_hamming_loss: 0.4624\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9793 - hamming_loss: 0.4830 - val_loss: 0.9733 - val_hamming_loss: 0.4598\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.9722 - hamming_loss: 0.4672 - val_loss: 0.9715 - val_hamming_loss: 0.4537\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.9715 - hamming_loss: 0.4668 - val_loss: 0.9698 - val_hamming_loss: 0.4519\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.9645 - hamming_loss: 0.4563 - val_loss: 0.9680 - val_hamming_loss: 0.4449\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.9601 - hamming_loss: 0.4515 - val_loss: 0.9662 - val_hamming_loss: 0.4423\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.9639 - hamming_loss: 0.4567 - val_loss: 0.9644 - val_hamming_loss: 0.4406\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.9539 - hamming_loss: 0.4388 - val_loss: 0.9626 - val_hamming_loss: 0.4379\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.9491 - hamming_loss: 0.4226 - val_loss: 0.9607 - val_hamming_loss: 0.4318\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.9474 - hamming_loss: 0.4349 - val_loss: 0.9589 - val_hamming_loss: 0.4301\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.9459 - hamming_loss: 0.4375 - val_loss: 0.9570 - val_hamming_loss: 0.4240\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.9469 - hamming_loss: 0.4226 - val_loss: 0.9552 - val_hamming_loss: 0.4152\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.9365 - hamming_loss: 0.4043 - val_loss: 0.9534 - val_hamming_loss: 0.4108\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.9372 - hamming_loss: 0.4130 - val_loss: 0.9515 - val_hamming_loss: 0.4065\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.9343 - hamming_loss: 0.4165 - val_loss: 0.9496 - val_hamming_loss: 0.4056\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.9313 - hamming_loss: 0.4174 - val_loss: 0.9477 - val_hamming_loss: 0.4030\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.9284 - hamming_loss: 0.4017 - val_loss: 0.9459 - val_hamming_loss: 0.3977\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.9251 - hamming_loss: 0.3925 - val_loss: 0.9441 - val_hamming_loss: 0.3969\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.9247 - hamming_loss: 0.3916 - val_loss: 0.9422 - val_hamming_loss: 0.3934\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.9152 - hamming_loss: 0.3837 - val_loss: 0.9403 - val_hamming_loss: 0.3951\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.9112 - hamming_loss: 0.3986 - val_loss: 0.9384 - val_hamming_loss: 0.3916\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.9108 - hamming_loss: 0.3890 - val_loss: 0.9364 - val_hamming_loss: 0.3881\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.9103 - hamming_loss: 0.3789 - val_loss: 0.9345 - val_hamming_loss: 0.3837\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.9038 - hamming_loss: 0.3890 - val_loss: 0.9326 - val_hamming_loss: 0.3820\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.9020 - hamming_loss: 0.3785 - val_loss: 0.9307 - val_hamming_loss: 0.3767\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.8928 - hamming_loss: 0.3641 - val_loss: 0.9288 - val_hamming_loss: 0.3733\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.8969 - hamming_loss: 0.3680 - val_loss: 0.9269 - val_hamming_loss: 0.3741\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.8967 - hamming_loss: 0.3702 - val_loss: 0.9249 - val_hamming_loss: 0.3715\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.8813 - hamming_loss: 0.3497 - val_loss: 0.9229 - val_hamming_loss: 0.3698\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.8766 - hamming_loss: 0.3497 - val_loss: 0.9209 - val_hamming_loss: 0.3663\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.8827 - hamming_loss: 0.3684 - val_loss: 0.9189 - val_hamming_loss: 0.3645\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.8800 - hamming_loss: 0.3510 - val_loss: 0.9169 - val_hamming_loss: 0.3636\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.8750 - hamming_loss: 0.3409 - val_loss: 0.9149 - val_hamming_loss: 0.3593\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.8699 - hamming_loss: 0.3400 - val_loss: 0.9129 - val_hamming_loss: 0.3540\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.8780 - hamming_loss: 0.3571 - val_loss: 0.9109 - val_hamming_loss: 0.3497\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.8746 - hamming_loss: 0.3457 - val_loss: 0.9090 - val_hamming_loss: 0.3462\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.8647 - hamming_loss: 0.3440 - val_loss: 0.9071 - val_hamming_loss: 0.3444\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.8597 - hamming_loss: 0.3413 - val_loss: 0.9051 - val_hamming_loss: 0.3435\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.8596 - hamming_loss: 0.3392 - val_loss: 0.9030 - val_hamming_loss: 0.3392\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.8591 - hamming_loss: 0.3370 - val_loss: 0.9010 - val_hamming_loss: 0.3339\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.8571 - hamming_loss: 0.3479 - val_loss: 0.8989 - val_hamming_loss: 0.3304\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.8511 - hamming_loss: 0.3396 - val_loss: 0.8969 - val_hamming_loss: 0.3287\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.8443 - hamming_loss: 0.3177 - val_loss: 0.8948 - val_hamming_loss: 0.3278\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.8467 - hamming_loss: 0.3234 - val_loss: 0.8928 - val_hamming_loss: 0.3260\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.8455 - hamming_loss: 0.3326 - val_loss: 0.8908 - val_hamming_loss: 0.3226\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.8401 - hamming_loss: 0.3156 - val_loss: 0.8888 - val_hamming_loss: 0.3199\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.8294 - hamming_loss: 0.3134 - val_loss: 0.8868 - val_hamming_loss: 0.3191\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.8296 - hamming_loss: 0.3077 - val_loss: 0.8847 - val_hamming_loss: 0.3173\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.8348 - hamming_loss: 0.3278 - val_loss: 0.8827 - val_hamming_loss: 0.3129\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.8213 - hamming_loss: 0.2963 - val_loss: 0.8806 - val_hamming_loss: 0.3112\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.8191 - hamming_loss: 0.3116 - val_loss: 0.8786 - val_hamming_loss: 0.3059\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.8206 - hamming_loss: 0.3081 - val_loss: 0.8767 - val_hamming_loss: 0.3042\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.8194 - hamming_loss: 0.2990 - val_loss: 0.8747 - val_hamming_loss: 0.3024\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.8149 - hamming_loss: 0.3103 - val_loss: 0.8727 - val_hamming_loss: 0.2990\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.8172 - hamming_loss: 0.3024 - val_loss: 0.8708 - val_hamming_loss: 0.2937\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.8162 - hamming_loss: 0.2898 - val_loss: 0.8688 - val_hamming_loss: 0.2920\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.8073 - hamming_loss: 0.3068 - val_loss: 0.8669 - val_hamming_loss: 0.2920\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.8073 - hamming_loss: 0.3024 - val_loss: 0.8649 - val_hamming_loss: 0.2876\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.7974 - hamming_loss: 0.2841 - val_loss: 0.8630 - val_hamming_loss: 0.2867\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.7957 - hamming_loss: 0.2823 - val_loss: 0.8611 - val_hamming_loss: 0.2841\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.7957 - hamming_loss: 0.2981 - val_loss: 0.8592 - val_hamming_loss: 0.2815\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.8008 - hamming_loss: 0.2898 - val_loss: 0.8573 - val_hamming_loss: 0.2780\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.7946 - hamming_loss: 0.2845 - val_loss: 0.8555 - val_hamming_loss: 0.2762\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.7847 - hamming_loss: 0.2802 - val_loss: 0.8536 - val_hamming_loss: 0.2745\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.7864 - hamming_loss: 0.2815 - val_loss: 0.8517 - val_hamming_loss: 0.2745\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.7899 - hamming_loss: 0.2793 - val_loss: 0.8498 - val_hamming_loss: 0.2736\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.7885 - hamming_loss: 0.2819 - val_loss: 0.8481 - val_hamming_loss: 0.2710\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.7883 - hamming_loss: 0.2832 - val_loss: 0.8463 - val_hamming_loss: 0.2692\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.7744 - hamming_loss: 0.2740 - val_loss: 0.8445 - val_hamming_loss: 0.2684\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.7699 - hamming_loss: 0.2806 - val_loss: 0.8427 - val_hamming_loss: 0.2649\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.7728 - hamming_loss: 0.2653 - val_loss: 0.8409 - val_hamming_loss: 0.2640\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.7749 - hamming_loss: 0.2793 - val_loss: 0.8391 - val_hamming_loss: 0.2640\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.7695 - hamming_loss: 0.2596 - val_loss: 0.8373 - val_hamming_loss: 0.2631\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.7669 - hamming_loss: 0.2609 - val_loss: 0.8356 - val_hamming_loss: 0.2587\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.7674 - hamming_loss: 0.2592 - val_loss: 0.8338 - val_hamming_loss: 0.2579\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.7532 - hamming_loss: 0.2574 - val_loss: 0.8320 - val_hamming_loss: 0.2587\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.7614 - hamming_loss: 0.2675 - val_loss: 0.8303 - val_hamming_loss: 0.2552\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.7678 - hamming_loss: 0.2666 - val_loss: 0.8286 - val_hamming_loss: 0.2561\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.7572 - hamming_loss: 0.2631 - val_loss: 0.8269 - val_hamming_loss: 0.2552\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.7446 - hamming_loss: 0.2509 - val_loss: 0.8252 - val_hamming_loss: 0.2535\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.7484 - hamming_loss: 0.2461 - val_loss: 0.8235 - val_hamming_loss: 0.2509\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.7455 - hamming_loss: 0.2448 - val_loss: 0.8219 - val_hamming_loss: 0.2491\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.7400 - hamming_loss: 0.2557 - val_loss: 0.8202 - val_hamming_loss: 0.2474\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.7447 - hamming_loss: 0.2386 - val_loss: 0.8185 - val_hamming_loss: 0.2448\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.7366 - hamming_loss: 0.2399 - val_loss: 0.8169 - val_hamming_loss: 0.2430\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.7391 - hamming_loss: 0.2522 - val_loss: 0.8153 - val_hamming_loss: 0.2421\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.7427 - hamming_loss: 0.2465 - val_loss: 0.8137 - val_hamming_loss: 0.2413\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.7228 - hamming_loss: 0.2378 - val_loss: 0.8120 - val_hamming_loss: 0.2404\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.7271 - hamming_loss: 0.2382 - val_loss: 0.8104 - val_hamming_loss: 0.2369\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.7351 - hamming_loss: 0.2504 - val_loss: 0.8088 - val_hamming_loss: 0.2351\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.7295 - hamming_loss: 0.2308 - val_loss: 0.8072 - val_hamming_loss: 0.2325\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.7152 - hamming_loss: 0.2295 - val_loss: 0.8057 - val_hamming_loss: 0.2316\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.7256 - hamming_loss: 0.2338 - val_loss: 0.8041 - val_hamming_loss: 0.2299\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.7153 - hamming_loss: 0.2251 - val_loss: 0.8025 - val_hamming_loss: 0.2290\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.7214 - hamming_loss: 0.2351 - val_loss: 0.8010 - val_hamming_loss: 0.2264\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.7192 - hamming_loss: 0.2299 - val_loss: 0.7994 - val_hamming_loss: 0.2255\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.7101 - hamming_loss: 0.2225 - val_loss: 0.7979 - val_hamming_loss: 0.2255\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.7176 - hamming_loss: 0.2356 - val_loss: 0.7964 - val_hamming_loss: 0.2238\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.7169 - hamming_loss: 0.2281 - val_loss: 0.7950 - val_hamming_loss: 0.2238\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_FF_lr001 = model_bpmll_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_bpmll_FF_lr001_df = pd.DataFrame(history_bpmll_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL Feed Forward/history_bpmll_FF_lr0001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_bpmll_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPMLL Bidirectional LSTM Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object_reduced = open('../RNN Text Categorization/RNN_data_dict_reduced.json',)\n",
    "RNN_data_dict_reduced = json.load(file_object_reduced)\n",
    "RNN_data_dict_reduced = ast.literal_eval(RNN_data_dict_reduced)\n",
    "train_padded_hasLabel = np.array(RNN_data_dict_reduced['train_padded_hasLabel'])\n",
    "test_padded_hasLabel = np.array(RNN_data_dict_reduced['test_padded_hasLabel'])\n",
    "Y_train_hasLabel = np.array(RNN_data_dict_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(RNN_data_dict_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bidirectional LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_bpmll_biLSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences = False, return_state = False)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model_bpmll_biLSTM.compile(loss = bp_mll_loss, optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 4s - loss: 0.9990 - hamming_loss: 0.4350 - val_loss: 0.9986 - val_hamming_loss: 0.5411\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9981 - hamming_loss: 0.5197 - val_loss: 0.9979 - val_hamming_loss: 0.5262\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9973 - hamming_loss: 0.5017 - val_loss: 0.9971 - val_hamming_loss: 0.5026\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.9964 - hamming_loss: 0.4786 - val_loss: 0.9964 - val_hamming_loss: 0.4895\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.9956 - hamming_loss: 0.4576 - val_loss: 0.9956 - val_hamming_loss: 0.4764\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.9947 - hamming_loss: 0.4406 - val_loss: 0.9948 - val_hamming_loss: 0.4510\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.9938 - hamming_loss: 0.4156 - val_loss: 0.9940 - val_hamming_loss: 0.4266\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.9928 - hamming_loss: 0.3872 - val_loss: 0.9931 - val_hamming_loss: 0.4073\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.9919 - hamming_loss: 0.3663 - val_loss: 0.9922 - val_hamming_loss: 0.3881\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.9908 - hamming_loss: 0.3540 - val_loss: 0.9912 - val_hamming_loss: 0.3733\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.9897 - hamming_loss: 0.3444 - val_loss: 0.9902 - val_hamming_loss: 0.3689\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.9886 - hamming_loss: 0.3361 - val_loss: 0.9892 - val_hamming_loss: 0.3593\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.9874 - hamming_loss: 0.3365 - val_loss: 0.9880 - val_hamming_loss: 0.3505\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.9861 - hamming_loss: 0.3335 - val_loss: 0.9868 - val_hamming_loss: 0.3497\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.9847 - hamming_loss: 0.3313 - val_loss: 0.9855 - val_hamming_loss: 0.3540\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.9833 - hamming_loss: 0.3352 - val_loss: 0.9841 - val_hamming_loss: 0.3523\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.9817 - hamming_loss: 0.3365 - val_loss: 0.9826 - val_hamming_loss: 0.3523\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.9800 - hamming_loss: 0.3387 - val_loss: 0.9810 - val_hamming_loss: 0.3514\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.9782 - hamming_loss: 0.3405 - val_loss: 0.9792 - val_hamming_loss: 0.3514\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.9761 - hamming_loss: 0.3427 - val_loss: 0.9773 - val_hamming_loss: 0.3514\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.9739 - hamming_loss: 0.3453 - val_loss: 0.9751 - val_hamming_loss: 0.3566\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.9715 - hamming_loss: 0.3466 - val_loss: 0.9727 - val_hamming_loss: 0.3584\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.9688 - hamming_loss: 0.3497 - val_loss: 0.9699 - val_hamming_loss: 0.3575\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.9657 - hamming_loss: 0.3514 - val_loss: 0.9668 - val_hamming_loss: 0.3558\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.9622 - hamming_loss: 0.3518 - val_loss: 0.9633 - val_hamming_loss: 0.3584\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.9583 - hamming_loss: 0.3523 - val_loss: 0.9592 - val_hamming_loss: 0.3584\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.9538 - hamming_loss: 0.3518 - val_loss: 0.9546 - val_hamming_loss: 0.3566\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.9487 - hamming_loss: 0.3510 - val_loss: 0.9491 - val_hamming_loss: 0.3558\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.9426 - hamming_loss: 0.3488 - val_loss: 0.9426 - val_hamming_loss: 0.3514\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.9352 - hamming_loss: 0.3431 - val_loss: 0.9348 - val_hamming_loss: 0.3418\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.9265 - hamming_loss: 0.3361 - val_loss: 0.9254 - val_hamming_loss: 0.3313\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.9161 - hamming_loss: 0.3234 - val_loss: 0.9143 - val_hamming_loss: 0.3147\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.9044 - hamming_loss: 0.3142 - val_loss: 0.9017 - val_hamming_loss: 0.3068\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.8909 - hamming_loss: 0.3103 - val_loss: 0.8888 - val_hamming_loss: 0.3007\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.8778 - hamming_loss: 0.3055 - val_loss: 0.8759 - val_hamming_loss: 0.2981\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.8652 - hamming_loss: 0.2990 - val_loss: 0.8643 - val_hamming_loss: 0.2981\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.8539 - hamming_loss: 0.2972 - val_loss: 0.8542 - val_hamming_loss: 0.2955\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.8440 - hamming_loss: 0.2968 - val_loss: 0.8457 - val_hamming_loss: 0.2972\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.8360 - hamming_loss: 0.2968 - val_loss: 0.8383 - val_hamming_loss: 0.2990\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.8289 - hamming_loss: 0.2985 - val_loss: 0.8319 - val_hamming_loss: 0.3007\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.8227 - hamming_loss: 0.2985 - val_loss: 0.8264 - val_hamming_loss: 0.3007\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.8174 - hamming_loss: 0.2985 - val_loss: 0.8214 - val_hamming_loss: 0.3007\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.8125 - hamming_loss: 0.2985 - val_loss: 0.8170 - val_hamming_loss: 0.3007\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.8082 - hamming_loss: 0.2985 - val_loss: 0.8129 - val_hamming_loss: 0.3007\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.8042 - hamming_loss: 0.2985 - val_loss: 0.8091 - val_hamming_loss: 0.3007\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.8005 - hamming_loss: 0.2985 - val_loss: 0.8056 - val_hamming_loss: 0.3007\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.7970 - hamming_loss: 0.2985 - val_loss: 0.8024 - val_hamming_loss: 0.3007\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.7939 - hamming_loss: 0.2985 - val_loss: 0.7993 - val_hamming_loss: 0.3007\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.7909 - hamming_loss: 0.2985 - val_loss: 0.7964 - val_hamming_loss: 0.3007\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.7881 - hamming_loss: 0.2985 - val_loss: 0.7938 - val_hamming_loss: 0.3007\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.7855 - hamming_loss: 0.2985 - val_loss: 0.7913 - val_hamming_loss: 0.3007\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.7830 - hamming_loss: 0.2985 - val_loss: 0.7889 - val_hamming_loss: 0.3007\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.7807 - hamming_loss: 0.2985 - val_loss: 0.7866 - val_hamming_loss: 0.3007\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.7785 - hamming_loss: 0.2985 - val_loss: 0.7844 - val_hamming_loss: 0.3007\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.7764 - hamming_loss: 0.2985 - val_loss: 0.7824 - val_hamming_loss: 0.3007\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.7744 - hamming_loss: 0.2985 - val_loss: 0.7805 - val_hamming_loss: 0.3007\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.7725 - hamming_loss: 0.2985 - val_loss: 0.7787 - val_hamming_loss: 0.3007\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.7707 - hamming_loss: 0.2985 - val_loss: 0.7769 - val_hamming_loss: 0.3007\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.7690 - hamming_loss: 0.2985 - val_loss: 0.7753 - val_hamming_loss: 0.3007\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.7674 - hamming_loss: 0.2985 - val_loss: 0.7737 - val_hamming_loss: 0.3007\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.7658 - hamming_loss: 0.2985 - val_loss: 0.7721 - val_hamming_loss: 0.3007\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.7643 - hamming_loss: 0.2985 - val_loss: 0.7706 - val_hamming_loss: 0.3007\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.7628 - hamming_loss: 0.2985 - val_loss: 0.7692 - val_hamming_loss: 0.3007\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.7614 - hamming_loss: 0.2985 - val_loss: 0.7678 - val_hamming_loss: 0.3007\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.7601 - hamming_loss: 0.2985 - val_loss: 0.7665 - val_hamming_loss: 0.3007\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.7589 - hamming_loss: 0.2985 - val_loss: 0.7653 - val_hamming_loss: 0.3007\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.7576 - hamming_loss: 0.2985 - val_loss: 0.7641 - val_hamming_loss: 0.3007\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.7564 - hamming_loss: 0.2985 - val_loss: 0.7629 - val_hamming_loss: 0.3007\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.7553 - hamming_loss: 0.2985 - val_loss: 0.7618 - val_hamming_loss: 0.3007\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.7542 - hamming_loss: 0.2985 - val_loss: 0.7607 - val_hamming_loss: 0.3007\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.7532 - hamming_loss: 0.2985 - val_loss: 0.7596 - val_hamming_loss: 0.3007\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.7522 - hamming_loss: 0.2985 - val_loss: 0.7587 - val_hamming_loss: 0.3007\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.7511 - hamming_loss: 0.2985 - val_loss: 0.7577 - val_hamming_loss: 0.3007\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.7502 - hamming_loss: 0.2985 - val_loss: 0.7568 - val_hamming_loss: 0.3007\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.7493 - hamming_loss: 0.2985 - val_loss: 0.7559 - val_hamming_loss: 0.3007\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.7484 - hamming_loss: 0.2985 - val_loss: 0.7550 - val_hamming_loss: 0.3007\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.7475 - hamming_loss: 0.2985 - val_loss: 0.7541 - val_hamming_loss: 0.3007\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.7467 - hamming_loss: 0.2985 - val_loss: 0.7533 - val_hamming_loss: 0.3007\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.7459 - hamming_loss: 0.2985 - val_loss: 0.7525 - val_hamming_loss: 0.3007\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.7451 - hamming_loss: 0.2985 - val_loss: 0.7517 - val_hamming_loss: 0.3007\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.7443 - hamming_loss: 0.2985 - val_loss: 0.7509 - val_hamming_loss: 0.3007\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.7436 - hamming_loss: 0.2985 - val_loss: 0.7502 - val_hamming_loss: 0.3007\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.7429 - hamming_loss: 0.2985 - val_loss: 0.7495 - val_hamming_loss: 0.3007\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.7422 - hamming_loss: 0.2985 - val_loss: 0.7489 - val_hamming_loss: 0.3007\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.7415 - hamming_loss: 0.2985 - val_loss: 0.7482 - val_hamming_loss: 0.3007\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.7408 - hamming_loss: 0.2985 - val_loss: 0.7476 - val_hamming_loss: 0.3007\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.7402 - hamming_loss: 0.2985 - val_loss: 0.7470 - val_hamming_loss: 0.3007\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.7395 - hamming_loss: 0.2985 - val_loss: 0.7464 - val_hamming_loss: 0.3007\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.7389 - hamming_loss: 0.2985 - val_loss: 0.7458 - val_hamming_loss: 0.3007\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.7383 - hamming_loss: 0.2985 - val_loss: 0.7452 - val_hamming_loss: 0.3007\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.7377 - hamming_loss: 0.2985 - val_loss: 0.7446 - val_hamming_loss: 0.3007\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.7371 - hamming_loss: 0.2985 - val_loss: 0.7441 - val_hamming_loss: 0.3007\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.7366 - hamming_loss: 0.2985 - val_loss: 0.7435 - val_hamming_loss: 0.3007\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.7360 - hamming_loss: 0.2985 - val_loss: 0.7430 - val_hamming_loss: 0.3007\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.7355 - hamming_loss: 0.2985 - val_loss: 0.7425 - val_hamming_loss: 0.3007\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.7349 - hamming_loss: 0.2985 - val_loss: 0.7419 - val_hamming_loss: 0.3007\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.7344 - hamming_loss: 0.2985 - val_loss: 0.7415 - val_hamming_loss: 0.3007\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.7339 - hamming_loss: 0.2985 - val_loss: 0.7410 - val_hamming_loss: 0.3007\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.7334 - hamming_loss: 0.2985 - val_loss: 0.7405 - val_hamming_loss: 0.3007\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.7329 - hamming_loss: 0.2985 - val_loss: 0.7400 - val_hamming_loss: 0.3007\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_RNN_lr001 = model_bpmll_biLSTM.fit(train_padded_hasLabel, Y_train_hasLabel, epochs = 100, \n",
    "                       validation_data = (test_padded_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_bpmll_RNN_lr001_df = pd.DataFrame(history_bpmll_RNN_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL RNN/history_bpmll_RNN_lr0001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_RNN_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_biLSTM.predict(train_padded_hasLabel)\n",
    "Y_test_pred = model_bpmll_biLSTM.predict(test_padded_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_RNN_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Entropy Bidirectional LSTM Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bidirectional LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_ce_biLSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences = False, return_state = False)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model_ce_biLSTM.compile(loss = 'binary_crossentropy', optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 5s - loss: 0.6407 - hamming_loss: 0.2946 - val_loss: 0.4737 - val_hamming_loss: 0.1783\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.4329 - hamming_loss: 0.1792 - val_loss: 0.4222 - val_hamming_loss: 0.1888\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.4174 - hamming_loss: 0.1849 - val_loss: 0.4183 - val_hamming_loss: 0.1783\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.4093 - hamming_loss: 0.1796 - val_loss: 0.4088 - val_hamming_loss: 0.1783\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.3969 - hamming_loss: 0.1788 - val_loss: 0.4083 - val_hamming_loss: 0.1897\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.3801 - hamming_loss: 0.1744 - val_loss: 0.4075 - val_hamming_loss: 0.1801\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.3577 - hamming_loss: 0.1591 - val_loss: 0.4027 - val_hamming_loss: 0.1731\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.3325 - hamming_loss: 0.1342 - val_loss: 0.4029 - val_hamming_loss: 0.1809\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.3072 - hamming_loss: 0.1289 - val_loss: 0.4015 - val_hamming_loss: 0.1818\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.2821 - hamming_loss: 0.1132 - val_loss: 0.3962 - val_hamming_loss: 0.1722\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.2591 - hamming_loss: 0.1049 - val_loss: 0.4009 - val_hamming_loss: 0.1722\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.2396 - hamming_loss: 0.0940 - val_loss: 0.4037 - val_hamming_loss: 0.1722\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.2230 - hamming_loss: 0.0822 - val_loss: 0.4074 - val_hamming_loss: 0.1740\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.2085 - hamming_loss: 0.0712 - val_loss: 0.4131 - val_hamming_loss: 0.1713\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.1947 - hamming_loss: 0.0664 - val_loss: 0.4272 - val_hamming_loss: 0.1792\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.1818 - hamming_loss: 0.0625 - val_loss: 0.4242 - val_hamming_loss: 0.1722\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.1712 - hamming_loss: 0.0586 - val_loss: 0.4322 - val_hamming_loss: 0.1713\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.1596 - hamming_loss: 0.0485 - val_loss: 0.4446 - val_hamming_loss: 0.1652\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.1497 - hamming_loss: 0.0389 - val_loss: 0.4518 - val_hamming_loss: 0.1643\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.1412 - hamming_loss: 0.0350 - val_loss: 0.4494 - val_hamming_loss: 0.1626\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.1328 - hamming_loss: 0.0310 - val_loss: 0.4564 - val_hamming_loss: 0.1661\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.1240 - hamming_loss: 0.0288 - val_loss: 0.4581 - val_hamming_loss: 0.1661\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.1158 - hamming_loss: 0.0293 - val_loss: 0.4670 - val_hamming_loss: 0.1670\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.1081 - hamming_loss: 0.0245 - val_loss: 0.4701 - val_hamming_loss: 0.1643\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.1014 - hamming_loss: 0.0201 - val_loss: 0.4867 - val_hamming_loss: 0.1678\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.0953 - hamming_loss: 0.0188 - val_loss: 0.4735 - val_hamming_loss: 0.1652\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.0905 - hamming_loss: 0.0201 - val_loss: 0.4778 - val_hamming_loss: 0.1635\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.0847 - hamming_loss: 0.0188 - val_loss: 0.4841 - val_hamming_loss: 0.1678\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.0785 - hamming_loss: 0.0175 - val_loss: 0.4895 - val_hamming_loss: 0.1617\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.0739 - hamming_loss: 0.0144 - val_loss: 0.5127 - val_hamming_loss: 0.1678\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.0701 - hamming_loss: 0.0122 - val_loss: 0.5200 - val_hamming_loss: 0.1696\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.0659 - hamming_loss: 0.0092 - val_loss: 0.5120 - val_hamming_loss: 0.1643\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.0616 - hamming_loss: 0.0092 - val_loss: 0.5221 - val_hamming_loss: 0.1678\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.0580 - hamming_loss: 0.0083 - val_loss: 0.5252 - val_hamming_loss: 0.1678\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.0544 - hamming_loss: 0.0070 - val_loss: 0.5308 - val_hamming_loss: 0.1635\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.0512 - hamming_loss: 0.0066 - val_loss: 0.5415 - val_hamming_loss: 0.1635\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.0483 - hamming_loss: 0.0052 - val_loss: 0.5476 - val_hamming_loss: 0.1635\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.0459 - hamming_loss: 0.0039 - val_loss: 0.5558 - val_hamming_loss: 0.1635\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.0435 - hamming_loss: 0.0052 - val_loss: 0.5556 - val_hamming_loss: 0.1652\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.0413 - hamming_loss: 0.0035 - val_loss: 0.5556 - val_hamming_loss: 0.1626\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.0393 - hamming_loss: 0.0031 - val_loss: 0.5702 - val_hamming_loss: 0.1626\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.0378 - hamming_loss: 0.0022 - val_loss: 0.5764 - val_hamming_loss: 0.1643\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.0363 - hamming_loss: 0.0022 - val_loss: 0.5775 - val_hamming_loss: 0.1661\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.0347 - hamming_loss: 0.0013 - val_loss: 0.5779 - val_hamming_loss: 0.1652\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.0332 - hamming_loss: 0.0017 - val_loss: 0.5786 - val_hamming_loss: 0.1635\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.0319 - hamming_loss: 0.0017 - val_loss: 0.5799 - val_hamming_loss: 0.1608\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.0306 - hamming_loss: 0.0013 - val_loss: 0.5865 - val_hamming_loss: 0.1591\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.0295 - hamming_loss: 0.0013 - val_loss: 0.5915 - val_hamming_loss: 0.1643\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.0285 - hamming_loss: 0.0013 - val_loss: 0.5916 - val_hamming_loss: 0.1652\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.0273 - hamming_loss: 8.7413e-04 - val_loss: 0.5947 - val_hamming_loss: 0.1617\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.0267 - hamming_loss: 0.0013 - val_loss: 0.5986 - val_hamming_loss: 0.1626\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.0255 - hamming_loss: 8.7413e-04 - val_loss: 0.6050 - val_hamming_loss: 0.1678\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.0246 - hamming_loss: 8.7413e-04 - val_loss: 0.6124 - val_hamming_loss: 0.1652\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.0235 - hamming_loss: 4.3706e-04 - val_loss: 0.6159 - val_hamming_loss: 0.1705\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.0226 - hamming_loss: 4.3706e-04 - val_loss: 0.6195 - val_hamming_loss: 0.1635\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.0219 - hamming_loss: 4.3706e-04 - val_loss: 0.6227 - val_hamming_loss: 0.1643\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.0211 - hamming_loss: 4.3706e-04 - val_loss: 0.6252 - val_hamming_loss: 0.1643\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.0205 - hamming_loss: 4.3706e-04 - val_loss: 0.6296 - val_hamming_loss: 0.1652\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.0198 - hamming_loss: 4.3706e-04 - val_loss: 0.6377 - val_hamming_loss: 0.1713\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.0192 - hamming_loss: 4.3706e-04 - val_loss: 0.6345 - val_hamming_loss: 0.1705\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.0186 - hamming_loss: 4.3706e-04 - val_loss: 0.6369 - val_hamming_loss: 0.1713\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.0181 - hamming_loss: 4.3706e-04 - val_loss: 0.6424 - val_hamming_loss: 0.1705\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.0176 - hamming_loss: 4.3706e-04 - val_loss: 0.6431 - val_hamming_loss: 0.1696\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.0171 - hamming_loss: 4.3706e-04 - val_loss: 0.6480 - val_hamming_loss: 0.1722\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.0167 - hamming_loss: 4.3706e-04 - val_loss: 0.6563 - val_hamming_loss: 0.1687\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.0162 - hamming_loss: 4.3706e-04 - val_loss: 0.6620 - val_hamming_loss: 0.1705\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.0158 - hamming_loss: 4.3706e-04 - val_loss: 0.6650 - val_hamming_loss: 0.1687\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.0153 - hamming_loss: 4.3706e-04 - val_loss: 0.6666 - val_hamming_loss: 0.1696\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.0149 - hamming_loss: 4.3706e-04 - val_loss: 0.6730 - val_hamming_loss: 0.1670\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.0145 - hamming_loss: 4.3706e-04 - val_loss: 0.6749 - val_hamming_loss: 0.1696\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.0143 - hamming_loss: 4.3706e-04 - val_loss: 0.6782 - val_hamming_loss: 0.1678\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.0138 - hamming_loss: 4.3706e-04 - val_loss: 0.6845 - val_hamming_loss: 0.1687\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.0135 - hamming_loss: 4.3706e-04 - val_loss: 0.6838 - val_hamming_loss: 0.1687\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.0131 - hamming_loss: 4.3706e-04 - val_loss: 0.6846 - val_hamming_loss: 0.1670\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.0128 - hamming_loss: 4.3706e-04 - val_loss: 0.6935 - val_hamming_loss: 0.1705\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.0125 - hamming_loss: 4.3706e-04 - val_loss: 0.6937 - val_hamming_loss: 0.1696\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.0122 - hamming_loss: 4.3706e-04 - val_loss: 0.6938 - val_hamming_loss: 0.1670\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.0119 - hamming_loss: 4.3706e-04 - val_loss: 0.7017 - val_hamming_loss: 0.1687\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.0116 - hamming_loss: 0.0000e+00 - val_loss: 0.7070 - val_hamming_loss: 0.1705\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.0114 - hamming_loss: 4.3706e-04 - val_loss: 0.7072 - val_hamming_loss: 0.1670\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.0111 - hamming_loss: 4.3706e-04 - val_loss: 0.7083 - val_hamming_loss: 0.1722\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.0109 - hamming_loss: 4.3706e-04 - val_loss: 0.7100 - val_hamming_loss: 0.1722\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.0106 - hamming_loss: 0.0000e+00 - val_loss: 0.7143 - val_hamming_loss: 0.1713\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.0104 - hamming_loss: 0.0000e+00 - val_loss: 0.7158 - val_hamming_loss: 0.1740\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.0102 - hamming_loss: 0.0000e+00 - val_loss: 0.7199 - val_hamming_loss: 0.1740\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.0100 - hamming_loss: 0.0000e+00 - val_loss: 0.7226 - val_hamming_loss: 0.1713\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.0097 - hamming_loss: 0.0000e+00 - val_loss: 0.7239 - val_hamming_loss: 0.1705\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.0095 - hamming_loss: 0.0000e+00 - val_loss: 0.7277 - val_hamming_loss: 0.1748\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.0094 - hamming_loss: 0.0000e+00 - val_loss: 0.7301 - val_hamming_loss: 0.1731\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.0092 - hamming_loss: 0.0000e+00 - val_loss: 0.7343 - val_hamming_loss: 0.1713\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.0090 - hamming_loss: 0.0000e+00 - val_loss: 0.7359 - val_hamming_loss: 0.1687\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.0088 - hamming_loss: 0.0000e+00 - val_loss: 0.7389 - val_hamming_loss: 0.1705\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.0087 - hamming_loss: 0.0000e+00 - val_loss: 0.7400 - val_hamming_loss: 0.1687\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.0085 - hamming_loss: 0.0000e+00 - val_loss: 0.7454 - val_hamming_loss: 0.1713\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.0084 - hamming_loss: 0.0000e+00 - val_loss: 0.7423 - val_hamming_loss: 0.1705\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.0083 - hamming_loss: 0.0000e+00 - val_loss: 0.7469 - val_hamming_loss: 0.1696\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.0081 - hamming_loss: 0.0000e+00 - val_loss: 0.7465 - val_hamming_loss: 0.1696\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.0080 - hamming_loss: 0.0000e+00 - val_loss: 0.7377 - val_hamming_loss: 0.1696\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.0079 - hamming_loss: 0.0000e+00 - val_loss: 0.7567 - val_hamming_loss: 0.1748\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.0077 - hamming_loss: 0.0000e+00 - val_loss: 0.7553 - val_hamming_loss: 0.1678\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_RNN_lr001 = model_ce_biLSTM.fit(train_padded_hasLabel, Y_train_hasLabel, epochs = 100, \n",
    "                       validation_data = (test_padded_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_RNN_lr001_df = pd.DataFrame(history_ce_RNN_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/Cross Entropy RNN/history_ce_RNN_lr0001.json\", \"w\") as outfile: \n",
    "#    history_ce_RNN_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_biLSTM.predict(train_padded_hasLabel)\n",
    "Y_test_pred = model_ce_biLSTM.predict(test_padded_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "ce_RNN_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_lr0001' : ce_FF_withThreshold,\n",
    "                                                        'bpmll_FF_lr0001' : bpmll_FF_withThreshold,\n",
    "                                                        'ce_RNN_lr0001' : ce_RNN_withThreshold,\n",
    "                                                        'bpmll_RNN_lr0001' : bpmll_RNN_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "#with open(\"Reduced Data Eval Metrics/val_hamming_loss_withThreshold_lr0001.json\", \"w\") as outfile: \n",
    "#    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_lr0001</th>\n",
       "      <th>bpmll_FF_lr0001</th>\n",
       "      <th>ce_RNN_lr0001</th>\n",
       "      <th>bpmll_RNN_lr0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.207168</td>\n",
       "      <td>0.184441</td>\n",
       "      <td>0.189685</td>\n",
       "      <td>0.213287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_lr0001  bpmll_FF_lr0001  ce_RNN_lr0001  bpmll_RNN_lr0001\n",
       "0      0.207168         0.184441       0.189685          0.213287"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Full Dataset (some instances have no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the full tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data.json',)\n",
    "tfidf_data_full = json.load(file_object)\n",
    "X_train = np.array(tfidf_data_full['X_train'])\n",
    "X_test = np.array(tfidf_data_full['X_test'])\n",
    "Y_train = np.array(tfidf_data_full['Y_train'])\n",
    "Y_test = np.array(tfidf_data_full['Y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use same architecture as the previous cross-entropy feed-forward network and train on full dataset\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model_ce_FF_full.compile(optimizer = optim_func,\n",
    "              loss = 'binary_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 1s - loss: 0.7023 - hamming_loss: 0.3895 - val_loss: 0.6944 - val_hamming_loss: 0.4808\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 0.7009 - hamming_loss: 0.4738 - val_loss: 0.6923 - val_hamming_loss: 0.4728\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 0.7003 - hamming_loss: 0.4762 - val_loss: 0.6902 - val_hamming_loss: 0.4663\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 0.6940 - hamming_loss: 0.4592 - val_loss: 0.6881 - val_hamming_loss: 0.4607\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 0.6914 - hamming_loss: 0.4592 - val_loss: 0.6860 - val_hamming_loss: 0.4511\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 0.6892 - hamming_loss: 0.4496 - val_loss: 0.6840 - val_hamming_loss: 0.4431\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 0.6862 - hamming_loss: 0.4437 - val_loss: 0.6820 - val_hamming_loss: 0.4343\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 0.6767 - hamming_loss: 0.4211 - val_loss: 0.6800 - val_hamming_loss: 0.4271\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 0.6723 - hamming_loss: 0.4132 - val_loss: 0.6781 - val_hamming_loss: 0.4183\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 0.6712 - hamming_loss: 0.4096 - val_loss: 0.6763 - val_hamming_loss: 0.4119\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 0.6707 - hamming_loss: 0.4029 - val_loss: 0.6745 - val_hamming_loss: 0.4062\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 0.6704 - hamming_loss: 0.4048 - val_loss: 0.6727 - val_hamming_loss: 0.4030\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 0.6698 - hamming_loss: 0.4076 - val_loss: 0.6709 - val_hamming_loss: 0.3958\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 0.6630 - hamming_loss: 0.3838 - val_loss: 0.6691 - val_hamming_loss: 0.3926\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 0.6594 - hamming_loss: 0.3767 - val_loss: 0.6673 - val_hamming_loss: 0.3886\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 0.6486 - hamming_loss: 0.3672 - val_loss: 0.6655 - val_hamming_loss: 0.3814\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 0.6517 - hamming_loss: 0.3620 - val_loss: 0.6637 - val_hamming_loss: 0.3742\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 0.6466 - hamming_loss: 0.3501 - val_loss: 0.6619 - val_hamming_loss: 0.3710\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 0.6440 - hamming_loss: 0.3505 - val_loss: 0.6601 - val_hamming_loss: 0.3678\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 0.6397 - hamming_loss: 0.3351 - val_loss: 0.6584 - val_hamming_loss: 0.3582\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 0.6379 - hamming_loss: 0.3442 - val_loss: 0.6566 - val_hamming_loss: 0.3542\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 0.6332 - hamming_loss: 0.3366 - val_loss: 0.6547 - val_hamming_loss: 0.3478\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 0.6328 - hamming_loss: 0.3295 - val_loss: 0.6529 - val_hamming_loss: 0.3446\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 0.6347 - hamming_loss: 0.3402 - val_loss: 0.6510 - val_hamming_loss: 0.3429\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 0.6305 - hamming_loss: 0.3335 - val_loss: 0.6492 - val_hamming_loss: 0.3429\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 0.6248 - hamming_loss: 0.3168 - val_loss: 0.6473 - val_hamming_loss: 0.3365\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 0.6230 - hamming_loss: 0.3081 - val_loss: 0.6454 - val_hamming_loss: 0.3309\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 0.6223 - hamming_loss: 0.3152 - val_loss: 0.6436 - val_hamming_loss: 0.3245\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 0.6151 - hamming_loss: 0.3109 - val_loss: 0.6417 - val_hamming_loss: 0.3229\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 0.6134 - hamming_loss: 0.3037 - val_loss: 0.6397 - val_hamming_loss: 0.3197\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 0.6110 - hamming_loss: 0.2922 - val_loss: 0.6378 - val_hamming_loss: 0.3157\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 0.6054 - hamming_loss: 0.2934 - val_loss: 0.6358 - val_hamming_loss: 0.3077\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 0.6090 - hamming_loss: 0.2835 - val_loss: 0.6339 - val_hamming_loss: 0.3053\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 0.5966 - hamming_loss: 0.2807 - val_loss: 0.6320 - val_hamming_loss: 0.3013\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 0.6028 - hamming_loss: 0.2807 - val_loss: 0.6301 - val_hamming_loss: 0.2989\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 0.6033 - hamming_loss: 0.2902 - val_loss: 0.6282 - val_hamming_loss: 0.2973\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 0.5909 - hamming_loss: 0.2760 - val_loss: 0.6262 - val_hamming_loss: 0.2965\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 0.5904 - hamming_loss: 0.2724 - val_loss: 0.6242 - val_hamming_loss: 0.2925\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 0.5874 - hamming_loss: 0.2661 - val_loss: 0.6223 - val_hamming_loss: 0.2909\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 0.5800 - hamming_loss: 0.2613 - val_loss: 0.6203 - val_hamming_loss: 0.2885\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 0.5808 - hamming_loss: 0.2661 - val_loss: 0.6182 - val_hamming_loss: 0.2861\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 0.5803 - hamming_loss: 0.2577 - val_loss: 0.6162 - val_hamming_loss: 0.2829\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 0.5782 - hamming_loss: 0.2581 - val_loss: 0.6143 - val_hamming_loss: 0.2804\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 0.5760 - hamming_loss: 0.2577 - val_loss: 0.6124 - val_hamming_loss: 0.2772\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 0.5734 - hamming_loss: 0.2466 - val_loss: 0.6105 - val_hamming_loss: 0.2756\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 0.5699 - hamming_loss: 0.2375 - val_loss: 0.6086 - val_hamming_loss: 0.2740\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 0.5646 - hamming_loss: 0.2446 - val_loss: 0.6066 - val_hamming_loss: 0.2732\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 0.5700 - hamming_loss: 0.2542 - val_loss: 0.6046 - val_hamming_loss: 0.2724\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 0.5602 - hamming_loss: 0.2431 - val_loss: 0.6026 - val_hamming_loss: 0.2700\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 0.5564 - hamming_loss: 0.2395 - val_loss: 0.6005 - val_hamming_loss: 0.2676\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 0.5556 - hamming_loss: 0.2486 - val_loss: 0.5984 - val_hamming_loss: 0.2668\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 0.5512 - hamming_loss: 0.2272 - val_loss: 0.5962 - val_hamming_loss: 0.2644\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 0.5473 - hamming_loss: 0.2335 - val_loss: 0.5941 - val_hamming_loss: 0.2628\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 0.5480 - hamming_loss: 0.2367 - val_loss: 0.5920 - val_hamming_loss: 0.2604\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 0.5358 - hamming_loss: 0.2209 - val_loss: 0.5898 - val_hamming_loss: 0.2588\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 0.5429 - hamming_loss: 0.2300 - val_loss: 0.5878 - val_hamming_loss: 0.2572\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 0.5358 - hamming_loss: 0.2228 - val_loss: 0.5857 - val_hamming_loss: 0.2564\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 0.5319 - hamming_loss: 0.2177 - val_loss: 0.5835 - val_hamming_loss: 0.2548\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 0.5348 - hamming_loss: 0.2236 - val_loss: 0.5814 - val_hamming_loss: 0.2532\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 0.5277 - hamming_loss: 0.2197 - val_loss: 0.5794 - val_hamming_loss: 0.2516\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 0.5287 - hamming_loss: 0.2165 - val_loss: 0.5774 - val_hamming_loss: 0.2468\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 0.5305 - hamming_loss: 0.2228 - val_loss: 0.5754 - val_hamming_loss: 0.2452\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 0.5137 - hamming_loss: 0.2105 - val_loss: 0.5734 - val_hamming_loss: 0.2444\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 0.5194 - hamming_loss: 0.2149 - val_loss: 0.5714 - val_hamming_loss: 0.2444\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 0.5295 - hamming_loss: 0.2320 - val_loss: 0.5695 - val_hamming_loss: 0.2396\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 0.5144 - hamming_loss: 0.2141 - val_loss: 0.5675 - val_hamming_loss: 0.2372\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 0.5127 - hamming_loss: 0.2006 - val_loss: 0.5656 - val_hamming_loss: 0.2340\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 0.5035 - hamming_loss: 0.2050 - val_loss: 0.5636 - val_hamming_loss: 0.2316\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 0.5062 - hamming_loss: 0.2070 - val_loss: 0.5617 - val_hamming_loss: 0.2292\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 0.5077 - hamming_loss: 0.2090 - val_loss: 0.5597 - val_hamming_loss: 0.2284\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 0.5069 - hamming_loss: 0.2034 - val_loss: 0.5577 - val_hamming_loss: 0.2276\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 0.5016 - hamming_loss: 0.1990 - val_loss: 0.5557 - val_hamming_loss: 0.2268\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 0.5043 - hamming_loss: 0.2018 - val_loss: 0.5537 - val_hamming_loss: 0.2276\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 0.4894 - hamming_loss: 0.1967 - val_loss: 0.5517 - val_hamming_loss: 0.2260\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 0.4957 - hamming_loss: 0.1975 - val_loss: 0.5498 - val_hamming_loss: 0.2252\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 0.4910 - hamming_loss: 0.1955 - val_loss: 0.5479 - val_hamming_loss: 0.2236\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 0.4825 - hamming_loss: 0.1852 - val_loss: 0.5461 - val_hamming_loss: 0.2220\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 0.4847 - hamming_loss: 0.1907 - val_loss: 0.5444 - val_hamming_loss: 0.2179\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 0.4894 - hamming_loss: 0.1899 - val_loss: 0.5425 - val_hamming_loss: 0.2171\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 0.4767 - hamming_loss: 0.1899 - val_loss: 0.5408 - val_hamming_loss: 0.2171\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 0.4819 - hamming_loss: 0.1872 - val_loss: 0.5390 - val_hamming_loss: 0.2163\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 0.4748 - hamming_loss: 0.1923 - val_loss: 0.5373 - val_hamming_loss: 0.2139\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 0.4732 - hamming_loss: 0.1860 - val_loss: 0.5355 - val_hamming_loss: 0.2131\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 0.4701 - hamming_loss: 0.1935 - val_loss: 0.5337 - val_hamming_loss: 0.2115\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 0.4691 - hamming_loss: 0.1875 - val_loss: 0.5319 - val_hamming_loss: 0.2099\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 0.4667 - hamming_loss: 0.1737 - val_loss: 0.5301 - val_hamming_loss: 0.2099\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 0.4622 - hamming_loss: 0.1745 - val_loss: 0.5283 - val_hamming_loss: 0.2059\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 0.4554 - hamming_loss: 0.1745 - val_loss: 0.5265 - val_hamming_loss: 0.2051\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 0.4682 - hamming_loss: 0.1832 - val_loss: 0.5248 - val_hamming_loss: 0.2043\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 0.4532 - hamming_loss: 0.1737 - val_loss: 0.5231 - val_hamming_loss: 0.2019\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 0.4563 - hamming_loss: 0.1725 - val_loss: 0.5213 - val_hamming_loss: 0.2019\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 0.4572 - hamming_loss: 0.1804 - val_loss: 0.5196 - val_hamming_loss: 0.2019\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 0.4501 - hamming_loss: 0.1697 - val_loss: 0.5180 - val_hamming_loss: 0.2011\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 0.4447 - hamming_loss: 0.1705 - val_loss: 0.5163 - val_hamming_loss: 0.2011\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 0.4420 - hamming_loss: 0.1721 - val_loss: 0.5146 - val_hamming_loss: 0.2003\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 0.4412 - hamming_loss: 0.1649 - val_loss: 0.5130 - val_hamming_loss: 0.2003\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 0.4385 - hamming_loss: 0.1701 - val_loss: 0.5114 - val_hamming_loss: 0.1979\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 0.4309 - hamming_loss: 0.1602 - val_loss: 0.5098 - val_hamming_loss: 0.1955\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 0.4288 - hamming_loss: 0.1614 - val_loss: 0.5082 - val_hamming_loss: 0.1947\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 0.4349 - hamming_loss: 0.1598 - val_loss: 0.5066 - val_hamming_loss: 0.1939\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001_full = model_ce_FF_full.fit(X_train, Y_train, epochs = 100,\n",
    "                validation_data = (X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_FF_lr001_full_df = pd.DataFrame(history_ce_FF_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr0001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF_full.predict(X_train)\n",
    "Y_test_pred = model_ce_FF_full.predict(X_test)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_FF_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Reccurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object = open('../RNN Text Categorization/RNN_data_dict.json',)\n",
    "RNN_data_dict = json.load(file_object)\n",
    "RNN_data_dict = ast.literal_eval(RNN_data_dict)\n",
    "train_padded = np.array(RNN_data_dict['train_padded'])\n",
    "test_padded = np.array(RNN_data_dict['test_padded'])\n",
    "Y_train = np.array(RNN_data_dict['Y_train'])\n",
    "Y_test = np.array(RNN_data_dict['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_LSTM_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.LSTM(16, return_sequences = False, return_state = False),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.0001)\n",
    "\n",
    "model_LSTM_full.compile(loss = 'binary_crossentropy', optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 0.6953 - hamming_loss: 0.5159 - val_loss: 0.6949 - val_hamming_loss: 0.5921\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 0.6944 - hamming_loss: 0.5948 - val_loss: 0.6940 - val_hamming_loss: 0.5921\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 0.6935 - hamming_loss: 0.5948 - val_loss: 0.6931 - val_hamming_loss: 0.5921\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 0.6926 - hamming_loss: 0.5956 - val_loss: 0.6922 - val_hamming_loss: 0.5585\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 0.6917 - hamming_loss: 0.5757 - val_loss: 0.6913 - val_hamming_loss: 0.5585\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 0.6908 - hamming_loss: 0.5757 - val_loss: 0.6904 - val_hamming_loss: 0.4960\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 0.6899 - hamming_loss: 0.4734 - val_loss: 0.6894 - val_hamming_loss: 0.4431\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 0.6889 - hamming_loss: 0.4187 - val_loss: 0.6885 - val_hamming_loss: 0.3421\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 0.6879 - hamming_loss: 0.3466 - val_loss: 0.6875 - val_hamming_loss: 0.3421\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 0.6870 - hamming_loss: 0.3466 - val_loss: 0.6864 - val_hamming_loss: 0.3421\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 0.6859 - hamming_loss: 0.3148 - val_loss: 0.6854 - val_hamming_loss: 0.2813\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 0.6848 - hamming_loss: 0.2879 - val_loss: 0.6843 - val_hamming_loss: 0.2813\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 0.6837 - hamming_loss: 0.2879 - val_loss: 0.6831 - val_hamming_loss: 0.2813\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 0.6825 - hamming_loss: 0.2879 - val_loss: 0.6818 - val_hamming_loss: 0.2813\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 0.6813 - hamming_loss: 0.2879 - val_loss: 0.6806 - val_hamming_loss: 0.2813\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 0.6800 - hamming_loss: 0.2879 - val_loss: 0.6792 - val_hamming_loss: 0.2813\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 0.6786 - hamming_loss: 0.2871 - val_loss: 0.6777 - val_hamming_loss: 0.2043\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 0.6770 - hamming_loss: 0.2109 - val_loss: 0.6760 - val_hamming_loss: 0.2043\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 0.6753 - hamming_loss: 0.2109 - val_loss: 0.6742 - val_hamming_loss: 0.2043\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 0.6735 - hamming_loss: 0.2109 - val_loss: 0.6722 - val_hamming_loss: 0.2043\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 0.6715 - hamming_loss: 0.2109 - val_loss: 0.6700 - val_hamming_loss: 0.2043\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 0.6691 - hamming_loss: 0.1907 - val_loss: 0.6675 - val_hamming_loss: 0.1723\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 0.6665 - hamming_loss: 0.1792 - val_loss: 0.6646 - val_hamming_loss: 0.1723\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 0.6635 - hamming_loss: 0.1792 - val_loss: 0.6614 - val_hamming_loss: 0.1723\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 0.6602 - hamming_loss: 0.1792 - val_loss: 0.6577 - val_hamming_loss: 0.1723\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 0.6564 - hamming_loss: 0.1792 - val_loss: 0.6535 - val_hamming_loss: 0.1723\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 0.6520 - hamming_loss: 0.1792 - val_loss: 0.6486 - val_hamming_loss: 0.1723\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 0.6468 - hamming_loss: 0.1792 - val_loss: 0.6430 - val_hamming_loss: 0.1723\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 0.6409 - hamming_loss: 0.1792 - val_loss: 0.6364 - val_hamming_loss: 0.1723\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 0.6342 - hamming_loss: 0.1792 - val_loss: 0.6289 - val_hamming_loss: 0.1723\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 0.6265 - hamming_loss: 0.1792 - val_loss: 0.6206 - val_hamming_loss: 0.1723\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 0.6181 - hamming_loss: 0.1792 - val_loss: 0.6117 - val_hamming_loss: 0.1723\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 0.6092 - hamming_loss: 0.1792 - val_loss: 0.6020 - val_hamming_loss: 0.1723\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 0.5998 - hamming_loss: 0.1792 - val_loss: 0.5925 - val_hamming_loss: 0.1723\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 0.5907 - hamming_loss: 0.1792 - val_loss: 0.5835 - val_hamming_loss: 0.1723\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 0.5823 - hamming_loss: 0.1792 - val_loss: 0.5756 - val_hamming_loss: 0.1723\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 0.5752 - hamming_loss: 0.1792 - val_loss: 0.5689 - val_hamming_loss: 0.1723\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 0.5693 - hamming_loss: 0.1792 - val_loss: 0.5634 - val_hamming_loss: 0.1723\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 0.5642 - hamming_loss: 0.1792 - val_loss: 0.5587 - val_hamming_loss: 0.1723\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 0.5599 - hamming_loss: 0.1792 - val_loss: 0.5546 - val_hamming_loss: 0.1723\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 0.5560 - hamming_loss: 0.1792 - val_loss: 0.5508 - val_hamming_loss: 0.1723\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 0.5523 - hamming_loss: 0.1792 - val_loss: 0.5472 - val_hamming_loss: 0.1723\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 0.5489 - hamming_loss: 0.1792 - val_loss: 0.5439 - val_hamming_loss: 0.1723\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 0.5458 - hamming_loss: 0.1792 - val_loss: 0.5408 - val_hamming_loss: 0.1723\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 0.5429 - hamming_loss: 0.1792 - val_loss: 0.5380 - val_hamming_loss: 0.1723\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 0.5401 - hamming_loss: 0.1792 - val_loss: 0.5353 - val_hamming_loss: 0.1723\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 0.5375 - hamming_loss: 0.1792 - val_loss: 0.5327 - val_hamming_loss: 0.1723\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 0.5349 - hamming_loss: 0.1792 - val_loss: 0.5301 - val_hamming_loss: 0.1723\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 0.5323 - hamming_loss: 0.1792 - val_loss: 0.5276 - val_hamming_loss: 0.1723\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 0.5298 - hamming_loss: 0.1792 - val_loss: 0.5250 - val_hamming_loss: 0.1723\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 0.5273 - hamming_loss: 0.1792 - val_loss: 0.5226 - val_hamming_loss: 0.1723\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 0.5249 - hamming_loss: 0.1792 - val_loss: 0.5203 - val_hamming_loss: 0.1723\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 0.5227 - hamming_loss: 0.1792 - val_loss: 0.5181 - val_hamming_loss: 0.1723\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 0.5206 - hamming_loss: 0.1792 - val_loss: 0.5159 - val_hamming_loss: 0.1723\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 0.5184 - hamming_loss: 0.1792 - val_loss: 0.5138 - val_hamming_loss: 0.1723\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 0.5164 - hamming_loss: 0.1792 - val_loss: 0.5119 - val_hamming_loss: 0.1723\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 0.5145 - hamming_loss: 0.1792 - val_loss: 0.5097 - val_hamming_loss: 0.1723\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 0.5124 - hamming_loss: 0.1792 - val_loss: 0.5077 - val_hamming_loss: 0.1723\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 0.5104 - hamming_loss: 0.1792 - val_loss: 0.5057 - val_hamming_loss: 0.1723\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 0.5085 - hamming_loss: 0.1792 - val_loss: 0.5038 - val_hamming_loss: 0.1723\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 0.5067 - hamming_loss: 0.1792 - val_loss: 0.5020 - val_hamming_loss: 0.1723\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 0.5049 - hamming_loss: 0.1792 - val_loss: 0.5002 - val_hamming_loss: 0.1723\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 0.5032 - hamming_loss: 0.1792 - val_loss: 0.4984 - val_hamming_loss: 0.1723\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 0.5014 - hamming_loss: 0.1792 - val_loss: 0.4967 - val_hamming_loss: 0.1723\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 0.4998 - hamming_loss: 0.1792 - val_loss: 0.4951 - val_hamming_loss: 0.1723\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 0.4981 - hamming_loss: 0.1792 - val_loss: 0.4934 - val_hamming_loss: 0.1723\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 0.4965 - hamming_loss: 0.1792 - val_loss: 0.4918 - val_hamming_loss: 0.1723\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 0.4949 - hamming_loss: 0.1792 - val_loss: 0.4902 - val_hamming_loss: 0.1723\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 0.4933 - hamming_loss: 0.1792 - val_loss: 0.4887 - val_hamming_loss: 0.1723\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 0.4918 - hamming_loss: 0.1792 - val_loss: 0.4872 - val_hamming_loss: 0.1723\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 0.4903 - hamming_loss: 0.1792 - val_loss: 0.4857 - val_hamming_loss: 0.1723\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 0.4888 - hamming_loss: 0.1792 - val_loss: 0.4842 - val_hamming_loss: 0.1723\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 0.4873 - hamming_loss: 0.1792 - val_loss: 0.4827 - val_hamming_loss: 0.1723\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 0.4858 - hamming_loss: 0.1792 - val_loss: 0.4812 - val_hamming_loss: 0.1723\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 0.4844 - hamming_loss: 0.1792 - val_loss: 0.4799 - val_hamming_loss: 0.1723\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 0.4831 - hamming_loss: 0.1792 - val_loss: 0.4785 - val_hamming_loss: 0.1723\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 0.4818 - hamming_loss: 0.1792 - val_loss: 0.4773 - val_hamming_loss: 0.1723\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 0.4806 - hamming_loss: 0.1792 - val_loss: 0.4761 - val_hamming_loss: 0.1723\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 0.4794 - hamming_loss: 0.1792 - val_loss: 0.4749 - val_hamming_loss: 0.1723\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 0.4782 - hamming_loss: 0.1792 - val_loss: 0.4738 - val_hamming_loss: 0.1723\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 0.4770 - hamming_loss: 0.1792 - val_loss: 0.4726 - val_hamming_loss: 0.1723\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 0.4759 - hamming_loss: 0.1792 - val_loss: 0.4715 - val_hamming_loss: 0.1723\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 0.4748 - hamming_loss: 0.1792 - val_loss: 0.4705 - val_hamming_loss: 0.1723\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 0.4736 - hamming_loss: 0.1792 - val_loss: 0.4694 - val_hamming_loss: 0.1723\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 0.4725 - hamming_loss: 0.1792 - val_loss: 0.4684 - val_hamming_loss: 0.1723\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 0.4714 - hamming_loss: 0.1792 - val_loss: 0.4673 - val_hamming_loss: 0.1723\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 0.4704 - hamming_loss: 0.1792 - val_loss: 0.4663 - val_hamming_loss: 0.1723\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 0.4693 - hamming_loss: 0.1792 - val_loss: 0.4653 - val_hamming_loss: 0.1723\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 0.4682 - hamming_loss: 0.1792 - val_loss: 0.4643 - val_hamming_loss: 0.1723\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 0.4672 - hamming_loss: 0.1792 - val_loss: 0.4633 - val_hamming_loss: 0.1723\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 0.4662 - hamming_loss: 0.1792 - val_loss: 0.4624 - val_hamming_loss: 0.1723\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 0.4652 - hamming_loss: 0.1792 - val_loss: 0.4615 - val_hamming_loss: 0.1723\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 0.4643 - hamming_loss: 0.1792 - val_loss: 0.4607 - val_hamming_loss: 0.1723\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 0.4633 - hamming_loss: 0.1792 - val_loss: 0.4598 - val_hamming_loss: 0.1723\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 0.4624 - hamming_loss: 0.1792 - val_loss: 0.4590 - val_hamming_loss: 0.1723\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 0.4615 - hamming_loss: 0.1792 - val_loss: 0.4581 - val_hamming_loss: 0.1723\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 0.4606 - hamming_loss: 0.1792 - val_loss: 0.4573 - val_hamming_loss: 0.1723\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 0.4598 - hamming_loss: 0.1792 - val_loss: 0.4565 - val_hamming_loss: 0.1723\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 0.4589 - hamming_loss: 0.1792 - val_loss: 0.4557 - val_hamming_loss: 0.1723\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 0.4581 - hamming_loss: 0.1792 - val_loss: 0.4550 - val_hamming_loss: 0.1723\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_RNN_lr001_full = model_LSTM_full.fit(train_padded, Y_train, epochs = 100, \n",
    "               validation_data = (test_padded, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_RNN_lr001_full_df = pd.DataFrame(history_ce_RNN_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy RNN/history_ce_RNN_lr0001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_RNN_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_LSTM_full.predict(train_padded)\n",
    "Y_test_pred = model_LSTM_full.predict(test_padded)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_RNN_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17307692307692307"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_RNN_full_withThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_full_lr0001' : ce_FF_full_withThreshold,\n",
    "                                                        'ce_RNN_full_lr0001' : ce_RNN_full_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "#with open(\"Full Data Eval Metrics/val_hamming_loss_withThreshold_lr0001.json\", \"w\") as outfile: \n",
    "#    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_full_lr0001</th>\n",
       "      <th>ce_RNN_full_lr0001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.211538</td>\n",
       "      <td>0.177083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_full_lr0001  ce_RNN_full_lr0001\n",
       "0           0.211538            0.177083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
