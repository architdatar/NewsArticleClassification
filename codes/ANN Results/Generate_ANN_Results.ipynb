{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Filename: Generate_ANN_Results.ipynb\n",
    "#\n",
    "# Purpose: Generate results from different ANN models trained on paragraph \n",
    "#          classification task\n",
    "#\n",
    "# Author(s): Bobby (Robert) Lumpkin\n",
    "#\n",
    "# Library Dependencies: numpy, pandas, tensorflow, bpmll\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Results from Different ANN Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from bpmll import bp_mll_loss\n",
    "import sklearn_json as skljson\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import sys\n",
    "os.chdir('C:\\\\Users\\\\rober\\\\OneDrive\\\\Documents\\\\STAT 6500\\\\Project\\\\NewsArticleClassification\\\\codes\\\\ANN Results')  ## Set working directory\n",
    "                                                                                                                      ## to be 'ANN Results'\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the \n",
    "from threshold_learning import predict_labels_binary         ## threshold_learning library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Reduced Dataset (each instance has atleast one label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the reduced tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data_reduced.json',)\n",
    "tfidf_data_reduced = json.load(file_object)\n",
    "X_train_hasLabel = np.array(tfidf_data_reduced['X_train_hasLabel'])\n",
    "X_test_hasLabel = np.array(tfidf_data_reduced['X_test_hasLabel'])\n",
    "Y_train_hasLabel = np.array(tfidf_data_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(tfidf_data_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the cross-entropy loss network (bpmll used later)\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "metric = tfa.metrics.HammingLoss(mode = 'multilabel', threshold = 0.5)\n",
    "\n",
    "model_ce_FF.compile(optimizer = optim_func,\n",
    "              loss = 'binary_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 2s - loss: 0.6967 - hamming_loss: 0.4655 - val_loss: 0.6730 - val_hamming_loss: 0.4073\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.6624 - hamming_loss: 0.3916 - val_loss: 0.6541 - val_hamming_loss: 0.3427\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.6365 - hamming_loss: 0.3422 - val_loss: 0.6353 - val_hamming_loss: 0.2990\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.6105 - hamming_loss: 0.3003 - val_loss: 0.6157 - val_hamming_loss: 0.2736\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.5861 - hamming_loss: 0.2802 - val_loss: 0.5954 - val_hamming_loss: 0.2509\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.5562 - hamming_loss: 0.2517 - val_loss: 0.5747 - val_hamming_loss: 0.2308\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.5355 - hamming_loss: 0.2290 - val_loss: 0.5533 - val_hamming_loss: 0.2281\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.5093 - hamming_loss: 0.2111 - val_loss: 0.5323 - val_hamming_loss: 0.2142\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.4780 - hamming_loss: 0.1936 - val_loss: 0.5123 - val_hamming_loss: 0.2002\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.4527 - hamming_loss: 0.1748 - val_loss: 0.4941 - val_hamming_loss: 0.1879\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.4412 - hamming_loss: 0.1844 - val_loss: 0.4776 - val_hamming_loss: 0.1722\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.4201 - hamming_loss: 0.1687 - val_loss: 0.4631 - val_hamming_loss: 0.1617\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.3986 - hamming_loss: 0.1604 - val_loss: 0.4508 - val_hamming_loss: 0.1617\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.3785 - hamming_loss: 0.1530 - val_loss: 0.4400 - val_hamming_loss: 0.1635\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.3584 - hamming_loss: 0.1416 - val_loss: 0.4304 - val_hamming_loss: 0.1608\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.3449 - hamming_loss: 0.1329 - val_loss: 0.4221 - val_hamming_loss: 0.1617\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.3367 - hamming_loss: 0.1294 - val_loss: 0.4145 - val_hamming_loss: 0.1608\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.3188 - hamming_loss: 0.1211 - val_loss: 0.4078 - val_hamming_loss: 0.1600\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.3060 - hamming_loss: 0.1136 - val_loss: 0.4016 - val_hamming_loss: 0.1600\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.3066 - hamming_loss: 0.1250 - val_loss: 0.3961 - val_hamming_loss: 0.1600\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.2851 - hamming_loss: 0.1110 - val_loss: 0.3909 - val_hamming_loss: 0.1565\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.2758 - hamming_loss: 0.1001 - val_loss: 0.3862 - val_hamming_loss: 0.1565\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.2735 - hamming_loss: 0.1053 - val_loss: 0.3822 - val_hamming_loss: 0.1565\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.2639 - hamming_loss: 0.1031 - val_loss: 0.3790 - val_hamming_loss: 0.1573\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.2560 - hamming_loss: 0.0913 - val_loss: 0.3761 - val_hamming_loss: 0.1573\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.2564 - hamming_loss: 0.1005 - val_loss: 0.3735 - val_hamming_loss: 0.1573\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.2268 - hamming_loss: 0.0865 - val_loss: 0.3708 - val_hamming_loss: 0.1538\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.2319 - hamming_loss: 0.0861 - val_loss: 0.3689 - val_hamming_loss: 0.1538\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.2288 - hamming_loss: 0.0852 - val_loss: 0.3672 - val_hamming_loss: 0.1530\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.2236 - hamming_loss: 0.0865 - val_loss: 0.3653 - val_hamming_loss: 0.1521\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.2089 - hamming_loss: 0.0760 - val_loss: 0.3635 - val_hamming_loss: 0.1521\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.2081 - hamming_loss: 0.0752 - val_loss: 0.3622 - val_hamming_loss: 0.1521\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.2093 - hamming_loss: 0.0747 - val_loss: 0.3610 - val_hamming_loss: 0.1495\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.1897 - hamming_loss: 0.0699 - val_loss: 0.3596 - val_hamming_loss: 0.1503\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.1915 - hamming_loss: 0.0699 - val_loss: 0.3585 - val_hamming_loss: 0.1495\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.1961 - hamming_loss: 0.0717 - val_loss: 0.3576 - val_hamming_loss: 0.1477\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.1866 - hamming_loss: 0.0673 - val_loss: 0.3565 - val_hamming_loss: 0.1469\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.1649 - hamming_loss: 0.0573 - val_loss: 0.3558 - val_hamming_loss: 0.1477\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.1729 - hamming_loss: 0.0712 - val_loss: 0.3552 - val_hamming_loss: 0.1451\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.1688 - hamming_loss: 0.0651 - val_loss: 0.3544 - val_hamming_loss: 0.1451\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.1654 - hamming_loss: 0.0573 - val_loss: 0.3537 - val_hamming_loss: 0.1451\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.1692 - hamming_loss: 0.0608 - val_loss: 0.3542 - val_hamming_loss: 0.1460\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.1535 - hamming_loss: 0.0551 - val_loss: 0.3548 - val_hamming_loss: 0.1434\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.1470 - hamming_loss: 0.0546 - val_loss: 0.3554 - val_hamming_loss: 0.1425\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.1478 - hamming_loss: 0.0564 - val_loss: 0.3560 - val_hamming_loss: 0.1425\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.1613 - hamming_loss: 0.0551 - val_loss: 0.3564 - val_hamming_loss: 0.1425\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.1444 - hamming_loss: 0.0494 - val_loss: 0.3565 - val_hamming_loss: 0.1434\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.1471 - hamming_loss: 0.0542 - val_loss: 0.3566 - val_hamming_loss: 0.1451\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.1311 - hamming_loss: 0.0441 - val_loss: 0.3563 - val_hamming_loss: 0.1442\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.1444 - hamming_loss: 0.0498 - val_loss: 0.3564 - val_hamming_loss: 0.1425\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.1421 - hamming_loss: 0.0538 - val_loss: 0.3574 - val_hamming_loss: 0.1425\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.1286 - hamming_loss: 0.0481 - val_loss: 0.3587 - val_hamming_loss: 0.1434\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.1247 - hamming_loss: 0.0402 - val_loss: 0.3604 - val_hamming_loss: 0.1434\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.1397 - hamming_loss: 0.0594 - val_loss: 0.3615 - val_hamming_loss: 0.1434\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.1377 - hamming_loss: 0.0463 - val_loss: 0.3622 - val_hamming_loss: 0.1416\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.1265 - hamming_loss: 0.0463 - val_loss: 0.3623 - val_hamming_loss: 0.1399\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.1267 - hamming_loss: 0.0476 - val_loss: 0.3626 - val_hamming_loss: 0.1399\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.1255 - hamming_loss: 0.0476 - val_loss: 0.3629 - val_hamming_loss: 0.1399\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.1265 - hamming_loss: 0.0433 - val_loss: 0.3635 - val_hamming_loss: 0.1416\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.1148 - hamming_loss: 0.0406 - val_loss: 0.3647 - val_hamming_loss: 0.1416\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.1244 - hamming_loss: 0.0476 - val_loss: 0.3655 - val_hamming_loss: 0.1407\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.1192 - hamming_loss: 0.0433 - val_loss: 0.3667 - val_hamming_loss: 0.1416\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.1257 - hamming_loss: 0.0415 - val_loss: 0.3673 - val_hamming_loss: 0.1407\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.1107 - hamming_loss: 0.0411 - val_loss: 0.3677 - val_hamming_loss: 0.1399\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.1106 - hamming_loss: 0.0367 - val_loss: 0.3680 - val_hamming_loss: 0.1407\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.1172 - hamming_loss: 0.0398 - val_loss: 0.3685 - val_hamming_loss: 0.1407\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.1071 - hamming_loss: 0.0358 - val_loss: 0.3699 - val_hamming_loss: 0.1390\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.1204 - hamming_loss: 0.0446 - val_loss: 0.3712 - val_hamming_loss: 0.1390\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.1217 - hamming_loss: 0.0420 - val_loss: 0.3737 - val_hamming_loss: 0.1399\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.1127 - hamming_loss: 0.0459 - val_loss: 0.3755 - val_hamming_loss: 0.1399\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.1019 - hamming_loss: 0.0358 - val_loss: 0.3770 - val_hamming_loss: 0.1399\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.1095 - hamming_loss: 0.0393 - val_loss: 0.3784 - val_hamming_loss: 0.1390\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.1140 - hamming_loss: 0.0463 - val_loss: 0.3795 - val_hamming_loss: 0.1399\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.1156 - hamming_loss: 0.0402 - val_loss: 0.3808 - val_hamming_loss: 0.1399\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.1095 - hamming_loss: 0.0393 - val_loss: 0.3818 - val_hamming_loss: 0.1399\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.1085 - hamming_loss: 0.0376 - val_loss: 0.3827 - val_hamming_loss: 0.1399\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.0958 - hamming_loss: 0.0337 - val_loss: 0.3824 - val_hamming_loss: 0.1381\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.1035 - hamming_loss: 0.0372 - val_loss: 0.3822 - val_hamming_loss: 0.1372\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.1070 - hamming_loss: 0.0411 - val_loss: 0.3830 - val_hamming_loss: 0.1372\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.0984 - hamming_loss: 0.0358 - val_loss: 0.3850 - val_hamming_loss: 0.1390\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.0930 - hamming_loss: 0.0302 - val_loss: 0.3874 - val_hamming_loss: 0.1381\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.0959 - hamming_loss: 0.0319 - val_loss: 0.3889 - val_hamming_loss: 0.1390\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.0989 - hamming_loss: 0.0411 - val_loss: 0.3895 - val_hamming_loss: 0.1381\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.0962 - hamming_loss: 0.0398 - val_loss: 0.3905 - val_hamming_loss: 0.1372\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.0952 - hamming_loss: 0.0302 - val_loss: 0.3915 - val_hamming_loss: 0.1372\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.0944 - hamming_loss: 0.0345 - val_loss: 0.3920 - val_hamming_loss: 0.1372\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.0868 - hamming_loss: 0.0341 - val_loss: 0.3934 - val_hamming_loss: 0.1364\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.0950 - hamming_loss: 0.0363 - val_loss: 0.3947 - val_hamming_loss: 0.1381\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.0947 - hamming_loss: 0.0341 - val_loss: 0.3952 - val_hamming_loss: 0.1372\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.0893 - hamming_loss: 0.0341 - val_loss: 0.3952 - val_hamming_loss: 0.1355\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.1044 - hamming_loss: 0.0406 - val_loss: 0.3953 - val_hamming_loss: 0.1364\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.0953 - hamming_loss: 0.0358 - val_loss: 0.3965 - val_hamming_loss: 0.1355\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.0881 - hamming_loss: 0.0332 - val_loss: 0.3973 - val_hamming_loss: 0.1346\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.0904 - hamming_loss: 0.0345 - val_loss: 0.3981 - val_hamming_loss: 0.1346\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.0885 - hamming_loss: 0.0341 - val_loss: 0.3998 - val_hamming_loss: 0.1364\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.0979 - hamming_loss: 0.0358 - val_loss: 0.4022 - val_hamming_loss: 0.1372\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.0924 - hamming_loss: 0.0350 - val_loss: 0.4059 - val_hamming_loss: 0.1355\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.0875 - hamming_loss: 0.0328 - val_loss: 0.4084 - val_hamming_loss: 0.1355\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.0968 - hamming_loss: 0.0358 - val_loss: 0.4106 - val_hamming_loss: 0.1355\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.1035 - hamming_loss: 0.0415 - val_loss: 0.4130 - val_hamming_loss: 0.1355\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001 = model_ce_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_ce_FF_lr001_df = pd.DataFrame(history_ce_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr001.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_ce_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "ce_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward BP-MLL Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start by defining and compiling the bp-mll loss network \n",
    "tf.random.set_seed(123)\n",
    "model_bpmll_FF = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_bpmll_FF.compile(optimizer = optim_func,\n",
    "              loss = bp_mll_loss, metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 1s - loss: 0.9794 - hamming_loss: 0.3596 - val_loss: 0.9620 - val_hamming_loss: 0.4353\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9434 - hamming_loss: 0.4270 - val_loss: 0.9439 - val_hamming_loss: 0.4038\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9161 - hamming_loss: 0.3934 - val_loss: 0.9250 - val_hamming_loss: 0.3802\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.8863 - hamming_loss: 0.3571 - val_loss: 0.9059 - val_hamming_loss: 0.3531\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.8618 - hamming_loss: 0.3536 - val_loss: 0.8866 - val_hamming_loss: 0.3304\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.8277 - hamming_loss: 0.3252 - val_loss: 0.8678 - val_hamming_loss: 0.2990\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.8053 - hamming_loss: 0.3055 - val_loss: 0.8489 - val_hamming_loss: 0.2788\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.7880 - hamming_loss: 0.2898 - val_loss: 0.8311 - val_hamming_loss: 0.2570\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.7562 - hamming_loss: 0.2745 - val_loss: 0.8144 - val_hamming_loss: 0.2439\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.7367 - hamming_loss: 0.2461 - val_loss: 0.7990 - val_hamming_loss: 0.2343\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.7198 - hamming_loss: 0.2456 - val_loss: 0.7848 - val_hamming_loss: 0.2229\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.7032 - hamming_loss: 0.2242 - val_loss: 0.7720 - val_hamming_loss: 0.2177\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.6897 - hamming_loss: 0.2198 - val_loss: 0.7602 - val_hamming_loss: 0.2124\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.6717 - hamming_loss: 0.2041 - val_loss: 0.7493 - val_hamming_loss: 0.2089\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.6544 - hamming_loss: 0.1958 - val_loss: 0.7394 - val_hamming_loss: 0.2045\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.6414 - hamming_loss: 0.1923 - val_loss: 0.7305 - val_hamming_loss: 0.2010\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.6338 - hamming_loss: 0.1836 - val_loss: 0.7223 - val_hamming_loss: 0.1976\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.6170 - hamming_loss: 0.1792 - val_loss: 0.7148 - val_hamming_loss: 0.1949\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.6047 - hamming_loss: 0.1639 - val_loss: 0.7079 - val_hamming_loss: 0.1949\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.6008 - hamming_loss: 0.1726 - val_loss: 0.7017 - val_hamming_loss: 0.1932\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.5838 - hamming_loss: 0.1569 - val_loss: 0.6960 - val_hamming_loss: 0.1888\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.5825 - hamming_loss: 0.1469 - val_loss: 0.6906 - val_hamming_loss: 0.1871\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.5759 - hamming_loss: 0.1469 - val_loss: 0.6857 - val_hamming_loss: 0.1862\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.5687 - hamming_loss: 0.1464 - val_loss: 0.6813 - val_hamming_loss: 0.1844\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.5640 - hamming_loss: 0.1517 - val_loss: 0.6773 - val_hamming_loss: 0.1809\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.5607 - hamming_loss: 0.1394 - val_loss: 0.6735 - val_hamming_loss: 0.1774\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.5349 - hamming_loss: 0.1167 - val_loss: 0.6700 - val_hamming_loss: 0.1740\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.5414 - hamming_loss: 0.1267 - val_loss: 0.6668 - val_hamming_loss: 0.1705\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.5414 - hamming_loss: 0.1241 - val_loss: 0.6635 - val_hamming_loss: 0.1705\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.5340 - hamming_loss: 0.1241 - val_loss: 0.6607 - val_hamming_loss: 0.1652\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.5239 - hamming_loss: 0.1145 - val_loss: 0.6587 - val_hamming_loss: 0.1661\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.5190 - hamming_loss: 0.1036 - val_loss: 0.6569 - val_hamming_loss: 0.1635\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.5229 - hamming_loss: 0.1180 - val_loss: 0.6550 - val_hamming_loss: 0.1626\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.5117 - hamming_loss: 0.1014 - val_loss: 0.6531 - val_hamming_loss: 0.1626\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.5064 - hamming_loss: 0.1045 - val_loss: 0.6518 - val_hamming_loss: 0.1600\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.5144 - hamming_loss: 0.1115 - val_loss: 0.6503 - val_hamming_loss: 0.1591\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.5041 - hamming_loss: 0.0970 - val_loss: 0.6485 - val_hamming_loss: 0.1591\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.4913 - hamming_loss: 0.0935 - val_loss: 0.6466 - val_hamming_loss: 0.1582\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.4966 - hamming_loss: 0.0909 - val_loss: 0.6451 - val_hamming_loss: 0.1582\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.4917 - hamming_loss: 0.0957 - val_loss: 0.6435 - val_hamming_loss: 0.1582\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.4862 - hamming_loss: 0.0839 - val_loss: 0.6420 - val_hamming_loss: 0.1582\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.4896 - hamming_loss: 0.0918 - val_loss: 0.6404 - val_hamming_loss: 0.1582\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.4854 - hamming_loss: 0.0892 - val_loss: 0.6393 - val_hamming_loss: 0.1556\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.4742 - hamming_loss: 0.0817 - val_loss: 0.6388 - val_hamming_loss: 0.1556\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.4834 - hamming_loss: 0.0909 - val_loss: 0.6382 - val_hamming_loss: 0.1538\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.4903 - hamming_loss: 0.0909 - val_loss: 0.6377 - val_hamming_loss: 0.1521\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.4819 - hamming_loss: 0.0830 - val_loss: 0.6372 - val_hamming_loss: 0.1530\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.4780 - hamming_loss: 0.0857 - val_loss: 0.6363 - val_hamming_loss: 0.1530\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.4694 - hamming_loss: 0.0800 - val_loss: 0.6353 - val_hamming_loss: 0.1521\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.4758 - hamming_loss: 0.0870 - val_loss: 0.6342 - val_hamming_loss: 0.1486\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.4766 - hamming_loss: 0.0830 - val_loss: 0.6338 - val_hamming_loss: 0.1486\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.4698 - hamming_loss: 0.0795 - val_loss: 0.6337 - val_hamming_loss: 0.1495\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.4609 - hamming_loss: 0.0712 - val_loss: 0.6336 - val_hamming_loss: 0.1495\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.4731 - hamming_loss: 0.0870 - val_loss: 0.6333 - val_hamming_loss: 0.1512\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.4705 - hamming_loss: 0.0787 - val_loss: 0.6327 - val_hamming_loss: 0.1495\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.4615 - hamming_loss: 0.0717 - val_loss: 0.6323 - val_hamming_loss: 0.1486\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.4641 - hamming_loss: 0.0734 - val_loss: 0.6321 - val_hamming_loss: 0.1477\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.4619 - hamming_loss: 0.0760 - val_loss: 0.6320 - val_hamming_loss: 0.1477\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.4614 - hamming_loss: 0.0699 - val_loss: 0.6316 - val_hamming_loss: 0.1477\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.4562 - hamming_loss: 0.0717 - val_loss: 0.6317 - val_hamming_loss: 0.1477\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.4612 - hamming_loss: 0.0673 - val_loss: 0.6319 - val_hamming_loss: 0.1486\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.4564 - hamming_loss: 0.0739 - val_loss: 0.6318 - val_hamming_loss: 0.1495\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.4606 - hamming_loss: 0.0712 - val_loss: 0.6312 - val_hamming_loss: 0.1486\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.4539 - hamming_loss: 0.0699 - val_loss: 0.6309 - val_hamming_loss: 0.1477\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.4547 - hamming_loss: 0.0726 - val_loss: 0.6306 - val_hamming_loss: 0.1477\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.4539 - hamming_loss: 0.0695 - val_loss: 0.6308 - val_hamming_loss: 0.1469\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.4486 - hamming_loss: 0.0660 - val_loss: 0.6312 - val_hamming_loss: 0.1460\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.4569 - hamming_loss: 0.0721 - val_loss: 0.6315 - val_hamming_loss: 0.1460\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.4590 - hamming_loss: 0.0734 - val_loss: 0.6315 - val_hamming_loss: 0.1460\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.4536 - hamming_loss: 0.0634 - val_loss: 0.6312 - val_hamming_loss: 0.1451\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.4435 - hamming_loss: 0.0660 - val_loss: 0.6309 - val_hamming_loss: 0.1442\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.4471 - hamming_loss: 0.0642 - val_loss: 0.6308 - val_hamming_loss: 0.1442\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.4505 - hamming_loss: 0.0677 - val_loss: 0.6305 - val_hamming_loss: 0.1434\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.4561 - hamming_loss: 0.0699 - val_loss: 0.6301 - val_hamming_loss: 0.1442\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.4476 - hamming_loss: 0.0629 - val_loss: 0.6297 - val_hamming_loss: 0.1451\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.4526 - hamming_loss: 0.0699 - val_loss: 0.6295 - val_hamming_loss: 0.1442\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.4433 - hamming_loss: 0.0621 - val_loss: 0.6294 - val_hamming_loss: 0.1434\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.4488 - hamming_loss: 0.0647 - val_loss: 0.6290 - val_hamming_loss: 0.1434\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.4462 - hamming_loss: 0.0660 - val_loss: 0.6288 - val_hamming_loss: 0.1425\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.4451 - hamming_loss: 0.0669 - val_loss: 0.6288 - val_hamming_loss: 0.1425\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.4449 - hamming_loss: 0.0642 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.4394 - hamming_loss: 0.0559 - val_loss: 0.6287 - val_hamming_loss: 0.1425\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.4395 - hamming_loss: 0.0573 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.4448 - hamming_loss: 0.0651 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.4436 - hamming_loss: 0.0594 - val_loss: 0.6286 - val_hamming_loss: 0.1425\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.4466 - hamming_loss: 0.0664 - val_loss: 0.6287 - val_hamming_loss: 0.1425\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.4359 - hamming_loss: 0.0586 - val_loss: 0.6290 - val_hamming_loss: 0.1434\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.4428 - hamming_loss: 0.0625 - val_loss: 0.6288 - val_hamming_loss: 0.1451\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.4382 - hamming_loss: 0.0608 - val_loss: 0.6289 - val_hamming_loss: 0.1451\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.4415 - hamming_loss: 0.0673 - val_loss: 0.6286 - val_hamming_loss: 0.1451\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.4432 - hamming_loss: 0.0660 - val_loss: 0.6284 - val_hamming_loss: 0.1451\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.4380 - hamming_loss: 0.0612 - val_loss: 0.6284 - val_hamming_loss: 0.1451\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.4341 - hamming_loss: 0.0581 - val_loss: 0.6280 - val_hamming_loss: 0.1451\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.4358 - hamming_loss: 0.0612 - val_loss: 0.6282 - val_hamming_loss: 0.1434\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.4363 - hamming_loss: 0.0564 - val_loss: 0.6281 - val_hamming_loss: 0.1434\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.4431 - hamming_loss: 0.0647 - val_loss: 0.6284 - val_hamming_loss: 0.1442\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.4430 - hamming_loss: 0.0712 - val_loss: 0.6284 - val_hamming_loss: 0.1442\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.4377 - hamming_loss: 0.0621 - val_loss: 0.6279 - val_hamming_loss: 0.1434\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.4452 - hamming_loss: 0.0621 - val_loss: 0.6278 - val_hamming_loss: 0.1434\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.4429 - hamming_loss: 0.0664 - val_loss: 0.6280 - val_hamming_loss: 0.1434\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_FF_lr001 = model_bpmll_FF.fit(X_train_hasLabel, Y_train_hasLabel, epochs = 100,\n",
    "                validation_data = (X_test_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file \n",
    "history_bpmll_FF_lr001_df = pd.DataFrame(history_bpmll_FF_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL Feed Forward/history_bpmll_FF_lr001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_FF_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_FF.predict(X_train_hasLabel)\n",
    "Y_test_pred = model_bpmll_FF.predict(X_test_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_FF_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bidirectional LSTM Recurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object_reduced = open('../RNN Text Categorization/RNN_data_dict_reduced.json',)\n",
    "RNN_data_dict_reduced = json.load(file_object_reduced)\n",
    "RNN_data_dict_reduced = ast.literal_eval(RNN_data_dict_reduced)\n",
    "train_padded_hasLabel = np.array(RNN_data_dict_reduced['train_padded_hasLabel'])\n",
    "test_padded_hasLabel = np.array(RNN_data_dict_reduced['test_padded_hasLabel'])\n",
    "Y_train_hasLabel = np.array(RNN_data_dict_reduced['Y_train_hasLabel'])\n",
    "Y_test_hasLabel = np.array(RNN_data_dict_reduced['Y_test_hasLabel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the bidirectional LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "max_length = 100\n",
    "num_unique_words = 2711\n",
    "\n",
    "model_bpmll_biLSTM = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(16, return_sequences = False, return_state = False)),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_bpmll_biLSTM.compile(loss = bp_mll_loss, optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 - 6s - loss: 0.9963 - hamming_loss: 0.3636 - val_loss: 0.9916 - val_hamming_loss: 0.3759\n",
      "Epoch 2/100\n",
      "6/6 - 0s - loss: 0.9869 - hamming_loss: 0.3431 - val_loss: 0.9820 - val_hamming_loss: 0.3549\n",
      "Epoch 3/100\n",
      "6/6 - 0s - loss: 0.9746 - hamming_loss: 0.3475 - val_loss: 0.9679 - val_hamming_loss: 0.3584\n",
      "Epoch 4/100\n",
      "6/6 - 0s - loss: 0.9561 - hamming_loss: 0.3479 - val_loss: 0.9450 - val_hamming_loss: 0.3514\n",
      "Epoch 5/100\n",
      "6/6 - 0s - loss: 0.9259 - hamming_loss: 0.3230 - val_loss: 0.9044 - val_hamming_loss: 0.3042\n",
      "Epoch 6/100\n",
      "6/6 - 0s - loss: 0.8743 - hamming_loss: 0.3046 - val_loss: 0.8490 - val_hamming_loss: 0.3007\n",
      "Epoch 7/100\n",
      "6/6 - 0s - loss: 0.8240 - hamming_loss: 0.2985 - val_loss: 0.8097 - val_hamming_loss: 0.3007\n",
      "Epoch 8/100\n",
      "6/6 - 0s - loss: 0.7903 - hamming_loss: 0.2985 - val_loss: 0.7843 - val_hamming_loss: 0.3007\n",
      "Epoch 9/100\n",
      "6/6 - 0s - loss: 0.7678 - hamming_loss: 0.2985 - val_loss: 0.7658 - val_hamming_loss: 0.3007\n",
      "Epoch 10/100\n",
      "6/6 - 0s - loss: 0.7521 - hamming_loss: 0.2985 - val_loss: 0.7528 - val_hamming_loss: 0.3007\n",
      "Epoch 11/100\n",
      "6/6 - 0s - loss: 0.7408 - hamming_loss: 0.2985 - val_loss: 0.7438 - val_hamming_loss: 0.3007\n",
      "Epoch 12/100\n",
      "6/6 - 0s - loss: 0.7329 - hamming_loss: 0.2985 - val_loss: 0.7375 - val_hamming_loss: 0.3007\n",
      "Epoch 13/100\n",
      "6/6 - 0s - loss: 0.7267 - hamming_loss: 0.2985 - val_loss: 0.7325 - val_hamming_loss: 0.3007\n",
      "Epoch 14/100\n",
      "6/6 - 0s - loss: 0.7216 - hamming_loss: 0.2985 - val_loss: 0.7290 - val_hamming_loss: 0.3007\n",
      "Epoch 15/100\n",
      "6/6 - 0s - loss: 0.7173 - hamming_loss: 0.2985 - val_loss: 0.7253 - val_hamming_loss: 0.3007\n",
      "Epoch 16/100\n",
      "6/6 - 0s - loss: 0.7132 - hamming_loss: 0.2981 - val_loss: 0.7225 - val_hamming_loss: 0.3007\n",
      "Epoch 17/100\n",
      "6/6 - 0s - loss: 0.7090 - hamming_loss: 0.2946 - val_loss: 0.7198 - val_hamming_loss: 0.2998\n",
      "Epoch 18/100\n",
      "6/6 - 0s - loss: 0.7048 - hamming_loss: 0.2920 - val_loss: 0.7166 - val_hamming_loss: 0.2981\n",
      "Epoch 19/100\n",
      "6/6 - 0s - loss: 0.7004 - hamming_loss: 0.2902 - val_loss: 0.7141 - val_hamming_loss: 0.2981\n",
      "Epoch 20/100\n",
      "6/6 - 0s - loss: 0.6962 - hamming_loss: 0.2858 - val_loss: 0.7120 - val_hamming_loss: 0.2928\n",
      "Epoch 21/100\n",
      "6/6 - 0s - loss: 0.6916 - hamming_loss: 0.2592 - val_loss: 0.7090 - val_hamming_loss: 0.2771\n",
      "Epoch 22/100\n",
      "6/6 - 0s - loss: 0.6874 - hamming_loss: 0.2469 - val_loss: 0.7089 - val_hamming_loss: 0.2509\n",
      "Epoch 23/100\n",
      "6/6 - 0s - loss: 0.6834 - hamming_loss: 0.2356 - val_loss: 0.7086 - val_hamming_loss: 0.2465\n",
      "Epoch 24/100\n",
      "6/6 - 0s - loss: 0.6791 - hamming_loss: 0.2225 - val_loss: 0.7035 - val_hamming_loss: 0.2386\n",
      "Epoch 25/100\n",
      "6/6 - 0s - loss: 0.6738 - hamming_loss: 0.2128 - val_loss: 0.6994 - val_hamming_loss: 0.2360\n",
      "Epoch 26/100\n",
      "6/6 - 0s - loss: 0.6689 - hamming_loss: 0.2102 - val_loss: 0.7021 - val_hamming_loss: 0.2369\n",
      "Epoch 27/100\n",
      "6/6 - 0s - loss: 0.6644 - hamming_loss: 0.2067 - val_loss: 0.6952 - val_hamming_loss: 0.2351\n",
      "Epoch 28/100\n",
      "6/6 - 0s - loss: 0.6586 - hamming_loss: 0.1954 - val_loss: 0.6979 - val_hamming_loss: 0.2220\n",
      "Epoch 29/100\n",
      "6/6 - 0s - loss: 0.6533 - hamming_loss: 0.1731 - val_loss: 0.6938 - val_hamming_loss: 0.2142\n",
      "Epoch 30/100\n",
      "6/6 - 0s - loss: 0.6480 - hamming_loss: 0.1608 - val_loss: 0.6948 - val_hamming_loss: 0.2072\n",
      "Epoch 31/100\n",
      "6/6 - 0s - loss: 0.6428 - hamming_loss: 0.1565 - val_loss: 0.6915 - val_hamming_loss: 0.2150\n",
      "Epoch 32/100\n",
      "6/6 - 0s - loss: 0.6378 - hamming_loss: 0.1556 - val_loss: 0.6924 - val_hamming_loss: 0.2019\n",
      "Epoch 33/100\n",
      "6/6 - 0s - loss: 0.6332 - hamming_loss: 0.1534 - val_loss: 0.6900 - val_hamming_loss: 0.1993\n",
      "Epoch 34/100\n",
      "6/6 - 0s - loss: 0.6291 - hamming_loss: 0.1547 - val_loss: 0.6900 - val_hamming_loss: 0.2002\n",
      "Epoch 35/100\n",
      "6/6 - 0s - loss: 0.6248 - hamming_loss: 0.1582 - val_loss: 0.6929 - val_hamming_loss: 0.1949\n",
      "Epoch 36/100\n",
      "6/6 - 0s - loss: 0.6217 - hamming_loss: 0.1565 - val_loss: 0.6951 - val_hamming_loss: 0.1993\n",
      "Epoch 37/100\n",
      "6/6 - 0s - loss: 0.6182 - hamming_loss: 0.1543 - val_loss: 0.6962 - val_hamming_loss: 0.1976\n",
      "Epoch 38/100\n",
      "6/6 - 0s - loss: 0.6144 - hamming_loss: 0.1521 - val_loss: 0.6888 - val_hamming_loss: 0.2002\n",
      "Epoch 39/100\n",
      "6/6 - 0s - loss: 0.6106 - hamming_loss: 0.1521 - val_loss: 0.6866 - val_hamming_loss: 0.1984\n",
      "Epoch 40/100\n",
      "6/6 - 0s - loss: 0.6072 - hamming_loss: 0.1486 - val_loss: 0.6869 - val_hamming_loss: 0.2002\n",
      "Epoch 41/100\n",
      "6/6 - 0s - loss: 0.6041 - hamming_loss: 0.1486 - val_loss: 0.6909 - val_hamming_loss: 0.1932\n",
      "Epoch 42/100\n",
      "6/6 - 0s - loss: 0.6010 - hamming_loss: 0.1499 - val_loss: 0.6886 - val_hamming_loss: 0.1941\n",
      "Epoch 43/100\n",
      "6/6 - 0s - loss: 0.5980 - hamming_loss: 0.1486 - val_loss: 0.6884 - val_hamming_loss: 0.1976\n",
      "Epoch 44/100\n",
      "6/6 - 0s - loss: 0.5953 - hamming_loss: 0.1538 - val_loss: 0.6907 - val_hamming_loss: 0.1932\n",
      "Epoch 45/100\n",
      "6/6 - 0s - loss: 0.5933 - hamming_loss: 0.1565 - val_loss: 0.6943 - val_hamming_loss: 0.1949\n",
      "Epoch 46/100\n",
      "6/6 - 0s - loss: 0.5932 - hamming_loss: 0.1482 - val_loss: 0.6854 - val_hamming_loss: 0.1914\n",
      "Epoch 47/100\n",
      "6/6 - 0s - loss: 0.5898 - hamming_loss: 0.1521 - val_loss: 0.6937 - val_hamming_loss: 0.2133\n",
      "Epoch 48/100\n",
      "6/6 - 0s - loss: 0.5900 - hamming_loss: 0.1552 - val_loss: 0.6898 - val_hamming_loss: 0.1897\n",
      "Epoch 49/100\n",
      "6/6 - 0s - loss: 0.5859 - hamming_loss: 0.1490 - val_loss: 0.6921 - val_hamming_loss: 0.1879\n",
      "Epoch 50/100\n",
      "6/6 - 0s - loss: 0.5830 - hamming_loss: 0.1477 - val_loss: 0.6887 - val_hamming_loss: 0.1923\n",
      "Epoch 51/100\n",
      "6/6 - 0s - loss: 0.5805 - hamming_loss: 0.1508 - val_loss: 0.6881 - val_hamming_loss: 0.1906\n",
      "Epoch 52/100\n",
      "6/6 - 0s - loss: 0.5781 - hamming_loss: 0.1473 - val_loss: 0.6904 - val_hamming_loss: 0.1862\n",
      "Epoch 53/100\n",
      "6/6 - 0s - loss: 0.5760 - hamming_loss: 0.1451 - val_loss: 0.6875 - val_hamming_loss: 0.1906\n",
      "Epoch 54/100\n",
      "6/6 - 0s - loss: 0.5738 - hamming_loss: 0.1499 - val_loss: 0.6858 - val_hamming_loss: 0.1888\n",
      "Epoch 55/100\n",
      "6/6 - 0s - loss: 0.5716 - hamming_loss: 0.1464 - val_loss: 0.6877 - val_hamming_loss: 0.1871\n",
      "Epoch 56/100\n",
      "6/6 - 0s - loss: 0.5695 - hamming_loss: 0.1469 - val_loss: 0.6861 - val_hamming_loss: 0.1906\n",
      "Epoch 57/100\n",
      "6/6 - 0s - loss: 0.5674 - hamming_loss: 0.1442 - val_loss: 0.6876 - val_hamming_loss: 0.1897\n",
      "Epoch 58/100\n",
      "6/6 - 0s - loss: 0.5652 - hamming_loss: 0.1429 - val_loss: 0.6862 - val_hamming_loss: 0.1879\n",
      "Epoch 59/100\n",
      "6/6 - 0s - loss: 0.5631 - hamming_loss: 0.1416 - val_loss: 0.6857 - val_hamming_loss: 0.1888\n",
      "Epoch 60/100\n",
      "6/6 - 0s - loss: 0.5609 - hamming_loss: 0.1407 - val_loss: 0.6873 - val_hamming_loss: 0.1888\n",
      "Epoch 61/100\n",
      "6/6 - 0s - loss: 0.5587 - hamming_loss: 0.1381 - val_loss: 0.6854 - val_hamming_loss: 0.1879\n",
      "Epoch 62/100\n",
      "6/6 - 0s - loss: 0.5565 - hamming_loss: 0.1320 - val_loss: 0.6858 - val_hamming_loss: 0.1862\n",
      "Epoch 63/100\n",
      "6/6 - 0s - loss: 0.5544 - hamming_loss: 0.1307 - val_loss: 0.6832 - val_hamming_loss: 0.1853\n",
      "Epoch 64/100\n",
      "6/6 - 0s - loss: 0.5522 - hamming_loss: 0.1311 - val_loss: 0.6825 - val_hamming_loss: 0.1853\n",
      "Epoch 65/100\n",
      "6/6 - 0s - loss: 0.5502 - hamming_loss: 0.1307 - val_loss: 0.6848 - val_hamming_loss: 0.1836\n",
      "Epoch 66/100\n",
      "6/6 - 0s - loss: 0.5481 - hamming_loss: 0.1307 - val_loss: 0.6868 - val_hamming_loss: 0.1853\n",
      "Epoch 67/100\n",
      "6/6 - 0s - loss: 0.5460 - hamming_loss: 0.1281 - val_loss: 0.6838 - val_hamming_loss: 0.1836\n",
      "Epoch 68/100\n",
      "6/6 - 0s - loss: 0.5441 - hamming_loss: 0.1259 - val_loss: 0.6874 - val_hamming_loss: 0.1888\n",
      "Epoch 69/100\n",
      "6/6 - 0s - loss: 0.5421 - hamming_loss: 0.1237 - val_loss: 0.6880 - val_hamming_loss: 0.1844\n",
      "Epoch 70/100\n",
      "6/6 - 0s - loss: 0.5417 - hamming_loss: 0.1241 - val_loss: 0.6878 - val_hamming_loss: 0.1766\n",
      "Epoch 71/100\n",
      "6/6 - 0s - loss: 0.5396 - hamming_loss: 0.1206 - val_loss: 0.6957 - val_hamming_loss: 0.1888\n",
      "Epoch 72/100\n",
      "6/6 - 0s - loss: 0.5378 - hamming_loss: 0.1193 - val_loss: 0.6890 - val_hamming_loss: 0.1809\n",
      "Epoch 73/100\n",
      "6/6 - 0s - loss: 0.5361 - hamming_loss: 0.1136 - val_loss: 0.6818 - val_hamming_loss: 0.1897\n",
      "Epoch 74/100\n",
      "6/6 - 0s - loss: 0.5347 - hamming_loss: 0.1171 - val_loss: 0.6881 - val_hamming_loss: 0.1801\n",
      "Epoch 75/100\n",
      "6/6 - 0s - loss: 0.5317 - hamming_loss: 0.1084 - val_loss: 0.6916 - val_hamming_loss: 0.1801\n",
      "Epoch 76/100\n",
      "6/6 - 0s - loss: 0.5306 - hamming_loss: 0.1062 - val_loss: 0.6953 - val_hamming_loss: 0.1827\n",
      "Epoch 77/100\n",
      "6/6 - 0s - loss: 0.5288 - hamming_loss: 0.1036 - val_loss: 0.6929 - val_hamming_loss: 0.1836\n",
      "Epoch 78/100\n",
      "6/6 - 0s - loss: 0.5267 - hamming_loss: 0.1001 - val_loss: 0.6913 - val_hamming_loss: 0.1853\n",
      "Epoch 79/100\n",
      "6/6 - 0s - loss: 0.5247 - hamming_loss: 0.0948 - val_loss: 0.6890 - val_hamming_loss: 0.1783\n",
      "Epoch 80/100\n",
      "6/6 - 0s - loss: 0.5230 - hamming_loss: 0.0913 - val_loss: 0.6905 - val_hamming_loss: 0.1844\n",
      "Epoch 81/100\n",
      "6/6 - 0s - loss: 0.5212 - hamming_loss: 0.0896 - val_loss: 0.6870 - val_hamming_loss: 0.1792\n",
      "Epoch 82/100\n",
      "6/6 - 0s - loss: 0.5198 - hamming_loss: 0.0870 - val_loss: 0.6904 - val_hamming_loss: 0.1844\n",
      "Epoch 83/100\n",
      "6/6 - 0s - loss: 0.5180 - hamming_loss: 0.0865 - val_loss: 0.6857 - val_hamming_loss: 0.1774\n",
      "Epoch 84/100\n",
      "6/6 - 0s - loss: 0.5166 - hamming_loss: 0.0839 - val_loss: 0.6914 - val_hamming_loss: 0.1827\n",
      "Epoch 85/100\n",
      "6/6 - 0s - loss: 0.5151 - hamming_loss: 0.0848 - val_loss: 0.6873 - val_hamming_loss: 0.1748\n",
      "Epoch 86/100\n",
      "6/6 - 0s - loss: 0.5133 - hamming_loss: 0.0822 - val_loss: 0.6886 - val_hamming_loss: 0.1818\n",
      "Epoch 87/100\n",
      "6/6 - 0s - loss: 0.5118 - hamming_loss: 0.0809 - val_loss: 0.6867 - val_hamming_loss: 0.1748\n",
      "Epoch 88/100\n",
      "6/6 - 0s - loss: 0.5102 - hamming_loss: 0.0787 - val_loss: 0.6891 - val_hamming_loss: 0.1801\n",
      "Epoch 89/100\n",
      "6/6 - 0s - loss: 0.5088 - hamming_loss: 0.0787 - val_loss: 0.6851 - val_hamming_loss: 0.1705\n",
      "Epoch 90/100\n",
      "6/6 - 0s - loss: 0.5073 - hamming_loss: 0.0756 - val_loss: 0.6883 - val_hamming_loss: 0.1783\n",
      "Epoch 91/100\n",
      "6/6 - 0s - loss: 0.5060 - hamming_loss: 0.0774 - val_loss: 0.6857 - val_hamming_loss: 0.1713\n",
      "Epoch 92/100\n",
      "6/6 - 0s - loss: 0.5044 - hamming_loss: 0.0752 - val_loss: 0.6882 - val_hamming_loss: 0.1801\n",
      "Epoch 93/100\n",
      "6/6 - 0s - loss: 0.5029 - hamming_loss: 0.0752 - val_loss: 0.6835 - val_hamming_loss: 0.1696\n",
      "Epoch 94/100\n",
      "6/6 - 0s - loss: 0.5017 - hamming_loss: 0.0747 - val_loss: 0.6875 - val_hamming_loss: 0.1774\n",
      "Epoch 95/100\n",
      "6/6 - 0s - loss: 0.5001 - hamming_loss: 0.0721 - val_loss: 0.6853 - val_hamming_loss: 0.1705\n",
      "Epoch 96/100\n",
      "6/6 - 0s - loss: 0.4986 - hamming_loss: 0.0708 - val_loss: 0.6853 - val_hamming_loss: 0.1748\n",
      "Epoch 97/100\n",
      "6/6 - 0s - loss: 0.4969 - hamming_loss: 0.0712 - val_loss: 0.6884 - val_hamming_loss: 0.1731\n",
      "Epoch 98/100\n",
      "6/6 - 0s - loss: 0.4955 - hamming_loss: 0.0699 - val_loss: 0.6830 - val_hamming_loss: 0.1722\n",
      "Epoch 99/100\n",
      "6/6 - 0s - loss: 0.4942 - hamming_loss: 0.0677 - val_loss: 0.6890 - val_hamming_loss: 0.1722\n",
      "Epoch 100/100\n",
      "6/6 - 0s - loss: 0.4930 - hamming_loss: 0.0730 - val_loss: 0.6858 - val_hamming_loss: 0.1722\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_bpmll_RNN_lr001 = model_bpmll_biLSTM.fit(train_padded_hasLabel, Y_train_hasLabel, epochs = 100, \n",
    "                       validation_data = (test_padded_hasLabel, Y_test_hasLabel), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_bpmll_RNN_lr001_df = pd.DataFrame(history_bpmll_RNN_lr001.history)\n",
    "#with open(\"Reduced Data Eval Metrics/BPMLL RNN/history_bpmll_RNN_lr001.json\", \"w\") as outfile: \n",
    "#    history_bpmll_RNN_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_bpmll_biLSTM.predict(train_padded_hasLabel)\n",
    "Y_test_pred = model_bpmll_biLSTM.predict(test_padded_hasLabel)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train_hasLabel, Y_test_pred, t_range)\n",
    "bpmll_RNN_withThreshold = metrics.hamming_loss(Y_test_hasLabel, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_lr001' : ce_FF_withThreshold,\n",
    "                                                        'bpmll_FF_lr001' : bpmll_FF_withThreshold,\n",
    "                                                        'bpmll_RNN_lr001' : bpmll_RNN_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "#with open(\"Reduced Data Eval Metrics/val_hamming_loss_withThreshold_lr001.json\", \"w\") as outfile: \n",
    "#    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_lr001</th>\n",
       "      <th>bpmll_FF_lr001</th>\n",
       "      <th>bpmll_RNN_lr001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.185315</td>\n",
       "      <td>0.257867</td>\n",
       "      <td>0.204545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_lr001  bpmll_FF_lr001  bpmll_RNN_lr001\n",
       "0     0.185315        0.257867         0.204545"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models on Full Dataset (some instances have no labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the full tfidf dataset\n",
    "file_object = open('../BP-MLL Text Categorization/tfidf_trainTest_data.json',)\n",
    "tfidf_data_full = json.load(file_object)\n",
    "X_train = np.array(tfidf_data_full['X_train'])\n",
    "X_test = np.array(tfidf_data_full['X_test'])\n",
    "Y_train = np.array(tfidf_data_full['Y_train'])\n",
    "Y_test = np.array(tfidf_data_full['Y_test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed-Forward Cross-Entropy Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Use same architecture as the previous cross-entropy feed-forward network and train on full dataset\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_ce_FF_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Dense(32, activation = 'relu'),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_ce_FF_full.compile(optimizer = optim_func,\n",
    "              loss = 'binary_crossentropy', metrics = metric\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 1s - loss: 0.6951 - hamming_loss: 0.3726 - val_loss: 0.6761 - val_hamming_loss: 0.4183\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 0.6628 - hamming_loss: 0.3898 - val_loss: 0.6565 - val_hamming_loss: 0.3510\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 0.6383 - hamming_loss: 0.3398 - val_loss: 0.6372 - val_hamming_loss: 0.3093\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 0.6048 - hamming_loss: 0.2823 - val_loss: 0.6169 - val_hamming_loss: 0.2764\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 0.5818 - hamming_loss: 0.2669 - val_loss: 0.5955 - val_hamming_loss: 0.2596\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 0.5500 - hamming_loss: 0.2419 - val_loss: 0.5735 - val_hamming_loss: 0.2420\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 0.5212 - hamming_loss: 0.2177 - val_loss: 0.5510 - val_hamming_loss: 0.2292\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 0.4909 - hamming_loss: 0.2070 - val_loss: 0.5297 - val_hamming_loss: 0.2115\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 0.4653 - hamming_loss: 0.1824 - val_loss: 0.5110 - val_hamming_loss: 0.1955\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 0.4542 - hamming_loss: 0.1725 - val_loss: 0.4951 - val_hamming_loss: 0.1923\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 0.4280 - hamming_loss: 0.1665 - val_loss: 0.4809 - val_hamming_loss: 0.1787\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 0.4113 - hamming_loss: 0.1614 - val_loss: 0.4681 - val_hamming_loss: 0.1627\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 0.3973 - hamming_loss: 0.1515 - val_loss: 0.4562 - val_hamming_loss: 0.1603\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 0.3764 - hamming_loss: 0.1431 - val_loss: 0.4467 - val_hamming_loss: 0.1554\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 0.3616 - hamming_loss: 0.1400 - val_loss: 0.4385 - val_hamming_loss: 0.1514\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 0.3317 - hamming_loss: 0.1205 - val_loss: 0.4311 - val_hamming_loss: 0.1530\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 0.3350 - hamming_loss: 0.1205 - val_loss: 0.4235 - val_hamming_loss: 0.1538\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 0.3112 - hamming_loss: 0.1150 - val_loss: 0.4167 - val_hamming_loss: 0.1514\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 0.3048 - hamming_loss: 0.1067 - val_loss: 0.4105 - val_hamming_loss: 0.1506\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 0.2985 - hamming_loss: 0.1158 - val_loss: 0.4052 - val_hamming_loss: 0.1506\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 0.2807 - hamming_loss: 0.1063 - val_loss: 0.4007 - val_hamming_loss: 0.1490\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 0.2681 - hamming_loss: 0.1015 - val_loss: 0.3966 - val_hamming_loss: 0.1482\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 0.2630 - hamming_loss: 0.0975 - val_loss: 0.3932 - val_hamming_loss: 0.1482\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 0.2643 - hamming_loss: 0.0928 - val_loss: 0.3900 - val_hamming_loss: 0.1482\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 0.2579 - hamming_loss: 0.0932 - val_loss: 0.3870 - val_hamming_loss: 0.1482\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 0.2466 - hamming_loss: 0.0983 - val_loss: 0.3845 - val_hamming_loss: 0.1474\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 0.2372 - hamming_loss: 0.0888 - val_loss: 0.3816 - val_hamming_loss: 0.1458\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 0.2385 - hamming_loss: 0.0876 - val_loss: 0.3789 - val_hamming_loss: 0.1442\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 0.2200 - hamming_loss: 0.0738 - val_loss: 0.3768 - val_hamming_loss: 0.1442\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 0.2173 - hamming_loss: 0.0817 - val_loss: 0.3748 - val_hamming_loss: 0.1442\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 0.2163 - hamming_loss: 0.0777 - val_loss: 0.3727 - val_hamming_loss: 0.1434\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 0.1967 - hamming_loss: 0.0698 - val_loss: 0.3708 - val_hamming_loss: 0.1426\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 0.2093 - hamming_loss: 0.0761 - val_loss: 0.3694 - val_hamming_loss: 0.1434\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 0.1882 - hamming_loss: 0.0670 - val_loss: 0.3686 - val_hamming_loss: 0.1434\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 0.2010 - hamming_loss: 0.0793 - val_loss: 0.3675 - val_hamming_loss: 0.1418\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 0.1982 - hamming_loss: 0.0749 - val_loss: 0.3662 - val_hamming_loss: 0.1418\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 0.1802 - hamming_loss: 0.0698 - val_loss: 0.3654 - val_hamming_loss: 0.1418\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 0.1781 - hamming_loss: 0.0662 - val_loss: 0.3648 - val_hamming_loss: 0.1402\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 0.1658 - hamming_loss: 0.0619 - val_loss: 0.3639 - val_hamming_loss: 0.1394\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 0.1589 - hamming_loss: 0.0571 - val_loss: 0.3632 - val_hamming_loss: 0.1386\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 0.1758 - hamming_loss: 0.0690 - val_loss: 0.3629 - val_hamming_loss: 0.1394\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 0.1638 - hamming_loss: 0.0607 - val_loss: 0.3624 - val_hamming_loss: 0.1362\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 0.1601 - hamming_loss: 0.0583 - val_loss: 0.3627 - val_hamming_loss: 0.1354\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 0.1638 - hamming_loss: 0.0626 - val_loss: 0.3623 - val_hamming_loss: 0.1338\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 0.1663 - hamming_loss: 0.0619 - val_loss: 0.3617 - val_hamming_loss: 0.1322\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 0.1494 - hamming_loss: 0.0523 - val_loss: 0.3611 - val_hamming_loss: 0.1322\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 0.1388 - hamming_loss: 0.0472 - val_loss: 0.3611 - val_hamming_loss: 0.1330\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 0.1484 - hamming_loss: 0.0603 - val_loss: 0.3610 - val_hamming_loss: 0.1314\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 0.1429 - hamming_loss: 0.0535 - val_loss: 0.3603 - val_hamming_loss: 0.1290\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 0.1353 - hamming_loss: 0.0468 - val_loss: 0.3605 - val_hamming_loss: 0.1290\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 0.1471 - hamming_loss: 0.0496 - val_loss: 0.3616 - val_hamming_loss: 0.1282\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 0.1407 - hamming_loss: 0.0460 - val_loss: 0.3627 - val_hamming_loss: 0.1290\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 0.1378 - hamming_loss: 0.0492 - val_loss: 0.3630 - val_hamming_loss: 0.1290\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 0.1437 - hamming_loss: 0.0547 - val_loss: 0.3632 - val_hamming_loss: 0.1290\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 0.1331 - hamming_loss: 0.0500 - val_loss: 0.3639 - val_hamming_loss: 0.1298\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 0.1391 - hamming_loss: 0.0579 - val_loss: 0.3637 - val_hamming_loss: 0.1306\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 0.1240 - hamming_loss: 0.0476 - val_loss: 0.3638 - val_hamming_loss: 0.1306\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 0.1405 - hamming_loss: 0.0559 - val_loss: 0.3638 - val_hamming_loss: 0.1306\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 0.1316 - hamming_loss: 0.0484 - val_loss: 0.3641 - val_hamming_loss: 0.1322\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 0.1333 - hamming_loss: 0.0508 - val_loss: 0.3642 - val_hamming_loss: 0.1298\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 0.1294 - hamming_loss: 0.0492 - val_loss: 0.3646 - val_hamming_loss: 0.1290\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 0.1257 - hamming_loss: 0.0416 - val_loss: 0.3653 - val_hamming_loss: 0.1290\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 0.1134 - hamming_loss: 0.0420 - val_loss: 0.3658 - val_hamming_loss: 0.1306\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 0.1283 - hamming_loss: 0.0504 - val_loss: 0.3658 - val_hamming_loss: 0.1290\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 0.1370 - hamming_loss: 0.0492 - val_loss: 0.3652 - val_hamming_loss: 0.1290\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 0.1156 - hamming_loss: 0.0385 - val_loss: 0.3659 - val_hamming_loss: 0.1298\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 0.1201 - hamming_loss: 0.0484 - val_loss: 0.3667 - val_hamming_loss: 0.1290\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 0.1128 - hamming_loss: 0.0412 - val_loss: 0.3677 - val_hamming_loss: 0.1290\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 0.1122 - hamming_loss: 0.0400 - val_loss: 0.3683 - val_hamming_loss: 0.1290\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 0.1157 - hamming_loss: 0.0432 - val_loss: 0.3692 - val_hamming_loss: 0.1290\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 0.1192 - hamming_loss: 0.0444 - val_loss: 0.3696 - val_hamming_loss: 0.1282\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 0.1160 - hamming_loss: 0.0444 - val_loss: 0.3698 - val_hamming_loss: 0.1274\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 0.1088 - hamming_loss: 0.0393 - val_loss: 0.3715 - val_hamming_loss: 0.1290\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 0.1153 - hamming_loss: 0.0444 - val_loss: 0.3732 - val_hamming_loss: 0.1290\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 0.1283 - hamming_loss: 0.0535 - val_loss: 0.3748 - val_hamming_loss: 0.1290\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 0.1139 - hamming_loss: 0.0456 - val_loss: 0.3759 - val_hamming_loss: 0.1290\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 0.1068 - hamming_loss: 0.0393 - val_loss: 0.3760 - val_hamming_loss: 0.1298\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 0.1099 - hamming_loss: 0.0456 - val_loss: 0.3759 - val_hamming_loss: 0.1298\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 0.1221 - hamming_loss: 0.0488 - val_loss: 0.3760 - val_hamming_loss: 0.1290\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 0.1155 - hamming_loss: 0.0464 - val_loss: 0.3756 - val_hamming_loss: 0.1298\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 0.1108 - hamming_loss: 0.0432 - val_loss: 0.3742 - val_hamming_loss: 0.1290\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 0.1030 - hamming_loss: 0.0404 - val_loss: 0.3734 - val_hamming_loss: 0.1274\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 0.0923 - hamming_loss: 0.0385 - val_loss: 0.3739 - val_hamming_loss: 0.1274\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 0.0989 - hamming_loss: 0.0377 - val_loss: 0.3744 - val_hamming_loss: 0.1282\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 0.1002 - hamming_loss: 0.0408 - val_loss: 0.3757 - val_hamming_loss: 0.1274\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 0.1033 - hamming_loss: 0.0373 - val_loss: 0.3768 - val_hamming_loss: 0.1282\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 0.0960 - hamming_loss: 0.0345 - val_loss: 0.3781 - val_hamming_loss: 0.1290\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 0.1040 - hamming_loss: 0.0377 - val_loss: 0.3790 - val_hamming_loss: 0.1282\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 0.1165 - hamming_loss: 0.0393 - val_loss: 0.3795 - val_hamming_loss: 0.1274\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 0.0900 - hamming_loss: 0.0333 - val_loss: 0.3787 - val_hamming_loss: 0.1282\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 0.0995 - hamming_loss: 0.0381 - val_loss: 0.3777 - val_hamming_loss: 0.1290\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 0.1049 - hamming_loss: 0.0416 - val_loss: 0.3770 - val_hamming_loss: 0.1274\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 0.1003 - hamming_loss: 0.0361 - val_loss: 0.3769 - val_hamming_loss: 0.1274\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 0.0918 - hamming_loss: 0.0353 - val_loss: 0.3774 - val_hamming_loss: 0.1266\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 0.0931 - hamming_loss: 0.0365 - val_loss: 0.3783 - val_hamming_loss: 0.1266\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 0.1028 - hamming_loss: 0.0428 - val_loss: 0.3795 - val_hamming_loss: 0.1274\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 0.0892 - hamming_loss: 0.0341 - val_loss: 0.3808 - val_hamming_loss: 0.1274\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 0.0880 - hamming_loss: 0.0297 - val_loss: 0.3821 - val_hamming_loss: 0.1266\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 0.0851 - hamming_loss: 0.0321 - val_loss: 0.3832 - val_hamming_loss: 0.1266\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 0.0842 - hamming_loss: 0.0317 - val_loss: 0.3848 - val_hamming_loss: 0.1266\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_FF_lr001_full = model_ce_FF_full.fit(X_train, Y_train, epochs = 100,\n",
    "                validation_data = (X_test, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_FF_lr001_full_df = pd.DataFrame(history_ce_FF_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy Feed Forward/history_ce_FF_lr001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_FF_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_ce_FF_full.predict(X_train)\n",
    "Y_test_pred = model_ce_FF_full.predict(X_test)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_FF_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Reccurrent Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the pre-processed data\n",
    "file_object = open('../RNN Text Categorization/RNN_data_dict.json',)\n",
    "RNN_data_dict = json.load(file_object)\n",
    "RNN_data_dict = ast.literal_eval(RNN_data_dict)\n",
    "train_padded = np.array(RNN_data_dict['train_padded'])\n",
    "test_padded = np.array(RNN_data_dict['test_padded'])\n",
    "Y_train = np.array(RNN_data_dict['Y_train'])\n",
    "Y_test = np.array(RNN_data_dict['Y_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the LSTM RNN architecture\n",
    "tf.random.set_seed(123)\n",
    "num_labels = 13\n",
    "\n",
    "model_LSTM_full = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Embedding(num_unique_words, 32, input_length = max_length),\n",
    "    tf.keras.layers.LSTM(16, return_sequences = False, return_state = False),\n",
    "    #tf.keras.layers.Dropout(0.5),\n",
    "    tf.keras.layers.Dense(num_labels, activation = 'sigmoid')\n",
    "])\n",
    "\n",
    "optim_func = tf.keras.optimizers.Adam(lr = 0.001)\n",
    "\n",
    "model_LSTM_full.compile(loss = 'binary_crossentropy', optimizer = optim_func, metrics = metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "7/7 - 3s - loss: 0.6923 - hamming_loss: 0.4090 - val_loss: 0.6865 - val_hamming_loss: 0.3421\n",
      "Epoch 2/100\n",
      "7/7 - 0s - loss: 0.6830 - hamming_loss: 0.2950 - val_loss: 0.6763 - val_hamming_loss: 0.2043\n",
      "Epoch 3/100\n",
      "7/7 - 0s - loss: 0.6716 - hamming_loss: 0.1864 - val_loss: 0.6616 - val_hamming_loss: 0.1723\n",
      "Epoch 4/100\n",
      "7/7 - 0s - loss: 0.6542 - hamming_loss: 0.1792 - val_loss: 0.6368 - val_hamming_loss: 0.1723\n",
      "Epoch 5/100\n",
      "7/7 - 0s - loss: 0.6246 - hamming_loss: 0.1792 - val_loss: 0.5958 - val_hamming_loss: 0.1723\n",
      "Epoch 6/100\n",
      "7/7 - 0s - loss: 0.5810 - hamming_loss: 0.1792 - val_loss: 0.5540 - val_hamming_loss: 0.1723\n",
      "Epoch 7/100\n",
      "7/7 - 0s - loss: 0.5462 - hamming_loss: 0.1792 - val_loss: 0.5280 - val_hamming_loss: 0.1723\n",
      "Epoch 8/100\n",
      "7/7 - 0s - loss: 0.5233 - hamming_loss: 0.1792 - val_loss: 0.5068 - val_hamming_loss: 0.1723\n",
      "Epoch 9/100\n",
      "7/7 - 0s - loss: 0.5037 - hamming_loss: 0.1792 - val_loss: 0.4890 - val_hamming_loss: 0.1723\n",
      "Epoch 10/100\n",
      "7/7 - 0s - loss: 0.4869 - hamming_loss: 0.1792 - val_loss: 0.4745 - val_hamming_loss: 0.1723\n",
      "Epoch 11/100\n",
      "7/7 - 0s - loss: 0.4730 - hamming_loss: 0.1792 - val_loss: 0.4625 - val_hamming_loss: 0.1723\n",
      "Epoch 12/100\n",
      "7/7 - 0s - loss: 0.4606 - hamming_loss: 0.1792 - val_loss: 0.4523 - val_hamming_loss: 0.1723\n",
      "Epoch 13/100\n",
      "7/7 - 0s - loss: 0.4504 - hamming_loss: 0.1792 - val_loss: 0.4434 - val_hamming_loss: 0.1723\n",
      "Epoch 14/100\n",
      "7/7 - 0s - loss: 0.4418 - hamming_loss: 0.1792 - val_loss: 0.4365 - val_hamming_loss: 0.1723\n",
      "Epoch 15/100\n",
      "7/7 - 0s - loss: 0.4349 - hamming_loss: 0.1792 - val_loss: 0.4314 - val_hamming_loss: 0.1723\n",
      "Epoch 16/100\n",
      "7/7 - 0s - loss: 0.4295 - hamming_loss: 0.1792 - val_loss: 0.4276 - val_hamming_loss: 0.1723\n",
      "Epoch 17/100\n",
      "7/7 - 0s - loss: 0.4250 - hamming_loss: 0.1792 - val_loss: 0.4240 - val_hamming_loss: 0.1723\n",
      "Epoch 18/100\n",
      "7/7 - 0s - loss: 0.4214 - hamming_loss: 0.1792 - val_loss: 0.4215 - val_hamming_loss: 0.1723\n",
      "Epoch 19/100\n",
      "7/7 - 0s - loss: 0.4185 - hamming_loss: 0.1792 - val_loss: 0.4193 - val_hamming_loss: 0.1723\n",
      "Epoch 20/100\n",
      "7/7 - 0s - loss: 0.4164 - hamming_loss: 0.1792 - val_loss: 0.4178 - val_hamming_loss: 0.1723\n",
      "Epoch 21/100\n",
      "7/7 - 0s - loss: 0.4148 - hamming_loss: 0.1792 - val_loss: 0.4169 - val_hamming_loss: 0.1723\n",
      "Epoch 22/100\n",
      "7/7 - 0s - loss: 0.4133 - hamming_loss: 0.1792 - val_loss: 0.4162 - val_hamming_loss: 0.1723\n",
      "Epoch 23/100\n",
      "7/7 - 0s - loss: 0.4121 - hamming_loss: 0.1792 - val_loss: 0.4159 - val_hamming_loss: 0.1723\n",
      "Epoch 24/100\n",
      "7/7 - 0s - loss: 0.4109 - hamming_loss: 0.1792 - val_loss: 0.4150 - val_hamming_loss: 0.1723\n",
      "Epoch 25/100\n",
      "7/7 - 0s - loss: 0.4100 - hamming_loss: 0.1792 - val_loss: 0.4143 - val_hamming_loss: 0.1723\n",
      "Epoch 26/100\n",
      "7/7 - 0s - loss: 0.4092 - hamming_loss: 0.1792 - val_loss: 0.4138 - val_hamming_loss: 0.1723\n",
      "Epoch 27/100\n",
      "7/7 - 0s - loss: 0.4086 - hamming_loss: 0.1792 - val_loss: 0.4134 - val_hamming_loss: 0.1723\n",
      "Epoch 28/100\n",
      "7/7 - 0s - loss: 0.4080 - hamming_loss: 0.1792 - val_loss: 0.4136 - val_hamming_loss: 0.1723\n",
      "Epoch 29/100\n",
      "7/7 - 0s - loss: 0.4076 - hamming_loss: 0.1792 - val_loss: 0.4139 - val_hamming_loss: 0.1723\n",
      "Epoch 30/100\n",
      "7/7 - 0s - loss: 0.4072 - hamming_loss: 0.1792 - val_loss: 0.4142 - val_hamming_loss: 0.1723\n",
      "Epoch 31/100\n",
      "7/7 - 0s - loss: 0.4068 - hamming_loss: 0.1792 - val_loss: 0.4139 - val_hamming_loss: 0.1723\n",
      "Epoch 32/100\n",
      "7/7 - 0s - loss: 0.4064 - hamming_loss: 0.1792 - val_loss: 0.4132 - val_hamming_loss: 0.1723\n",
      "Epoch 33/100\n",
      "7/7 - 0s - loss: 0.4058 - hamming_loss: 0.1792 - val_loss: 0.4125 - val_hamming_loss: 0.1723\n",
      "Epoch 34/100\n",
      "7/7 - 0s - loss: 0.4055 - hamming_loss: 0.1792 - val_loss: 0.4124 - val_hamming_loss: 0.1723\n",
      "Epoch 35/100\n",
      "7/7 - 0s - loss: 0.4053 - hamming_loss: 0.1792 - val_loss: 0.4118 - val_hamming_loss: 0.1723\n",
      "Epoch 36/100\n",
      "7/7 - 0s - loss: 0.4051 - hamming_loss: 0.1792 - val_loss: 0.4114 - val_hamming_loss: 0.1723\n",
      "Epoch 37/100\n",
      "7/7 - 0s - loss: 0.4048 - hamming_loss: 0.1792 - val_loss: 0.4114 - val_hamming_loss: 0.1723\n",
      "Epoch 38/100\n",
      "7/7 - 0s - loss: 0.4047 - hamming_loss: 0.1792 - val_loss: 0.4109 - val_hamming_loss: 0.1723\n",
      "Epoch 39/100\n",
      "7/7 - 0s - loss: 0.4045 - hamming_loss: 0.1792 - val_loss: 0.4104 - val_hamming_loss: 0.1723\n",
      "Epoch 40/100\n",
      "7/7 - 0s - loss: 0.4047 - hamming_loss: 0.1792 - val_loss: 0.4100 - val_hamming_loss: 0.1723\n",
      "Epoch 41/100\n",
      "7/7 - 0s - loss: 0.4045 - hamming_loss: 0.1792 - val_loss: 0.4100 - val_hamming_loss: 0.1723\n",
      "Epoch 42/100\n",
      "7/7 - 0s - loss: 0.4045 - hamming_loss: 0.1792 - val_loss: 0.4103 - val_hamming_loss: 0.1723\n",
      "Epoch 43/100\n",
      "7/7 - 0s - loss: 0.4042 - hamming_loss: 0.1792 - val_loss: 0.4104 - val_hamming_loss: 0.1723\n",
      "Epoch 44/100\n",
      "7/7 - 0s - loss: 0.4041 - hamming_loss: 0.1792 - val_loss: 0.4105 - val_hamming_loss: 0.1723\n",
      "Epoch 45/100\n",
      "7/7 - 0s - loss: 0.4040 - hamming_loss: 0.1792 - val_loss: 0.4105 - val_hamming_loss: 0.1723\n",
      "Epoch 46/100\n",
      "7/7 - 0s - loss: 0.4040 - hamming_loss: 0.1792 - val_loss: 0.4104 - val_hamming_loss: 0.1723\n",
      "Epoch 47/100\n",
      "7/7 - 0s - loss: 0.4039 - hamming_loss: 0.1792 - val_loss: 0.4106 - val_hamming_loss: 0.1723\n",
      "Epoch 48/100\n",
      "7/7 - 0s - loss: 0.4037 - hamming_loss: 0.1792 - val_loss: 0.4109 - val_hamming_loss: 0.1723\n",
      "Epoch 49/100\n",
      "7/7 - 0s - loss: 0.4036 - hamming_loss: 0.1792 - val_loss: 0.4108 - val_hamming_loss: 0.1723\n",
      "Epoch 50/100\n",
      "7/7 - 0s - loss: 0.4035 - hamming_loss: 0.1792 - val_loss: 0.4107 - val_hamming_loss: 0.1723\n",
      "Epoch 51/100\n",
      "7/7 - 0s - loss: 0.4033 - hamming_loss: 0.1792 - val_loss: 0.4107 - val_hamming_loss: 0.1723\n",
      "Epoch 52/100\n",
      "7/7 - 0s - loss: 0.4033 - hamming_loss: 0.1792 - val_loss: 0.4110 - val_hamming_loss: 0.1723\n",
      "Epoch 53/100\n",
      "7/7 - 0s - loss: 0.4034 - hamming_loss: 0.1792 - val_loss: 0.4110 - val_hamming_loss: 0.1723\n",
      "Epoch 54/100\n",
      "7/7 - 0s - loss: 0.4032 - hamming_loss: 0.1792 - val_loss: 0.4107 - val_hamming_loss: 0.1723\n",
      "Epoch 55/100\n",
      "7/7 - 0s - loss: 0.4030 - hamming_loss: 0.1792 - val_loss: 0.4104 - val_hamming_loss: 0.1723\n",
      "Epoch 56/100\n",
      "7/7 - 0s - loss: 0.4029 - hamming_loss: 0.1792 - val_loss: 0.4099 - val_hamming_loss: 0.1723\n",
      "Epoch 57/100\n",
      "7/7 - 0s - loss: 0.4028 - hamming_loss: 0.1792 - val_loss: 0.4093 - val_hamming_loss: 0.1723\n",
      "Epoch 58/100\n",
      "7/7 - 0s - loss: 0.4028 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 59/100\n",
      "7/7 - 0s - loss: 0.4028 - hamming_loss: 0.1792 - val_loss: 0.4089 - val_hamming_loss: 0.1723\n",
      "Epoch 60/100\n",
      "7/7 - 0s - loss: 0.4027 - hamming_loss: 0.1792 - val_loss: 0.4089 - val_hamming_loss: 0.1723\n",
      "Epoch 61/100\n",
      "7/7 - 0s - loss: 0.4027 - hamming_loss: 0.1792 - val_loss: 0.4089 - val_hamming_loss: 0.1723\n",
      "Epoch 62/100\n",
      "7/7 - 0s - loss: 0.4026 - hamming_loss: 0.1792 - val_loss: 0.4088 - val_hamming_loss: 0.1723\n",
      "Epoch 63/100\n",
      "7/7 - 0s - loss: 0.4025 - hamming_loss: 0.1792 - val_loss: 0.4088 - val_hamming_loss: 0.1723\n",
      "Epoch 64/100\n",
      "7/7 - 0s - loss: 0.4024 - hamming_loss: 0.1792 - val_loss: 0.4087 - val_hamming_loss: 0.1723\n",
      "Epoch 65/100\n",
      "7/7 - 0s - loss: 0.4025 - hamming_loss: 0.1792 - val_loss: 0.4084 - val_hamming_loss: 0.1723\n",
      "Epoch 66/100\n",
      "7/7 - 0s - loss: 0.4025 - hamming_loss: 0.1792 - val_loss: 0.4084 - val_hamming_loss: 0.1723\n",
      "Epoch 67/100\n",
      "7/7 - 0s - loss: 0.4024 - hamming_loss: 0.1792 - val_loss: 0.4087 - val_hamming_loss: 0.1723\n",
      "Epoch 68/100\n",
      "7/7 - 0s - loss: 0.4022 - hamming_loss: 0.1792 - val_loss: 0.4089 - val_hamming_loss: 0.1723\n",
      "Epoch 69/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4091 - val_hamming_loss: 0.1723\n",
      "Epoch 70/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4088 - val_hamming_loss: 0.1723\n",
      "Epoch 71/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4089 - val_hamming_loss: 0.1723\n",
      "Epoch 72/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 73/100\n",
      "7/7 - 0s - loss: 0.4020 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 74/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 75/100\n",
      "7/7 - 0s - loss: 0.4023 - hamming_loss: 0.1792 - val_loss: 0.4088 - val_hamming_loss: 0.1723\n",
      "Epoch 76/100\n",
      "7/7 - 0s - loss: 0.4026 - hamming_loss: 0.1792 - val_loss: 0.4086 - val_hamming_loss: 0.1723\n",
      "Epoch 77/100\n",
      "7/7 - 0s - loss: 0.4025 - hamming_loss: 0.1792 - val_loss: 0.4083 - val_hamming_loss: 0.1723\n",
      "Epoch 78/100\n",
      "7/7 - 0s - loss: 0.4025 - hamming_loss: 0.1792 - val_loss: 0.4079 - val_hamming_loss: 0.1723\n",
      "Epoch 79/100\n",
      "7/7 - 0s - loss: 0.4022 - hamming_loss: 0.1792 - val_loss: 0.4079 - val_hamming_loss: 0.1723\n",
      "Epoch 80/100\n",
      "7/7 - 0s - loss: 0.4022 - hamming_loss: 0.1792 - val_loss: 0.4082 - val_hamming_loss: 0.1723\n",
      "Epoch 81/100\n",
      "7/7 - 0s - loss: 0.4020 - hamming_loss: 0.1792 - val_loss: 0.4082 - val_hamming_loss: 0.1723\n",
      "Epoch 82/100\n",
      "7/7 - 0s - loss: 0.4021 - hamming_loss: 0.1792 - val_loss: 0.4080 - val_hamming_loss: 0.1723\n",
      "Epoch 83/100\n",
      "7/7 - 0s - loss: 0.4020 - hamming_loss: 0.1792 - val_loss: 0.4081 - val_hamming_loss: 0.1723\n",
      "Epoch 84/100\n",
      "7/7 - 0s - loss: 0.4019 - hamming_loss: 0.1792 - val_loss: 0.4082 - val_hamming_loss: 0.1723\n",
      "Epoch 85/100\n",
      "7/7 - 0s - loss: 0.4019 - hamming_loss: 0.1792 - val_loss: 0.4084 - val_hamming_loss: 0.1723\n",
      "Epoch 86/100\n",
      "7/7 - 0s - loss: 0.4019 - hamming_loss: 0.1792 - val_loss: 0.4084 - val_hamming_loss: 0.1723\n",
      "Epoch 87/100\n",
      "7/7 - 0s - loss: 0.4018 - hamming_loss: 0.1792 - val_loss: 0.4086 - val_hamming_loss: 0.1723\n",
      "Epoch 88/100\n",
      "7/7 - 0s - loss: 0.4018 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 89/100\n",
      "7/7 - 0s - loss: 0.4018 - hamming_loss: 0.1792 - val_loss: 0.4093 - val_hamming_loss: 0.1723\n",
      "Epoch 90/100\n",
      "7/7 - 0s - loss: 0.4018 - hamming_loss: 0.1792 - val_loss: 0.4095 - val_hamming_loss: 0.1723\n",
      "Epoch 91/100\n",
      "7/7 - 0s - loss: 0.4017 - hamming_loss: 0.1792 - val_loss: 0.4096 - val_hamming_loss: 0.1723\n",
      "Epoch 92/100\n",
      "7/7 - 0s - loss: 0.4017 - hamming_loss: 0.1792 - val_loss: 0.4096 - val_hamming_loss: 0.1723\n",
      "Epoch 93/100\n",
      "7/7 - 0s - loss: 0.4017 - hamming_loss: 0.1792 - val_loss: 0.4095 - val_hamming_loss: 0.1723\n",
      "Epoch 94/100\n",
      "7/7 - 0s - loss: 0.4016 - hamming_loss: 0.1792 - val_loss: 0.4096 - val_hamming_loss: 0.1723\n",
      "Epoch 95/100\n",
      "7/7 - 0s - loss: 0.4015 - hamming_loss: 0.1792 - val_loss: 0.4092 - val_hamming_loss: 0.1723\n",
      "Epoch 96/100\n",
      "7/7 - 0s - loss: 0.4017 - hamming_loss: 0.1792 - val_loss: 0.4090 - val_hamming_loss: 0.1723\n",
      "Epoch 97/100\n",
      "7/7 - 0s - loss: 0.4016 - hamming_loss: 0.1792 - val_loss: 0.4091 - val_hamming_loss: 0.1723\n",
      "Epoch 98/100\n",
      "7/7 - 0s - loss: 0.4015 - hamming_loss: 0.1792 - val_loss: 0.4093 - val_hamming_loss: 0.1723\n",
      "Epoch 99/100\n",
      "7/7 - 0s - loss: 0.4015 - hamming_loss: 0.1792 - val_loss: 0.4096 - val_hamming_loss: 0.1723\n",
      "Epoch 100/100\n",
      "7/7 - 0s - loss: 0.4015 - hamming_loss: 0.1792 - val_loss: 0.4097 - val_hamming_loss: 0.1723\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "history_ce_RNN_lr001_full = model_LSTM_full.fit(train_padded, Y_train, epochs = 100, \n",
    "               validation_data = (test_padded, Y_test), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Convert training history to dataframe and write to a .json file\n",
    "history_ce_RNN_lr001_full_df = pd.DataFrame(history_ce_RNN_lr001_full.history)\n",
    "#with open(\"Full Data Eval Metrics/Cross Entropy RNN/history_ce_RNN_lr001_full.json\", \"w\") as outfile: \n",
    "#    history_ce_RNN_lr001_full_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Learn a threshold function and save the test error for use in future DF\n",
    "Y_train_pred = model_LSTM_full.predict(train_padded)\n",
    "Y_test_pred = model_LSTM_full.predict(test_padded)\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(Y_train_pred, Y_train, Y_test_pred, t_range)\n",
    "ce_RNN_full_withThreshold = metrics.hamming_loss(Y_test, test_labels_binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17307692307692307"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_RNN_full_withThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (CAUTION: DO NOT OVERWRITE EXISTING FILES) -- Collect the test set hamming losses for the models \n",
    "##                                               with learned threshold functions into a df and write to .json file\n",
    "val_hamming_loss_withThreshold_lr001_df = pd.DataFrame({'ce_FF_full_lr001' : ce_FF_full_withThreshold,\n",
    "                                                        'ce_RNN_full_lr001' : ce_RNN_full_withThreshold},\n",
    "                                                        index = [0])\n",
    "\n",
    "#with open(\"Full Data Eval Metrics/val_hamming_loss_withThreshold_lr001.json\", \"w\") as outfile: \n",
    "#    val_hamming_loss_withThreshold_lr001_df.to_json(outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ce_FF_full_lr001</th>\n",
       "      <th>ce_RNN_full_lr001</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.178686</td>\n",
       "      <td>0.173077</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ce_FF_full_lr001  ce_RNN_full_lr001\n",
       "0          0.178686           0.173077"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_hamming_loss_withThreshold_lr001_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
