{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################################################################################################\n",
    "# Filename: Autoencoder_for_Dimension_Reduction.ipynb\n",
    "#\n",
    "# Purpose: To learn an autoencoder for dimension reduction of tf-idf feature vectors\n",
    "#\n",
    "# Author(s): Bobby (Robert) Lumpkin\n",
    "#\n",
    "# Library Dependencies: numpy, pandas, tensorflow, bpmll, sklearn, skmultilearn, sys, threshold_learning\n",
    "########################################################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder Learning for TF-IDF Feature Vectors (Non-linear Dimension Reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skmultilearn.adapt import MLkNN\n",
    "import sys\n",
    "sys.path.append('../ThresholdFunctionLearning')    ## Append path to the ThresholdFunctionLearning directory to the interpreters\n",
    "                                                   ## search path\n",
    "from threshold_learning import predict_test_labels_binary    ## Import the 'predict_test_labels_binary()' function from the "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>para_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>threats/impacts</th>\n",
       "      <th>responses/actions</th>\n",
       "      <th>severity</th>\n",
       "      <th>susceptibility</th>\n",
       "      <th>self-efficacy</th>\n",
       "      <th>external-efficacy</th>\n",
       "      <th>response efficacy</th>\n",
       "      <th>public health</th>\n",
       "      <th>...</th>\n",
       "      <th>prosper</th>\n",
       "      <th>preview</th>\n",
       "      <th>moor</th>\n",
       "      <th>coverag</th>\n",
       "      <th>glow</th>\n",
       "      <th>profil</th>\n",
       "      <th>clash</th>\n",
       "      <th>incumb</th>\n",
       "      <th>frequent</th>\n",
       "      <th>unfound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>214236</td>\n",
       "      <td>MURPHY: Again Martha we are defacto staying at...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>214232</td>\n",
       "      <td>GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>214266</td>\n",
       "      <td>BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>214246</td>\n",
       "      <td>But in the meantime, my message to Louisiana i...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>214238</td>\n",
       "      <td>MURPHY: Yeah listen, we had gotten another shi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   para_id                                          full_text  \\\n",
       "0   214236  MURPHY: Again Martha we are defacto staying at...   \n",
       "1   214232  GOV. PHIL MURPHY, (D-NJ): Yes. Good to be back...   \n",
       "2   214266  BEAUMONT (ON SCREEN UPPER LEFT - \"FRIDAY MARCH...   \n",
       "3   214246  But in the meantime, my message to Louisiana i...   \n",
       "4   214238  MURPHY: Yeah listen, we had gotten another shi...   \n",
       "\n",
       "   threats/impacts  responses/actions  severity  susceptibility  \\\n",
       "0                1                  1         0               1   \n",
       "1                1                  1         1               1   \n",
       "2                0                  1         0               0   \n",
       "3                1                  1         1               0   \n",
       "4                0                  1         0               0   \n",
       "\n",
       "   self-efficacy  external-efficacy  response efficacy  public health  ...  \\\n",
       "0              1                  0                  1              1  ...   \n",
       "1              1                  0                  1              1  ...   \n",
       "2              0                  1                  0              1  ...   \n",
       "3              1                  0                  1              1  ...   \n",
       "4              0                  1                  0              1  ...   \n",
       "\n",
       "   prosper  preview  moor  coverag  glow  profil  clash  incumb  frequent  \\\n",
       "0      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "1      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "2      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "3      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "4      0.0      0.0   0.0      0.0   0.0     0.0    0.0     0.0       0.0   \n",
       "\n",
       "  unfound  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "\n",
       "[5 rows x 2119 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Load 'content_paragraphs_ready.csv' into a pandas dataframe\n",
    "data_filepath = \"..\\..\\dataset\\content_paragraphs_ready.csv\"\n",
    "paragraph_data = pd.read_csv(data_filepath)\n",
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>murphi</th>\n",
       "      <th>martha</th>\n",
       "      <th>defacto</th>\n",
       "      <th>stay</th>\n",
       "      <th>home</th>\n",
       "      <th>state</th>\n",
       "      <th>million</th>\n",
       "      <th>us</th>\n",
       "      <th>you�</th>\n",
       "      <th>...</th>\n",
       "      <th>susceptibility</th>\n",
       "      <th>self-efficacy</th>\n",
       "      <th>external-efficacy</th>\n",
       "      <th>response efficacy</th>\n",
       "      <th>public health</th>\n",
       "      <th>economy</th>\n",
       "      <th>education</th>\n",
       "      <th>political evaluation</th>\n",
       "      <th>racial conflict</th>\n",
       "      <th>international ralations/foreign policies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text1</td>\n",
       "      <td>1.684247</td>\n",
       "      <td>1.348455</td>\n",
       "      <td>2.161368</td>\n",
       "      <td>3.118616</td>\n",
       "      <td>3.016311</td>\n",
       "      <td>0.91833</td>\n",
       "      <td>1.207125</td>\n",
       "      <td>1.383217</td>\n",
       "      <td>1.763428</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>text2</td>\n",
       "      <td>1.684247</td>\n",
       "      <td>1.348455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.67332</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.763428</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>text3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>text4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>text5</td>\n",
       "      <td>1.684247</td>\n",
       "      <td>1.348455</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.383217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  doc_id    murphi    martha   defacto      stay      home    state   million  \\\n",
       "0  text1  1.684247  1.348455  2.161368  3.118616  3.016311  0.91833  1.207125   \n",
       "1  text2  1.684247  1.348455  0.000000  0.000000  0.000000  3.67332  0.000000   \n",
       "2  text3  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "3  text4  0.000000  0.000000  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "4  text5  1.684247  1.348455  0.000000  0.000000  0.000000  0.00000  0.000000   \n",
       "\n",
       "         us      you�  ...  susceptibility  self-efficacy  external-efficacy  \\\n",
       "0  1.383217  1.763428  ...               1              1                  0   \n",
       "1  0.000000  1.763428  ...               1              1                  0   \n",
       "2  0.000000  0.000000  ...               0              0                  1   \n",
       "3  0.000000  0.000000  ...               0              1                  0   \n",
       "4  1.383217  0.000000  ...               0              0                  1   \n",
       "\n",
       "   response efficacy  public health  economy  education  political evaluation  \\\n",
       "0                  1              1        0          0                     0   \n",
       "1                  1              1        0          0                     0   \n",
       "2                  0              1        0          0                     0   \n",
       "3                  1              1        0          0                     0   \n",
       "4                  0              1        0          0                     0   \n",
       "\n",
       "   racial conflict  international ralations/foreign policies  \n",
       "0                0                                         0  \n",
       "1                0                                         0  \n",
       "2                0                                         0  \n",
       "3                0                                         0  \n",
       "4                0                                         0  \n",
       "\n",
       "[5 rows x 2108 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Keep only 'doc_id', the label columns, and the tf-idf columns\n",
    "tfidf_colnames = list(paragraph_data.columns[25:])\n",
    "label_columns = list(paragraph_data.columns[2:15])\n",
    "cols_toKeep = ['doc_id']\n",
    "cols_toKeep.extend(tfidf_colnames)\n",
    "cols_toKeep.extend(label_columns)\n",
    "paragraph_data = paragraph_data[cols_toKeep]\n",
    "paragraph_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define the X and Y train and test matrices\n",
    "X = paragraph_data[tfidf_colnames].to_numpy().astype(float)\n",
    "Y = paragraph_data[label_columns].to_numpy().astype(float)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.33, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2094"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 62\n",
    "visible_dim = X.shape[1]\n",
    "\n",
    "class Autoencoder(Model):\n",
    "    def __init__(self, latent_dim, visible_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.latent_dim = latent_dim   \n",
    "        self.encoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(latent_dim * 2, activation = 'tanh'),\n",
    "            tf.keras.layers.Dense(latent_dim, activation = 'relu'),\n",
    "        ])\n",
    "        self.decoder = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(latent_dim * 2, activation = 'sigmoid'),\n",
    "            tf.keras.layers.Dense(visible_dim, activation = 'relu'),\n",
    "        ])\n",
    "\n",
    "    def call(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "autoencoder = Autoencoder(latent_dim, visible_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer = 'adam', loss = tf.keras.losses.MeanSquaredError())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "7/7 [==============================] - 1s 36ms/step - loss: 0.0506 - val_loss: 0.0410\n",
      "Epoch 2/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0432 - val_loss: 0.0410\n",
      "Epoch 3/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0450 - val_loss: 0.0410\n",
      "Epoch 4/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0438 - val_loss: 0.0410\n",
      "Epoch 5/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0436 - val_loss: 0.0410\n",
      "Epoch 6/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0424 - val_loss: 0.0409\n",
      "Epoch 7/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0430 - val_loss: 0.0409\n",
      "Epoch 8/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0436 - val_loss: 0.0409\n",
      "Epoch 9/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0426 - val_loss: 0.0409\n",
      "Epoch 10/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0455 - val_loss: 0.0409\n",
      "Epoch 11/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0440 - val_loss: 0.0408\n",
      "Epoch 12/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0432 - val_loss: 0.0407\n",
      "Epoch 13/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0411 - val_loss: 0.0407\n",
      "Epoch 14/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0444 - val_loss: 0.0407\n",
      "Epoch 15/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0436 - val_loss: 0.0406\n",
      "Epoch 16/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0425 - val_loss: 0.0406\n",
      "Epoch 17/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0427 - val_loss: 0.0405\n",
      "Epoch 18/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0418 - val_loss: 0.0404\n",
      "Epoch 19/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0415 - val_loss: 0.0404\n",
      "Epoch 20/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0426 - val_loss: 0.0404\n",
      "Epoch 21/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0409 - val_loss: 0.0403\n",
      "Epoch 22/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0413 - val_loss: 0.0403\n",
      "Epoch 23/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0410 - val_loss: 0.0402\n",
      "Epoch 24/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0426 - val_loss: 0.0402\n",
      "Epoch 25/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 26/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0420 - val_loss: 0.0402\n",
      "Epoch 27/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0415 - val_loss: 0.0401\n",
      "Epoch 28/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0414 - val_loss: 0.0401\n",
      "Epoch 29/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0420 - val_loss: 0.0401\n",
      "Epoch 30/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0401 - val_loss: 0.0401\n",
      "Epoch 31/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0405 - val_loss: 0.0400\n",
      "Epoch 32/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0389 - val_loss: 0.0400\n",
      "Epoch 33/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0394 - val_loss: 0.0400\n",
      "Epoch 34/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0411 - val_loss: 0.0400\n",
      "Epoch 35/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0378 - val_loss: 0.0400\n",
      "Epoch 36/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0390 - val_loss: 0.0400\n",
      "Epoch 37/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0387 - val_loss: 0.0400\n",
      "Epoch 38/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0401 - val_loss: 0.0399\n",
      "Epoch 39/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0386 - val_loss: 0.0399\n",
      "Epoch 40/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0397 - val_loss: 0.0399\n",
      "Epoch 41/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0399\n",
      "Epoch 42/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0373 - val_loss: 0.0399\n",
      "Epoch 43/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0396 - val_loss: 0.0398\n",
      "Epoch 44/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0387 - val_loss: 0.0398\n",
      "Epoch 45/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0394 - val_loss: 0.0398\n",
      "Epoch 46/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0396 - val_loss: 0.0398\n",
      "Epoch 47/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0386 - val_loss: 0.0398\n",
      "Epoch 48/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 49/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 50/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0375 - val_loss: 0.0398\n",
      "Epoch 51/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0392 - val_loss: 0.0398\n",
      "Epoch 52/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 53/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 54/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0406 - val_loss: 0.0398\n",
      "Epoch 55/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 56/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0397\n",
      "Epoch 57/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 58/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0386 - val_loss: 0.0398\n",
      "Epoch 59/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0383 - val_loss: 0.0397\n",
      "Epoch 60/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0397\n",
      "Epoch 61/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0397\n",
      "Epoch 62/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0387 - val_loss: 0.0398\n",
      "Epoch 63/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 64/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0390 - val_loss: 0.0398\n",
      "Epoch 65/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0397\n",
      "Epoch 66/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0397\n",
      "Epoch 67/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0386 - val_loss: 0.0397\n",
      "Epoch 68/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0397\n",
      "Epoch 69/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0397\n",
      "Epoch 70/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 71/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0363 - val_loss: 0.0397\n",
      "Epoch 72/400\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0385 - val_loss: 0.0397\n",
      "Epoch 73/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0391 - val_loss: 0.0397\n",
      "Epoch 74/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 75/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 76/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0366 - val_loss: 0.0397\n",
      "Epoch 77/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0397\n",
      "Epoch 78/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 79/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.0397\n",
      "Epoch 80/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0387 - val_loss: 0.0397\n",
      "Epoch 81/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 82/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 83/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0397\n",
      "Epoch 84/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0378 - val_loss: 0.0397\n",
      "Epoch 85/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0397\n",
      "Epoch 86/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0376 - val_loss: 0.0397\n",
      "Epoch 87/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0397\n",
      "Epoch 88/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 89/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0382 - val_loss: 0.0398\n",
      "Epoch 90/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 91/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 92/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0397\n",
      "Epoch 93/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 94/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0397\n",
      "Epoch 95/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0397\n",
      "Epoch 96/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0375 - val_loss: 0.0398\n",
      "Epoch 97/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0387 - val_loss: 0.0398\n",
      "Epoch 98/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 99/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0371 - val_loss: 0.0397\n",
      "Epoch 100/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0368 - val_loss: 0.0397\n",
      "Epoch 101/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 102/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 103/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 104/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 105/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 106/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 107/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 108/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 109/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 110/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 111/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 112/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 113/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 114/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 115/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 116/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 117/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0355 - val_loss: 0.0398\n",
      "Epoch 118/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 119/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 120/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 121/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 122/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 123/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 124/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 125/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 126/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 127/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0384 - val_loss: 0.0398\n",
      "Epoch 128/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 129/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 130/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 131/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 132/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 133/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 134/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 135/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 136/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0384 - val_loss: 0.0398\n",
      "Epoch 137/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0398\n",
      "Epoch 138/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 139/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0382 - val_loss: 0.0398\n",
      "Epoch 140/400\n",
      "7/7 [==============================] - 0s 17ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 141/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 142/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 143/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 144/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 145/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 146/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 147/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 148/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 149/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 150/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 151/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 152/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0352 - val_loss: 0.0398\n",
      "Epoch 153/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 154/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 155/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 156/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 157/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0355 - val_loss: 0.0398\n",
      "Epoch 158/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 159/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 160/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 161/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 162/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 163/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 164/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 165/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 166/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 167/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 168/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 169/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 170/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 171/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 172/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 173/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 174/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 175/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 176/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 177/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 178/400\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 179/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0399\n",
      "Epoch 180/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0356 - val_loss: 0.0399\n",
      "Epoch 181/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0363 - val_loss: 0.0399\n",
      "Epoch 182/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0399\n",
      "Epoch 183/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 184/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0399\n",
      "Epoch 185/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0399\n",
      "Epoch 186/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 187/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0359 - val_loss: 0.0399\n",
      "Epoch 188/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 189/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 190/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0376 - val_loss: 0.0399\n",
      "Epoch 191/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0376 - val_loss: 0.0399\n",
      "Epoch 192/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 193/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 194/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0399\n",
      "Epoch 195/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0372 - val_loss: 0.0399\n",
      "Epoch 196/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0369 - val_loss: 0.0399\n",
      "Epoch 197/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0357 - val_loss: 0.0399\n",
      "Epoch 198/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0367 - val_loss: 0.0399\n",
      "Epoch 199/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 200/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0364 - val_loss: 0.0399\n",
      "Epoch 201/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0387 - val_loss: 0.0399\n",
      "Epoch 202/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 203/400\n",
      "7/7 [==============================] - 0s 9ms/step - loss: 0.0357 - val_loss: 0.0399\n",
      "Epoch 204/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0353 - val_loss: 0.0399\n",
      "Epoch 205/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 206/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0379 - val_loss: 0.0399\n",
      "Epoch 207/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 208/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0355 - val_loss: 0.0398\n",
      "Epoch 209/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 210/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0344 - val_loss: 0.0399\n",
      "Epoch 211/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 212/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0399\n",
      "Epoch 213/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0370 - val_loss: 0.0399\n",
      "Epoch 214/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 215/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0354 - val_loss: 0.0399\n",
      "Epoch 216/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 217/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0399\n",
      "Epoch 218/400\n",
      "7/7 [==============================] - 0s 10ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 219/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 220/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0350 - val_loss: 0.0398\n",
      "Epoch 221/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 222/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 223/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 224/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 225/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0386 - val_loss: 0.0398\n",
      "Epoch 226/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 227/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 228/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 229/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 230/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 231/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 232/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 233/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 234/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 235/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0366 - val_loss: 0.0399\n",
      "Epoch 236/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 237/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 238/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 239/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 240/400\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 241/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 242/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0381 - val_loss: 0.0398\n",
      "Epoch 243/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 244/400\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 245/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 246/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0375 - val_loss: 0.0398\n",
      "Epoch 247/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 248/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 249/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 250/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 251/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 252/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 253/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 254/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 255/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 256/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 257/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 258/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 259/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 260/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 261/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 262/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 263/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0354 - val_loss: 0.0398\n",
      "Epoch 264/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 265/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 266/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0383 - val_loss: 0.0398\n",
      "Epoch 267/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 268/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0383 - val_loss: 0.0398\n",
      "Epoch 269/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 270/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 271/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 272/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 273/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 274/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0385 - val_loss: 0.0398\n",
      "Epoch 275/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 276/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 277/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 278/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 279/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 280/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0352 - val_loss: 0.0398\n",
      "Epoch 281/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 282/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 283/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 284/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 285/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 286/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0351 - val_loss: 0.0398\n",
      "Epoch 287/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 288/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 289/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 290/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0349 - val_loss: 0.0398\n",
      "Epoch 291/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 292/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0382 - val_loss: 0.0398\n",
      "Epoch 293/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 294/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 295/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 296/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0352 - val_loss: 0.0398\n",
      "Epoch 297/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 298/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0351 - val_loss: 0.0398\n",
      "Epoch 299/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 300/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 301/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 302/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 303/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0385 - val_loss: 0.0398\n",
      "Epoch 304/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 305/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 306/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0384 - val_loss: 0.0398\n",
      "Epoch 307/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 308/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 309/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 310/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 311/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 312/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0352 - val_loss: 0.0398\n",
      "Epoch 313/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 314/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 315/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0351 - val_loss: 0.0398\n",
      "Epoch 316/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 317/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 318/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 319/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 320/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 321/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 322/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 323/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0343 - val_loss: 0.0398\n",
      "Epoch 324/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 325/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 326/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 327/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 328/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 329/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 330/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0360 - val_loss: 0.0398\n",
      "Epoch 331/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 332/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0371 - val_loss: 0.0398\n",
      "Epoch 333/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 334/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0399\n",
      "Epoch 335/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 336/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 337/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0356 - val_loss: 0.0398\n",
      "Epoch 338/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 339/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 340/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0348 - val_loss: 0.0398\n",
      "Epoch 341/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 342/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 343/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 344/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 345/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0376 - val_loss: 0.0398\n",
      "Epoch 346/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 347/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 348/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 349/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0377 - val_loss: 0.0398\n",
      "Epoch 350/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 351/400\n",
      "7/7 [==============================] - 0s 14ms/step - loss: 0.0357 - val_loss: 0.0398\n",
      "Epoch 352/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0353 - val_loss: 0.0398\n",
      "Epoch 353/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 354/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0354 - val_loss: 0.0399\n",
      "Epoch 355/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 356/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0379 - val_loss: 0.0399\n",
      "Epoch 357/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 358/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0360 - val_loss: 0.0399\n",
      "Epoch 359/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 360/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0399\n",
      "Epoch 361/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 362/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0374 - val_loss: 0.0399\n",
      "Epoch 363/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 364/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 365/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0368 - val_loss: 0.0398\n",
      "Epoch 366/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0369 - val_loss: 0.0398\n",
      "Epoch 367/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 368/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0362 - val_loss: 0.0398\n",
      "Epoch 369/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0347 - val_loss: 0.0398\n",
      "Epoch 370/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 371/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 372/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0344 - val_loss: 0.0398\n",
      "Epoch 373/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 374/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 375/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0373 - val_loss: 0.0398\n",
      "Epoch 376/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0346 - val_loss: 0.0398\n",
      "Epoch 377/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 378/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0364 - val_loss: 0.0398\n",
      "Epoch 379/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0378 - val_loss: 0.0398\n",
      "Epoch 380/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0372 - val_loss: 0.0398\n",
      "Epoch 381/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0358 - val_loss: 0.0398\n",
      "Epoch 382/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 383/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0365 - val_loss: 0.0398\n",
      "Epoch 384/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0344 - val_loss: 0.0398\n",
      "Epoch 385/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n",
      "Epoch 386/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0370 - val_loss: 0.0398\n",
      "Epoch 387/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0379 - val_loss: 0.0398\n",
      "Epoch 388/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 389/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0381 - val_loss: 0.0398\n",
      "Epoch 390/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0380 - val_loss: 0.0398\n",
      "Epoch 391/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 392/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 393/400\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0394 - val_loss: 0.0398\n",
      "Epoch 394/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0359 - val_loss: 0.0398\n",
      "Epoch 395/400\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.0366 - val_loss: 0.0398\n",
      "Epoch 396/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0367 - val_loss: 0.0398\n",
      "Epoch 397/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0384 - val_loss: 0.0398\n",
      "Epoch 398/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0361 - val_loss: 0.0398\n",
      "Epoch 399/400\n",
      "7/7 [==============================] - 0s 12ms/step - loss: 0.0374 - val_loss: 0.0398\n",
      "Epoch 400/400\n",
      "7/7 [==============================] - 0s 13ms/step - loss: 0.0363 - val_loss: 0.0398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed23a59e50>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.set_seed(123)\n",
    "autoencoder.fit(X_train, X_train,\n",
    "                epochs = 400,\n",
    "                shuffle = True,\n",
    "                validation_data = (X_test, X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_tfidfs = autoencoder.encoder(X).numpy()\n",
    "decoded_tfidfs = autoencoder.decoder(encoded_tfidfs).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(290, 62)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_tfidfs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write the encoded data to a csv file\n",
    "encoded_df = pd.DataFrame(encoded_tfidfs)\n",
    "encoded_df.to_csv('encoded_tfidfs_reluOutput.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Encoded Data for ML-KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_train, encoded_test, Y_train, Y_test = train_test_split(encoded_tfidfs, Y, test_size = 0.33, random_state = 321)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Hamming loss for the training data is 0.112\n",
      "The Hamming loss for the test data is 0.162\n"
     ]
    }
   ],
   "source": [
    "classifier = MLkNN(k = 3)\n",
    "classifier.fit(encoded_train, Y_train)\n",
    "y_train_pred = classifier.predict(encoded_train)\n",
    "y_train_pred_array = y_train_pred.toarray()\n",
    "y_test_pred = classifier.predict(encoded_test)\n",
    "y_test_pred_array = y_test_pred.toarray()\n",
    "\n",
    "print (f\"The Hamming loss for the training data is {metrics.hamming_loss(Y_train, y_train_pred_array):.3f}\")\n",
    "print (f\"The Hamming loss for the test data is {metrics.hamming_loss(Y_test, y_test_pred_array):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'k': range(1,5), 's': [1.0, 1.5, 2.5, 5.0, 10.0]}  \n",
    "#By default, the Hamming loss as an option is not provided in the scoring string options. So, we will make the Hamming loss funciton as a scorer and use that. \n",
    "hamming_scorer = metrics.make_scorer(metrics.hamming_loss)\n",
    "\n",
    "clf = GridSearchCV(MLkNN(), parameters, scoring = hamming_scorer, cv = 5, verbose = 1)\n",
    "clf.fit(encoded_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Params</th>\n",
       "      <th>Mean out-of-bag Hamming loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'k': 1, 's': 1.0}</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'k': 1, 's': 1.5}</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'k': 1, 's': 2.5}</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'k': 1, 's': 5.0}</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'k': 1, 's': 10.0}</td>\n",
       "      <td>0.208741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'k': 2, 's': 1.0}</td>\n",
       "      <td>0.221416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'k': 2, 's': 1.5}</td>\n",
       "      <td>0.220627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'k': 2, 's': 2.5}</td>\n",
       "      <td>0.213526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'k': 2, 's': 5.0}</td>\n",
       "      <td>0.209571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'k': 2, 's': 10.0}</td>\n",
       "      <td>0.197145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'k': 3, 's': 1.0}</td>\n",
       "      <td>0.184896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'k': 3, 's': 1.5}</td>\n",
       "      <td>0.185685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>{'k': 3, 's': 2.5}</td>\n",
       "      <td>0.180421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>{'k': 3, 's': 5.0}</td>\n",
       "      <td>0.182788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>{'k': 3, 's': 10.0}</td>\n",
       "      <td>0.177639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>{'k': 4, 's': 1.0}</td>\n",
       "      <td>0.181989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>{'k': 4, 's': 1.5}</td>\n",
       "      <td>0.183193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>{'k': 4, 's': 2.5}</td>\n",
       "      <td>0.181595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>{'k': 4, 's': 5.0}</td>\n",
       "      <td>0.181989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>{'k': 4, 's': 10.0}</td>\n",
       "      <td>0.178833</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Params  Mean out-of-bag Hamming loss\n",
       "0    {'k': 1, 's': 1.0}                      0.208741\n",
       "1    {'k': 1, 's': 1.5}                      0.208741\n",
       "2    {'k': 1, 's': 2.5}                      0.208741\n",
       "3    {'k': 1, 's': 5.0}                      0.208741\n",
       "4   {'k': 1, 's': 10.0}                      0.208741\n",
       "5    {'k': 2, 's': 1.0}                      0.221416\n",
       "6    {'k': 2, 's': 1.5}                      0.220627\n",
       "7    {'k': 2, 's': 2.5}                      0.213526\n",
       "8    {'k': 2, 's': 5.0}                      0.209571\n",
       "9   {'k': 2, 's': 10.0}                      0.197145\n",
       "10   {'k': 3, 's': 1.0}                      0.184896\n",
       "11   {'k': 3, 's': 1.5}                      0.185685\n",
       "12   {'k': 3, 's': 2.5}                      0.180421\n",
       "13   {'k': 3, 's': 5.0}                      0.182788\n",
       "14  {'k': 3, 's': 10.0}                      0.177639\n",
       "15   {'k': 4, 's': 1.0}                      0.181989\n",
       "16   {'k': 4, 's': 1.5}                      0.183193\n",
       "17   {'k': 4, 's': 2.5}                      0.181595\n",
       "18   {'k': 4, 's': 5.0}                      0.181989\n",
       "19  {'k': 4, 's': 10.0}                      0.178833"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'k': 3, 's': 10.0} 0.17763936468389913\n"
     ]
    }
   ],
   "source": [
    "best_index = np.argmin(clf.cv_results_[\"mean_test_score\"])\n",
    "best_parameters = clf.cv_results_[\"params\"][best_index]\n",
    "\n",
    "df_CV = pd.DataFrame(columns=[\"Params\", \"Mean out-of-bag Hamming loss\"])\n",
    "df_CV[\"Params\"] = clf.cv_results_[\"params\"]\n",
    "df_CV[ \"Mean out-of-bag Hamming loss\"] = clf.cv_results_[\"mean_test_score\"]\n",
    "display(df_CV)\n",
    "print(best_parameters, np.min(clf.cv_results_['mean_test_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: The Hamming loss training data is 0.123\n",
      "Best parameters: The Hamming loss test data is 0.165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rober\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:67: FutureWarning: Pass n_neighbors=3 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  warnings.warn(\"Pass {} as keyword args. From version 0.25 \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters with threshold function learning: Hamming loss Test set is 0.22756410256410256\n"
     ]
    }
   ],
   "source": [
    "#Threshold learning\n",
    "#using the best parameters from the cross-validation with original threshold. \n",
    "classifier_best = MLkNN(k = 3, s = 10)\n",
    "classifier_best.fit(encoded_train, Y_train)\n",
    "y_train_pred_best = classifier_best.predict(encoded_train)\n",
    "y_train_pred_best_array = y_train_pred_best.toarray()\n",
    "y_test_pred_best = classifier_best.predict(encoded_test)\n",
    "y_test_pred_best_array = y_test_pred_best.toarray()\n",
    "\n",
    "print (f\"Best parameters: The Hamming loss training data is {metrics.hamming_loss(Y_train, y_train_pred_best_array):.3f}\")\n",
    "print (f\"Best parameters: The Hamming loss test data is {metrics.hamming_loss(Y_test, y_test_pred_best_array):.3f}\")\n",
    "\n",
    "#using the best parameters\n",
    "classifier_CV = MLkNN(k = 3, s = 2.5)\n",
    "classifier_CV.fit(encoded_train, Y_train)\n",
    "y_train_pred_proba = classifier_CV.predict_proba(encoded_train)\n",
    "y_train_pred_proba_array = y_train_pred_proba.toarray()\n",
    "y_test_pred_proba = classifier_CV.predict_proba(encoded_test)\n",
    "y_test_pred_proba_array = y_test_pred_proba.toarray()\n",
    "\n",
    "t_range = (0, 1)\n",
    "\n",
    "test_labels_binary, threshold_function = predict_test_labels_binary(y_train_pred_proba_array, Y_train, y_test_pred_proba_array, t_range)\n",
    "print (f\"Best parameters with threshold function learning: Hamming loss Test set is {metrics.hamming_loss(Y_test, test_labels_binary)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
